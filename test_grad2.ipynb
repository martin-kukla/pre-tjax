{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "347742f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "- 2\n",
      "-- torch.Size([6, 4]) tensor([-0.054427,  0.153246, -0.024114], device='cuda:0')\n",
      "-- torch.Size([6]) tensor([ 0.165028, -0.035873, -0.129454], device='cuda:0')\n",
      "- 1\n",
      "-- torch.Size([5, 4]) tensor([-0.028046, -0.044563, -0.020177], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([4]) tensor([ 7.932237e-05, -1.188597e-04,  1.259867e-05], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([ 9.668623e-05,  1.931267e-04, -5.131257e-05], device='cuda:0')\n",
      "-- torch.Size([2, 3, 2, 4]) tensor([ 0.003297, -0.003310, -0.001549], device='cuda:0')\n",
      "-- torch.Size([4, 4]) tensor([ 0.000242, -0.000832, -0.001930], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([6.587836e-06, 5.283717e-05, 1.544247e-04], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([ 1.020024e-05, -8.035130e-05, -1.248818e-04], device='cuda:0')\n",
      "-- torch.Size([16, 4]) tensor([-0.000737,  0.001317, -0.001313], device='cuda:0')\n",
      "-- torch.Size([16]) tensor([ 0.000607, -0.000634, -0.001001], device='cuda:0')\n",
      "-- torch.Size([4, 16]) tensor([-0.002221, -0.003061,  0.006204], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([-0.107728, -0.009035,  0.207030], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([4]) tensor([ 6.854429e-05,  2.721793e-05, -2.680711e-05], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([ 9.807515e-05, -4.645600e-05,  6.202506e-05], device='cuda:0')\n",
      "-- torch.Size([2, 3, 2, 4]) tensor([-0.001806,  0.000781,  0.001484], device='cuda:0')\n",
      "-- torch.Size([4, 4]) tensor([0.001442, 0.008826, 0.001474], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([ 7.902703e-05, -9.591306e-05,  1.071368e-05], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([ 1.008901e-04,  8.339278e-05, -4.658455e-05], device='cuda:0')\n",
      "-- torch.Size([16, 4]) tensor([-0.001364,  0.002001,  0.001140], device='cuda:0')\n",
      "-- torch.Size([16]) tensor([ 0.000102, -0.000280, -0.001648], device='cuda:0')\n",
      "-- torch.Size([4, 16]) tensor([ 0.001099, -0.005387, -0.003232], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([-0.111575, -0.009170,  0.208163], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([4]) tensor([-0.000331,  0.008550, -0.007783], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([ 9.693764e-05, -3.631846e-03,  5.948682e-03], device='cuda:0')\n",
      "----XXX----\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[16]' is invalid for input of size 160",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 34\u001b[0m\n\u001b[1;32m     30\u001b[0m print_res_shapes(res2[\u001b[38;5;241m0\u001b[39m]) \n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m----XXX----\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m res3 \u001b[38;5;241m=\u001b[39m \u001b[43mt_loss_bkwd2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayers_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_gen_aux\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#print(res3)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m print_res_shapes(res3[\u001b[38;5;241m0\u001b[39m]) \n",
      "File \u001b[0;32m/efs/notebooks/mkukla/pre-tjax/loss_and_optimizer_triton.py:122\u001b[0m, in \u001b[0;36mt_loss_bkwd2\u001b[0;34m(params, y, y_mask, y_indices, train, p_gen_aux)\u001b[0m\n\u001b[1;32m    119\u001b[0m logits \u001b[38;5;241m=\u001b[39m t_gpt2_forward(params, y_in, y_mask, y_indices, train, p_gen_aux) \n\u001b[1;32m    121\u001b[0m dloss_dx \u001b[38;5;241m=\u001b[39m t_avg_cross_entropy_loss_bkwd2(y_out, logits)\n\u001b[0;32m--> 122\u001b[0m dloss_dx \u001b[38;5;241m=\u001b[39m \u001b[43mt_gpt2_bkwd2_p\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdloss_dx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_gen_aux\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m loss_val, tokens_count \u001b[38;5;241m=\u001b[39m t_avg_cross_entropy_loss(y_out, logits)\n\u001b[1;32m    125\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy(y_out, logits)\n",
      "File \u001b[0;32m/efs/notebooks/mkukla/pre-tjax/model_triton.py:876\u001b[0m, in \u001b[0;36mt_gpt2_bkwd2_p\u001b[0;34m(dloss_dx, params, y, y_mask, y_indices, train, p_gen_aux)\u001b[0m\n\u001b[1;32m    873\u001b[0m linear_dloss_dp \u001b[38;5;241m=\u001b[39m t_linear_bkwd2_p(dloss_dx, params[\u001b[38;5;241m0\u001b[39m], y)    \n\u001b[1;32m    874\u001b[0m dloss_dx \u001b[38;5;241m=\u001b[39m t_linear_bkwd2_x(dloss_dx, params[\u001b[38;5;241m0\u001b[39m], y)\n\u001b[0;32m--> 876\u001b[0m dloss_dp \u001b[38;5;241m=\u001b[39m \u001b[43mt_gpt2_tlayers_bkwd2_p\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdloss_dx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_gen_aux\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[1;32m    877\u001b[0m dloss_dp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(dloss_dp)\n\u001b[1;32m    879\u001b[0m \u001b[38;5;66;03m# As we tie embedding and last projection weights (no need to add jac[0][1] as it's zeroed)\u001b[39;00m\n",
      "File \u001b[0;32m/efs/notebooks/mkukla/pre-tjax/model_triton.py:826\u001b[0m, in \u001b[0;36mt_gpt2_tlayers_bkwd2_p\u001b[0;34m(dloss_dx, params, y, mask, indices, train, p_gen_aux)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, layer_params \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(params[\u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))):\n\u001b[1;32m    825\u001b[0m     y, layer_p_gen_aux \u001b[38;5;241m=\u001b[39m layers_inputs[i]\n\u001b[0;32m--> 826\u001b[0m     layers_dloss_dp\u001b[38;5;241m.\u001b[39mappend(\u001b[43mt_gpt2_tlayer_bkwd2_p\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdloss_dx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_p_gen_aux\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    827\u001b[0m     dloss_dx \u001b[38;5;241m=\u001b[39m t_gpt2_tlayer_bkwd2_x(dloss_dx, layer_params, y, mask, train, layer_p_gen_aux)\n\u001b[1;32m    828\u001b[0m layers_dloss_dp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mreversed\u001b[39m(layers_dloss_dp)) \u001b[38;5;66;03m# TODO XXX: clean up list+ reversed combos\u001b[39;00m\n",
      "File \u001b[0;32m/efs/notebooks/mkukla/pre-tjax/model_triton.py:703\u001b[0m, in \u001b[0;36mt_gpt2_tlayer_bkwd2_p\u001b[0;34m(dloss_dx, layer_params, y, mask, train, p_gen_aux)\u001b[0m\n\u001b[1;32m    701\u001b[0m y_in \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m    702\u001b[0m y \u001b[38;5;241m=\u001b[39m t_gpt2_tlayer_sublock1_fwd(layer_params[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m6\u001b[39m], y, mask, train, p_gen_aux[:\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m--> 703\u001b[0m subblock2_dloss_dp \u001b[38;5;241m=\u001b[39m \u001b[43mt_gpt2_tlayer_sublock2_bkwd2_p\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdloss_dx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_gen_aux\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    704\u001b[0m dloss_dx \u001b[38;5;241m=\u001b[39m t_gpt2_tlayer_sublock2_bkwd2_x(dloss_dx, layer_params[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m6\u001b[39m:], y, train, p_gen_aux[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m    705\u001b[0m subblock1_dloss_dp \u001b[38;5;241m=\u001b[39m t_gpt2_tlayer_sublock1_bkwd2_p(dloss_dx, layer_params[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m6\u001b[39m], y_in, mask, train, p_gen_aux[:\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[0;32m/efs/notebooks/mkukla/pre-tjax/model_triton.py:638\u001b[0m, in \u001b[0;36mt_gpt2_tlayer_sublock2_bkwd2_p\u001b[0;34m(dloss_dx, layer_params, y, train, p_gen_aux)\u001b[0m\n\u001b[1;32m    636\u001b[0m dloss_dx \u001b[38;5;241m=\u001b[39m t_dropout_bkwd2(dloss_dx, y_diff_ffn, train, p_gen_aux)\n\u001b[1;32m    637\u001b[0m tlayer_ffn_dloss_dp \u001b[38;5;241m=\u001b[39m t_tlayer_ffn_bkwd2_p(dloss_dx, layer_params[\u001b[38;5;241m2\u001b[39m:], y_diff, t_gelu_fwd)\n\u001b[0;32m--> 638\u001b[0m dloss_dx \u001b[38;5;241m=\u001b[39m \u001b[43mt_tlayer_ffn_bkwd2_x\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdloss_dx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_diff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_gelu_fwd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    639\u001b[0m layernorm_dloss_dp \u001b[38;5;241m=\u001b[39m t_layernorm_bkwd2_p(dloss_dx, layer_params[:\u001b[38;5;241m2\u001b[39m], y_in)\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m layernorm_dloss_dp \u001b[38;5;241m+\u001b[39m tlayer_ffn_dloss_dp\n",
      "File \u001b[0;32m/efs/notebooks/mkukla/pre-tjax/model_triton.py:420\u001b[0m, in \u001b[0;36mt_tlayer_ffn_bkwd2_x\u001b[0;34m(dloss_dx, layer_params, x, activation_fn)\u001b[0m\n\u001b[1;32m    417\u001b[0m x_2d \u001b[38;5;241m=\u001b[39m activation_fn(x_2d)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;66;03m# propagate back\u001b[39;00m\n\u001b[0;32m--> 420\u001b[0m dloss_dx \u001b[38;5;241m=\u001b[39m \u001b[43mt_linear_bkwd2_x\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdloss_dx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_2d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m dact_dx \u001b[38;5;241m=\u001b[39m act_fn_bkwd(x_2d_in1)\n\u001b[1;32m    422\u001b[0m dloss_dx \u001b[38;5;241m=\u001b[39m _vjp(dloss_dx, dact_dx)\n",
      "File \u001b[0;32m/efs/notebooks/mkukla/pre-tjax/model_triton.py:141\u001b[0m, in \u001b[0;36mt_linear_bkwd2_x\u001b[0;34m(dloss_dx, layer_params, x)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mt_linear_bkwd2_x\u001b[39m(dloss_dx, layer_params, x): \u001b[38;5;66;03m# input: N x D\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_vjp_in_2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdloss_dx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_proj_bkwd_x\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/efs/notebooks/mkukla/pre-tjax/model_triton.py:124\u001b[0m, in \u001b[0;36m_vjp_in_2d\u001b[0;34m(v, jac)\u001b[0m\n\u001b[1;32m    122\u001b[0m outdim \u001b[38;5;241m=\u001b[39m jac\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;28mlen\u001b[39m(v\u001b[38;5;241m.\u001b[39mshape):]\n\u001b[1;32m    123\u001b[0m res \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(v\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), jac\u001b[38;5;241m.\u001b[39mreshape((v\u001b[38;5;241m.\u001b[39mnumel(), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutdim\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[16]' is invalid for input of size 160"
     ]
    }
   ],
   "source": [
    "# t_loss_bkwd vs t_loss_bkwd2 on train=True\n",
    "import torch\n",
    "torch.set_printoptions(precision=6)\n",
    "from torch.func import jacrev\n",
    "from model_torch_func import init_transformer_gpt2\n",
    "#from model_triton import *\n",
    "from loss_and_optimizer_triton import t_loss, t_loss_bkwd, t_loss_bkwd2\n",
    "BS, H, N, D = 2, 2, 5, 4\n",
    "vocab_size = 6\n",
    "layers = 2\n",
    "p_gen_aux = [42] + [43,44,45] * layers\n",
    "layers_params = init_transformer_gpt2(vocab_size, D, layers, H, 4*D, N)\n",
    "y= torch.randint(vocab_size, (BS, N+1), device=\"cuda\")\n",
    "mask = torch.ones((BS, N, N), dtype=torch.bool, device=\"cuda\")\n",
    "\n",
    "def print_res_shapes(res):\n",
    "    print(len(res))\n",
    "    for it in res:\n",
    "        print(f'-', len(it))\n",
    "        for p in it:\n",
    "            print(f'--', p.shape, p.reshape(-1)[-3:]) # TODO: modify to check different parts\n",
    "\n",
    "for i, i_mask in enumerate(mask):\n",
    "    mask[i] = torch.tril(i_mask)\n",
    "    #mask[i] = torch.zeros_like(i_mask)\n",
    "#print(mask)\n",
    "\n",
    "res2 = t_loss_bkwd(layers_params, y, mask, None, True, p_gen_aux)\n",
    "#print(res2[1])\n",
    "print_res_shapes(res2[0]) \n",
    "\n",
    "print(f'----XXX----')\n",
    "\n",
    "res3 = t_loss_bkwd2(layers_params, y, mask, None, True, p_gen_aux)\n",
    "#print(res3)\n",
    "print_res_shapes(res3[0]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a318d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=\"\"\n",
    "\n",
    "# t_avg_cross_entropy_loss_bkwd vs t_avg_cross_entropy_loss_bkwd2 on train=True\n",
    "import torch\n",
    "torch.set_printoptions(precision=6)\n",
    "from torch.func import jacrev\n",
    "from model_torch_func import init_transformer_gpt2\n",
    "from model_triton import t_gpt2_forward\n",
    "from loss_and_optimizer_triton import t_avg_cross_entropy_loss_bkwd, t_avg_cross_entropy_loss_bkwd2\n",
    "BS, H, N, D = 2, 2, 5, 4\n",
    "vocab_size = 6\n",
    "layers = 2\n",
    "p_gen_aux = [42] + [43,44,45] * layers\n",
    "layers_params = init_transformer_gpt2(vocab_size, D, layers, H, 4*D, N)\n",
    "y= torch.randint(vocab_size, (BS, N+1), device=\"cpu\")\n",
    "mask = torch.ones((BS, N, N), dtype=torch.bool, device=\"cpu\")\n",
    "\n",
    "y_in = y[:, :-1]\n",
    "y_out = y[:, 1:]\n",
    "logits = t_gpt2_forward(layers_params, y_in, mask, None, True, p_gen_aux) \n",
    "\n",
    "def print_res_shapes(res):\n",
    "    print(len(res))\n",
    "    for it in res:\n",
    "        print(f'-', len(it))\n",
    "        for p in it:\n",
    "            print(f'--', p.shape, p.reshape(-1)[-3:]) # TODO: modify to check different parts\n",
    "\n",
    "for i, i_mask in enumerate(mask):\n",
    "    mask[i] = torch.tril(i_mask)\n",
    "    #mask[i] = torch.zeros_like(i_mask)\n",
    "#print(mask)\n",
    "\n",
    "res2 = t_avg_cross_entropy_loss_bkwd(y_out, logits)\n",
    "print(res2.shape, res2)\n",
    "#print_res_shapes(res2[0]) \n",
    "\n",
    "print(f'----XXX----')\n",
    "\n",
    "res3 = t_avg_cross_entropy_loss_bkwd2(y_out, logits)\n",
    "print(res3.shape, res3)\n",
    "#print_res_shapes(res3[0]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410df231",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
