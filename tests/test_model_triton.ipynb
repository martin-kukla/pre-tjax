{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f0ad15d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_triton\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m seq_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[1;32m      4\u001b[0m vocab_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;66;03m#12000\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from ..model_triton import *\n",
    "\n",
    "seq_len = 32\n",
    "vocab_size = 1000 #12000\n",
    "layers = 1 #12\n",
    "emb_dim= 512\n",
    "nheads = 2 #8\n",
    "ffn_dim = 256\n",
    "params = init_transformer_gpt2(vocab_size, emb_dim, layers, nheads, ffn_dim, seq_len)\n",
    "\n",
    "# Print params if needed\n",
    "# for p_grp_ind, p_grp in enumerate(params):\n",
    "#     for p_ind, p in enumerate(p_grp):\n",
    "#         print(p_grp_ind, p_ind, p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c02766d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# TEST 1 test_tlayer_attn_head_fwd -> works fine\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m attn_head_params \u001b[38;5;241m=\u001b[39m \u001b[43mparams\u001b[49m[\u001b[38;5;241m2\u001b[39m][\u001b[38;5;241m2\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      3\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      4\u001b[0m q \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn((seq_len, emb_dim), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'params' is not defined"
     ]
    }
   ],
   "source": [
    "# TEST 1 test_tlayer_attn_head_fwd -> works fine\n",
    "attn_head_params = params[2][2][1]\n",
    "torch.manual_seed(0)\n",
    "q = torch.randn((seq_len, emb_dim), dtype=torch.float32, device=\"cuda\")\n",
    "k = torch.randn((seq_len, emb_dim), dtype=torch.float32, device=\"cuda\")\n",
    "v = torch.randn((seq_len, emb_dim), dtype=torch.float32, device=\"cuda\")\n",
    "y_mask = torch.tril(torch.ones((seq_len, seq_len), dtype=torch.bool, device=\"cuda\"))\n",
    "#y_mask = torch.unsqueeze(y_mask,0)\n",
    "\n",
    "res1=tlayer_attn_head_fwd(attn_head_params, (q,k,v), y_mask, False)\n",
    "\n",
    "batched_qkv = tuple([torch.unsqueeze(it,0) for it in (q,k,v)])\n",
    "batched_y_mask = torch.unsqueeze(y_mask,0)\n",
    "res2=t_tlayer_attn_head_fwd(attn_head_params, batched_qkv, batched_y_mask, False)[0]\n",
    "torch.allclose(res1, res2, 1e-04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6f3e38e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST 2 test_tlayer_attn_heads_fwd -> numerical differences due to vmap being used in one of them\n",
    "attn_heads_params = params[2][2]\n",
    "torch.manual_seed(0)\n",
    "q = torch.randn((seq_len, emb_dim), dtype=torch.float32, device=\"cuda\")\n",
    "k = torch.randn((seq_len, emb_dim), dtype=torch.float32, device=\"cuda\")\n",
    "v = torch.randn((seq_len, emb_dim), dtype=torch.float32, device=\"cuda\")\n",
    "y_mask = torch.tril(torch.ones((seq_len, seq_len), dtype=torch.bool, device=\"cuda\"))\n",
    "\n",
    "res1=tlayer_attn_heads_fwd(attn_heads_params[:1], (q,k,v), y_mask, False)\n",
    "\n",
    "batched_qkv = tuple([torch.unsqueeze(it,0) for it in (q,k,v)])\n",
    "batched_y_mask = torch.unsqueeze(y_mask,0)\n",
    "res2=t_tlayer_attn_heads_fwd(attn_heads_params, batched_qkv, batched_y_mask, False)[0]\n",
    "torch.allclose(res1, res2, 1e-01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "41e09d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST 3 test_tlayer_attn_fwd -> numerical differences, due to vmap being used\n",
    "attn_fwd_params = params[2][2:-6]\n",
    "torch.manual_seed(0)\n",
    "q = torch.randn((seq_len, emb_dim), dtype=torch.float32, device=\"cuda\")\n",
    "k = torch.randn((seq_len, emb_dim), dtype=torch.float32, device=\"cuda\")\n",
    "v = torch.randn((seq_len, emb_dim), dtype=torch.float32, device=\"cuda\")\n",
    "y_mask = torch.tril(torch.ones((seq_len, seq_len), dtype=torch.bool, device=\"cuda\"))\n",
    "#y_mask = torch.unsqueeze(y_mask,0)\n",
    "\n",
    "res1=tlayer_attn_fwd(attn_fwd_params, (q,k,v), y_mask, False)\n",
    "\n",
    "batched_qkv = tuple([torch.unsqueeze(it,0) for it in (q,k,v)])\n",
    "batched_y_mask = torch.unsqueeze(y_mask,0)\n",
    "res2=t_tlayer_attn_fwd(attn_fwd_params, batched_qkv, batched_y_mask, False)[0]\n",
    "torch.allclose(res1, res2, 1e-01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e5ad7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
