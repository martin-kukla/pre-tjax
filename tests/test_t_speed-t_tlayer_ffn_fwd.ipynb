{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47fc7fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"TRITON_INTERPRET\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80af0a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Torch-Compiled Region: 2/0        14.63%       2.649ms        19.53%       3.536ms     353.617us       0.000us         0.00%      16.520ms       1.652ms            10  \n",
      "                                               aten::mm         2.42%     438.667us         3.24%     585.799us      29.290us      13.922ms        84.28%      13.922ms     696.120us            20  \n",
      "void cutlass::Kernel2<cutlass_80_tensorop_s1688gemm_...         0.00%       0.000us         0.00%       0.000us       0.000us       7.153ms        43.30%       7.153ms     715.284us            10  \n",
      "void cutlass::Kernel2<cutlass_80_tensorop_s1688gemm_...         0.00%       0.000us         0.00%       0.000us       0.000us       6.770ms        40.98%       6.770ms     676.955us            10  \n",
      "                    triton_poi_fused_add_mul_pow_tanh_0         0.56%     101.682us         0.87%     157.523us      15.752us       2.088ms        12.64%       2.088ms     208.787us            10  \n",
      "                    triton_poi_fused_add_mul_pow_tanh_0         0.00%       0.000us         0.00%       0.000us       0.000us       2.088ms        12.64%       2.088ms     208.787us            10  \n",
      "                                 triton_poi_fused_add_1         0.50%      89.762us         0.79%     143.682us      14.368us     509.439us         3.08%     509.439us      50.944us            10  \n",
      "                                 triton_poi_fused_add_1         0.00%       0.000us         0.00%       0.000us       0.000us     509.439us         3.08%     509.439us      50.944us            10  \n",
      "                               TorchDynamo Cache Lookup         0.38%      68.361us         0.38%      68.361us       6.836us       0.000us         0.00%       0.000us       0.000us            10  \n",
      "                                 cudaDeviceGetAttribute         0.05%       9.940us         0.05%       9.940us       0.497us       0.000us         0.00%       0.000us       0.000us            20  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 18.103ms\n",
      "Self CUDA time total: 16.520ms\n",
      "\n",
      "JIT total 0.016771316528320312\n",
      "Naive total 0.03567385673522949\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from model_triton import t_tlayer_ffn_fwd, t_gelu_fwd_\n",
    "\n",
    "BS, N, D = 8, 512, 768\n",
    "FFN = 4 * D\n",
    "aa = torch.randn((BS, N, D), device=\"cuda\")\n",
    "p0 = torch.randn((FFN, D), device=\"cuda\")\n",
    "p1 = torch.randn((FFN,), device=\"cuda\")\n",
    "p2 = torch.randn((D, FFN), device=\"cuda\")\n",
    "p3 = torch.randn((D,), device=\"cuda\")\n",
    "params = (p0, p1, p2, p3)\n",
    "N_RUNS = 10\n",
    "\n",
    "def fn_naive(x):\n",
    "    return t_tlayer_ffn_fwd(params, x, t_gelu_fwd_)\n",
    "fn_jit = torch.compile(fn_naive)\n",
    "# burn it\n",
    "fn_jit(aa) \n",
    "#fn_jit(dloss_dx, aa) \n",
    "#fn_jit(aa, bb) \n",
    "\n",
    "from torch.profiler import profile, record_function, ProfilerActivity, schedule\n",
    "activities = [ProfilerActivity.CPU, ProfilerActivity.CUDA]\n",
    "with profile(activities=activities, record_shapes=True) as prof:\n",
    "    for _ in range(N_RUNS):\n",
    "        result = fn_jit(aa)\n",
    "        #result = fn_jit(dloss_dx, aa)\n",
    "        #result = fn_jit(aa, bb)\n",
    "        \n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n",
    "\n",
    "import time\n",
    "t0 = time.time()\n",
    "for _ in range(N_RUNS):\n",
    "    result = fn_jit(aa)\n",
    "    #result = fn_jit(dloss_dx, aa)\n",
    "    #result = fn_jit(aa, bb)\n",
    "torch.cuda.synchronize()\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(f'JIT total', total)\n",
    "\n",
    "import time\n",
    "t0 = time.time()\n",
    "for _ in range(N_RUNS):\n",
    "    result = fn_naive(aa)\n",
    "    #result = fn_naive(dloss_dx, aa)\n",
    "    #result = fn_naive(aa, bb)\n",
    "torch.cuda.synchronize()\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(f'Naive total', total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ded38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import triton\n",
    "# print(triton.runtime.driver.active.get_current_target())\n",
    "# device = \"cuda\" #triton.runtime.driver.active.get_active_torch_device()\n",
    "# properties = triton.runtime.driver.active.utils.get_device_properties(device)\n",
    "# See https://github.com/triton-lang/triton/issues/5628, and https://github.com/triton-lang/triton/issues/5388\n",
    "# properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc79b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cuda.matmul.allow_tf32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d7000e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0.033469438552856445\n"
     ]
    }
   ],
   "source": [
    "import triton\n",
    "import triton.language as tl\n",
    "\n",
    "from model_triton import gelu_k\n",
    "\n",
    "# This is an incomplete implementation. It makes the assumption that n_programs  \n",
    "# and m_programs are disiable by GROUP_SIZE_M\n",
    "# Assumes allow_tf32 (i.e. torch.backends.cuda.matmul.allow_tf32) being True \n",
    "# Note I overload this function by adding logic for linear layer in it\n",
    "@triton.jit\n",
    "def t_matmul_k(a_ptr, b_ptr, output_ptr, bias_ptr,\n",
    "                a_row_stride, a_col_stride,\n",
    "                b_row_stride, b_col_stride,\n",
    "                output_row_stride, output_col_stride,\n",
    "                n, m, k,\n",
    "                ADD_BIAS: tl.constexpr, ACTIVATION: tl.constexpr, # Overloading matmul with params for linear layer\n",
    "                BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n",
    "                GROUP_SIZE_M: tl.constexpr,\n",
    "                ):\n",
    "    # Matching PyTorch's fp32 dtype ( see https://github.com/triton-lang/triton/issues/4574)\n",
    "    ASM: tl.constexpr = \"cvt.rna.tf32.f32 $0, $1;\"\n",
    "        \n",
    "    pid = tl.program_id(0)\n",
    "    n_programs = tl.cdiv(n, BLOCK_SIZE_N)\n",
    "    m_programs = tl.cdiv(m, BLOCK_SIZE_M)\n",
    "    orig_n_pid = pid // m_programs\n",
    "    orig_m_pid = pid % m_programs\n",
    "       \n",
    "    # TODO T: Fix bug in Grouping to improve L2 Cache hit rate\n",
    "    # TODO T: simplify the grp_id calculations. Expand if m_programs are not divisable by GROUP_SIZE_M\n",
    "    # m_groups = m_programs // GROUP_SIZE_M # assumes m_programs is divisable by GROUP_SIZE_M for now\n",
    "    # n_grp_id = orig_n_pid % (n_programs//m_groups) # assumes n_programs is divisable by GROUP_SIZE_M for now\n",
    "    # m_grp_id = (orig_n_pid * m_groups)//n_programs\n",
    "    # n_pid =  n_grp_id * m_groups + orig_m_pid // GROUP_SIZE_M\n",
    "    # m_pid =  m_grp_id * GROUP_SIZE_M + orig_m_pid % GROUP_SIZE_M\n",
    "    n_pid = orig_n_pid\n",
    "    m_pid = orig_m_pid \n",
    "    \n",
    "    offsets = tl.arange(0, BLOCK_SIZE_K)     \n",
    "    n_offsets = n_pid * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
    "    m_offsets = m_pid * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n",
    "    # TODO T: Do I need modulo n, modulo m operations?    \n",
    "    n_offsets_mod = n_offsets %n\n",
    "    m_offsets_mod = m_offsets %m\n",
    "    \n",
    "    acc = tl.zeros((BLOCK_SIZE_N, BLOCK_SIZE_M), dtype=tl.float32)\n",
    "    for i in range(0, tl.cdiv(k, BLOCK_SIZE_K)):\n",
    "        k_step_offsets = i*BLOCK_SIZE_K + offsets\n",
    "        a_blck_ptr = a_ptr + n_offsets_mod[:,None] * a_row_stride + k_step_offsets[None, :] * a_col_stride\n",
    "        a_blck = tl.load(a_blck_ptr, mask=k_step_offsets[None, :] < k, other=0.0) \n",
    "        b_blck_ptr = b_ptr + k_step_offsets[:,None] * b_row_stride + m_offsets_mod[None, :] * b_col_stride\n",
    "        b_blck = tl.load(b_blck_ptr, mask=k_step_offsets[:, None] < k, other=0.0)\n",
    "\n",
    "        # Matching PyTorch's fp32 dtype ( see https://github.com/triton-lang/triton/issues/4574)\n",
    "        a_blck = tl.inline_asm_elementwise(ASM, \"=r, r\", [a_blck], dtype=tl.float32, is_pure=True, pack=1)\n",
    "        b_blck = tl.inline_asm_elementwise(ASM, \"=r, r\", [b_blck], dtype=tl.float32, is_pure=True, pack=1)\n",
    "        \n",
    "        # To test for double precision (https://github.com/triton-lang/triton/issues/4603)\n",
    "        # Use tf32x3 (slow) below without ASM elementwise casts above \n",
    "        acc = tl.dot(a_blck, b_blck, acc) #, input_precision=\"tf32x3\")\n",
    "    if ADD_BIAS:\n",
    "        bias = tl.load(bias_ptr + m_offsets, mask=m_offsets<m, other=0.0)\n",
    "        acc += bias # Works since Triton's broadcasting follows one of Numpy\n",
    "    if ACTIVATION == \"gelu\":\n",
    "        acc = gelu_k(acc)\n",
    "    output_blck_ptr = output_ptr + n_offsets[:,None] * output_row_stride + m_offsets[None, :] * output_col_stride\n",
    "    output_mask = (n_offsets[:,None] <n) & (m_offsets[None, :]<m)\n",
    "    tl.store(output_blck_ptr, acc, mask=output_mask)\n",
    "\n",
    "from model_triton import t_gelu_fwd\n",
    "def t_tlayer_ffn_fwd_t(layer_params, x:torch.Tensor, activation_fn):\n",
    "    assert activation_fn == t_gelu_fwd\n",
    "    \n",
    "    # FFN1\n",
    "    output_dim = x.shape\n",
    "    x = x.view((-1,x.shape[-1]))\n",
    "    N, K = x.shape\n",
    "    p0 = layer_params[0].t()\n",
    "    K2, M = p0.shape\n",
    "    assert K==K2\n",
    "    assert x.is_contiguous(), \"Matrix A must be contiguous\" # TODO T: why do I need contiguous a?\n",
    "    mid_output = torch.empty((N, M), device=x.device)\n",
    "    grid = lambda META: (triton.cdiv(N, META['BLOCK_SIZE_N']) * triton.cdiv(M, META['BLOCK_SIZE_M']), )\n",
    "\n",
    "    # One needs to tune params below depending on the size of input tensors \n",
    "    BLOCK_SIZE_N = 128    \n",
    "    BLOCK_SIZE_M = 64\n",
    "    BLOCK_SIZE_K = 32\n",
    "    GROUP_SIZE_M = 8\n",
    "    num_stages = 3\n",
    "    num_warps = 8\n",
    "    assert triton.cdiv(N, BLOCK_SIZE_N) % GROUP_SIZE_M == 0, \"Limtation of implementation\" # TODO T: Complete implementation\n",
    "    assert triton.cdiv(M, BLOCK_SIZE_M) % GROUP_SIZE_M == 0, \"Limtation of implementation\" # TODO T: Complete implementation\n",
    "\n",
    "    t_matmul_k[grid](\n",
    "        x, p0, mid_output, layer_params[1], \n",
    "        x.stride(0), x.stride(1), p0.stride(0), p0.stride(1), mid_output.stride(0), mid_output.stride(1), \n",
    "        N, M, K, ADD_BIAS=True, ACTIVATION = \"gelu\", \n",
    "        BLOCK_SIZE_N=BLOCK_SIZE_N, BLOCK_SIZE_M=BLOCK_SIZE_M, BLOCK_SIZE_K=BLOCK_SIZE_K, \n",
    "        GROUP_SIZE_M=GROUP_SIZE_M, num_stages=num_stages, num_warps=num_warps)\n",
    "\n",
    "    # FFN2: Note the swap of dimensions (K and M)\n",
    "    p2 = layer_params[2].t()\n",
    "    assert mid_output.is_contiguous(), \"Matrix A must be contiguous\" # TODO T: why do I need contiguous a?\n",
    "    output = torch.empty((N, K), device=x.device) \n",
    "    \n",
    "    # One needs to tune params below depending on the size of input tensors \n",
    "    BLOCK_SIZE_N = 128    \n",
    "    BLOCK_SIZE_M = 64\n",
    "    BLOCK_SIZE_K = 32\n",
    "    GROUP_SIZE_M = 4 # TODO T: Bump up once we fix grouping?\n",
    "    num_stages = 3\n",
    "    num_warps = 8\n",
    "    assert triton.cdiv(N, BLOCK_SIZE_N) % GROUP_SIZE_M == 0, \"Limtation of implementation\" # TODO T: Complete implementation\n",
    "    assert triton.cdiv(K, BLOCK_SIZE_M) % GROUP_SIZE_M == 0, \"Limtation of implementation\" # TODO T: Complete implementation\n",
    "\n",
    "    \n",
    "    t_matmul_k[grid](\n",
    "        mid_output, p2, output, layer_params[3],\n",
    "        mid_output.stride(0), mid_output.stride(1), p2.stride(0), p2.stride(1), output.stride(0), output.stride(1), \n",
    "        N, K, M, ADD_BIAS=True, ACTIVATION = None, \n",
    "        BLOCK_SIZE_N=BLOCK_SIZE_N, BLOCK_SIZE_M=BLOCK_SIZE_M, BLOCK_SIZE_K=BLOCK_SIZE_K, \n",
    "        GROUP_SIZE_M=GROUP_SIZE_M, num_stages=num_stages, num_warps=num_warps)\n",
    "    \n",
    "    \n",
    "    return output.view(output_dim)\n",
    "\n",
    "params_t = (params[0].t(), params[1], params[2].t(), params[3])\n",
    "def fn_t(x):\n",
    "    return t_tlayer_ffn_fwd_t(params, x, t_gelu_fwd)\n",
    "\n",
    "# from torch.profiler import profile, record_function, ProfilerActivity, schedule\n",
    "# activities = [ProfilerActivity.CPU, ProfilerActivity.CUDA]\n",
    "# with profile(activities=activities, record_shapes=True) as prof:\n",
    "#     for _ in range(N):\n",
    "#         #result = fn_t(aa)\n",
    "#         #result = fn_t(dloss_dx, aa)\n",
    "#         result = fn_t(aa, bb)\n",
    "# print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=20))\n",
    "\n",
    "fn_t(aa)\n",
    "\n",
    "import time\n",
    "t0 = time.time()\n",
    "for _ in range(N_RUNS):\n",
    "    result = fn_t(aa)\n",
    "    #result = fn_t(dloss_dx, aa)\n",
    "#    result = fn_t(aa, bb)\n",
    "torch.cuda.synchronize()\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(f'total', total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78722f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res1 torch.Size([8, 512, 768]) tensor([[[-2044.2085,  -628.0964,   509.8030,  ...,  2506.4290,\n",
      "           1714.4983,   438.8811],\n",
      "         [  619.1483,   970.4095,  -213.6661,  ...,  -597.3315,\n",
      "            349.2857,  -900.2518],\n",
      "         [  -33.1344,  -572.9765, -1567.0997,  ...,   282.1264,\n",
      "           -141.3630,  -224.8687],\n",
      "         [  138.4579,  1366.9819,  -797.5416,  ...,  1850.9603,\n",
      "           -351.1953,   189.9967]],\n",
      "\n",
      "        [[-1056.1564,  -259.5440,  -617.0130,  ...,  -978.8630,\n",
      "           2527.1841,  2615.4475],\n",
      "         [ 1095.5505,  -182.4461, -1122.1571,  ...,  1494.2449,\n",
      "           1704.5344,   807.6739],\n",
      "         [   54.2482, -1061.6094,  -250.8617,  ...,   645.6375,\n",
      "            603.7654,  1200.8158],\n",
      "         [  236.9339,   184.6860,   805.4480,  ...,  1364.8855,\n",
      "           1491.6332,   -32.8355]],\n",
      "\n",
      "        [[-1305.0312,    50.8062,   524.9065,  ...,   187.7160,\n",
      "           1025.1987,  1229.1498],\n",
      "         [ 1321.0454,  -389.5916, -2208.6802,  ...,   801.3989,\n",
      "            486.5822, -1251.5345],\n",
      "         [ -512.3868, -1334.3361, -1580.1539,  ...,  1460.9650,\n",
      "           -355.4827,  2307.2617],\n",
      "         [ 1874.5521,  1182.8024,  -494.4030,  ...,  1813.4751,\n",
      "             29.3799,   927.1111]],\n",
      "\n",
      "        [[ -372.1574,   537.0271,  -649.2274,  ...,  -116.9518,\n",
      "           1840.8069,  1737.3756],\n",
      "         [ -550.8344,   657.9885,  -919.1539,  ...,   835.6646,\n",
      "           1133.9266,   747.3923],\n",
      "         [ -566.1650,   172.0459, -1380.7362,  ...,   996.9174,\n",
      "            800.2026,   515.6531],\n",
      "         [  106.2325,  -338.0133, -1471.9302,  ...,   931.8419,\n",
      "           -629.4396,  -202.2982]]], device='cuda:0')\n",
      "res2 torch.Size([8, 512, 768]) tensor([[[-2044.2085,  -628.0964,   509.8030,  ...,  2506.4290,\n",
      "           1714.4983,   438.8811],\n",
      "         [  619.1483,   970.4095,  -213.6661,  ...,  -597.3315,\n",
      "            349.2857,  -900.2518],\n",
      "         [  -33.1344,  -572.9765, -1567.0997,  ...,   282.1264,\n",
      "           -141.3630,  -224.8687],\n",
      "         [  138.4579,  1366.9819,  -797.5416,  ...,  1850.9603,\n",
      "           -351.1953,   189.9967]],\n",
      "\n",
      "        [[-1056.1564,  -259.5440,  -617.0130,  ...,  -978.8630,\n",
      "           2527.1841,  2615.4475],\n",
      "         [ 1095.5505,  -182.4461, -1122.1571,  ...,  1494.2449,\n",
      "           1704.5344,   807.6739],\n",
      "         [   54.2482, -1061.6094,  -250.8617,  ...,   645.6375,\n",
      "            603.7654,  1200.8158],\n",
      "         [  236.9339,   184.6860,   805.4480,  ...,  1364.8855,\n",
      "           1491.6332,   -32.8355]],\n",
      "\n",
      "        [[-1305.0312,    50.8062,   524.9065,  ...,   187.7160,\n",
      "           1025.1987,  1229.1498],\n",
      "         [ 1321.0454,  -389.5916, -2208.6802,  ...,   801.3989,\n",
      "            486.5822, -1251.5345],\n",
      "         [ -512.3868, -1334.3361, -1580.1539,  ...,  1460.9650,\n",
      "           -355.4827,  2307.2617],\n",
      "         [ 1874.5521,  1182.8024,  -494.4030,  ...,  1813.4751,\n",
      "             29.3799,   927.1111]],\n",
      "\n",
      "        [[ -372.1574,   537.0271,  -649.2274,  ...,  -116.9518,\n",
      "           1840.8069,  1737.3756],\n",
      "         [ -550.8344,   657.9885,  -919.1539,  ...,   835.6646,\n",
      "           1133.9266,   747.3923],\n",
      "         [ -566.1650,   172.0459, -1380.7362,  ...,   996.9174,\n",
      "            800.2026,   515.6531],\n",
      "         [  106.2325,  -338.0133, -1471.9302,  ...,   931.8419,\n",
      "           -629.4396,  -202.2982]]], device='cuda:0')\n",
      "---\n",
      "res1 tensor([[[  806.7870,  -659.9079, -2256.1492,  ...,  1871.4333,\n",
      "            154.3370,  2347.8606],\n",
      "         [ -486.3959,  -141.9925, -2118.4102,  ...,  -285.0129,\n",
      "           1246.5275,  -327.0139],\n",
      "         [ -217.0149,   521.9933,   821.2365,  ...,  -639.7745,\n",
      "             93.8100,   105.6183],\n",
      "         [ -383.9390,  -436.9960,  -149.3036,  ...,  1796.4233,\n",
      "            142.0155,   -86.3561]],\n",
      "\n",
      "        [[ -223.7374,    44.4758,  -169.7346,  ...,  1023.4318,\n",
      "           -550.7454,   396.4361],\n",
      "         [-2050.9795,    13.9195, -2176.5801,  ...,  1785.9008,\n",
      "           1117.2544,  -646.1097],\n",
      "         [-2050.9253, -1015.2947, -1314.4299,  ...,   513.4145,\n",
      "           1262.1289,   458.1997],\n",
      "         [ -900.3217,  -524.9344,  1054.9460,  ...,  -106.1986,\n",
      "           -466.1894,  -488.9183]],\n",
      "\n",
      "        [[  580.6948,   966.5674,   509.4048,  ...,  1677.4725,\n",
      "           1184.5623,  1401.1692],\n",
      "         [ -591.5486,   281.3193,   231.3181,  ...,  1188.4274,\n",
      "           -763.1324,   389.1889],\n",
      "         [  686.0462,   910.8742, -1430.0630,  ...,  1254.9763,\n",
      "            -69.8343,   104.4517],\n",
      "         [ -760.9132,   246.9183,   343.2949,  ...,  1815.3602,\n",
      "           2108.0393,   892.6194]],\n",
      "\n",
      "        [[ 1281.8043,  -648.8613, -1104.5225,  ...,   786.1887,\n",
      "           1199.3927,  1732.4021],\n",
      "         [  181.1745, -1269.2993,  -789.9881,  ...,  -721.7990,\n",
      "            391.0327,  1265.8047],\n",
      "         [  154.1574,  -122.6439, -2264.9399,  ...,  1193.1385,\n",
      "           -526.4769,   783.4286],\n",
      "         [-1004.2841,   256.0002,   302.3167,  ...,  -380.8195,\n",
      "            -36.5112,  1460.8086]]], device='cuda:0')\n",
      "res2 tensor([[[  806.7870,  -659.9079, -2256.1492,  ...,  1871.4333,\n",
      "            154.3370,  2347.8606],\n",
      "         [ -486.3959,  -141.9925, -2118.4102,  ...,  -285.0129,\n",
      "           1246.5275,  -327.0139],\n",
      "         [ -217.0149,   521.9933,   821.2365,  ...,  -639.7745,\n",
      "             93.8100,   105.6183],\n",
      "         [ -383.9390,  -436.9960,  -149.3036,  ...,  1796.4233,\n",
      "            142.0155,   -86.3561]],\n",
      "\n",
      "        [[ -223.7374,    44.4758,  -169.7346,  ...,  1023.4318,\n",
      "           -550.7454,   396.4361],\n",
      "         [-2050.9795,    13.9195, -2176.5801,  ...,  1785.9008,\n",
      "           1117.2544,  -646.1097],\n",
      "         [-2050.9253, -1015.2947, -1314.4299,  ...,   513.4145,\n",
      "           1262.1289,   458.1997],\n",
      "         [ -900.3217,  -524.9344,  1054.9460,  ...,  -106.1986,\n",
      "           -466.1894,  -488.9183]],\n",
      "\n",
      "        [[  580.6948,   966.5674,   509.4048,  ...,  1677.4725,\n",
      "           1184.5623,  1401.1692],\n",
      "         [ -591.5486,   281.3193,   231.3181,  ...,  1188.4274,\n",
      "           -763.1324,   389.1889],\n",
      "         [  686.0462,   910.8742, -1430.0630,  ...,  1254.9763,\n",
      "            -69.8343,   104.4517],\n",
      "         [ -760.9132,   246.9183,   343.2949,  ...,  1815.3602,\n",
      "           2108.0393,   892.6194]],\n",
      "\n",
      "        [[ 1281.8043,  -648.8613, -1104.5225,  ...,   786.1887,\n",
      "           1199.3927,  1732.4021],\n",
      "         [  181.1745, -1269.2993,  -789.9881,  ...,  -721.7990,\n",
      "            391.0327,  1265.8047],\n",
      "         [  154.1574,  -122.6439, -2264.9399,  ...,  1193.1385,\n",
      "           -526.4769,   783.4286],\n",
      "         [-1004.2841,   256.0002,   302.3167,  ...,  -380.8195,\n",
      "            -36.5112,  1460.8086]]], device='cuda:0')\n",
      "------\n",
      "res1 tensor([[[  806.7870,  -659.9079, -2256.1492,  ...,  1871.4333,\n",
      "            154.3370,  2347.8606],\n",
      "         [ -486.3959,  -141.9925, -2118.4102,  ...,  -285.0129,\n",
      "           1246.5275,  -327.0139],\n",
      "         [ -217.0149,   521.9933,   821.2365,  ...,  -639.7745,\n",
      "             93.8100,   105.6183],\n",
      "         [ -383.9390,  -436.9960,  -149.3036,  ...,  1796.4233,\n",
      "            142.0155,   -86.3561]],\n",
      "\n",
      "        [[ -223.7374,    44.4758,  -169.7346,  ...,  1023.4318,\n",
      "           -550.7454,   396.4361],\n",
      "         [-2050.9795,    13.9195, -2176.5801,  ...,  1785.9008,\n",
      "           1117.2544,  -646.1097],\n",
      "         [-2050.9253, -1015.2947, -1314.4299,  ...,   513.4145,\n",
      "           1262.1289,   458.1997],\n",
      "         [ -900.3217,  -524.9344,  1054.9460,  ...,  -106.1986,\n",
      "           -466.1894,  -488.9183]],\n",
      "\n",
      "        [[  580.6948,   966.5674,   509.4048,  ...,  1677.4725,\n",
      "           1184.5623,  1401.1692],\n",
      "         [ -591.5486,   281.3193,   231.3181,  ...,  1188.4274,\n",
      "           -763.1324,   389.1889],\n",
      "         [  686.0462,   910.8742, -1430.0630,  ...,  1254.9763,\n",
      "            -69.8343,   104.4517],\n",
      "         [ -760.9132,   246.9183,   343.2949,  ...,  1815.3602,\n",
      "           2108.0393,   892.6194]],\n",
      "\n",
      "        [[ 1281.8043,  -648.8613, -1104.5225,  ...,   786.1887,\n",
      "           1199.3927,  1732.4021],\n",
      "         [  181.1745, -1269.2993,  -789.9881,  ...,  -721.7990,\n",
      "            391.0327,  1265.8047],\n",
      "         [  154.1574,  -122.6439, -2264.9399,  ...,  1193.1385,\n",
      "           -526.4769,   783.4286],\n",
      "         [-1004.2841,   256.0002,   302.3167,  ...,  -380.8195,\n",
      "            -36.5112,  1460.8086]]], device='cuda:0')\n",
      "res2 tensor([[[  806.7870,  -659.9079, -2256.1492,  ...,  1871.4333,\n",
      "            154.3370,  2347.8606],\n",
      "         [ -486.3959,  -141.9925, -2118.4102,  ...,  -285.0129,\n",
      "           1246.5275,  -327.0139],\n",
      "         [ -217.0149,   521.9933,   821.2365,  ...,  -639.7745,\n",
      "             93.8100,   105.6183],\n",
      "         [ -383.9390,  -436.9960,  -149.3036,  ...,  1796.4233,\n",
      "            142.0155,   -86.3561]],\n",
      "\n",
      "        [[ -223.7374,    44.4758,  -169.7346,  ...,  1023.4318,\n",
      "           -550.7454,   396.4361],\n",
      "         [-2050.9795,    13.9195, -2176.5801,  ...,  1785.9008,\n",
      "           1117.2544,  -646.1097],\n",
      "         [-2050.9253, -1015.2947, -1314.4299,  ...,   513.4145,\n",
      "           1262.1289,   458.1997],\n",
      "         [ -900.3217,  -524.9344,  1054.9460,  ...,  -106.1986,\n",
      "           -466.1894,  -488.9183]],\n",
      "\n",
      "        [[  580.6948,   966.5674,   509.4048,  ...,  1677.4725,\n",
      "           1184.5623,  1401.1692],\n",
      "         [ -591.5486,   281.3193,   231.3181,  ...,  1188.4274,\n",
      "           -763.1324,   389.1889],\n",
      "         [  686.0462,   910.8742, -1430.0630,  ...,  1254.9763,\n",
      "            -69.8343,   104.4517],\n",
      "         [ -760.9132,   246.9183,   343.2949,  ...,  1815.3602,\n",
      "           2108.0393,   892.6194]],\n",
      "\n",
      "        [[ 1281.8043,  -648.8613, -1104.5225,  ...,   786.1887,\n",
      "           1199.3927,  1732.4021],\n",
      "         [  181.1745, -1269.2993,  -789.9881,  ...,  -721.7990,\n",
      "            391.0327,  1265.8047],\n",
      "         [  154.1574,  -122.6439, -2264.9399,  ...,  1193.1385,\n",
      "           -526.4769,   783.4286],\n",
      "         [-1004.2841,   256.0002,   302.3167,  ...,  -380.8195,\n",
      "            -36.5112,  1460.8086]]], device='cuda:0')\n",
      "tensor([[[-2044.2085,  -628.0964,   509.8030,  ...,  2506.4290,\n",
      "           1714.4983,   438.8811],\n",
      "         [  619.1483,   970.4095,  -213.6661,  ...,  -597.3315,\n",
      "            349.2857,  -900.2518],\n",
      "         [  -33.1344,  -572.9765, -1567.0997,  ...,   282.1264,\n",
      "           -141.3630,  -224.8687],\n",
      "         ...,\n",
      "         [ -305.7758,  -598.2174,  -688.4333,  ...,   887.3094,\n",
      "           2893.9248,  -328.0294],\n",
      "         [-1030.9225,   141.8037,   703.0912,  ...,  1919.9558,\n",
      "            479.8187,  1151.8561],\n",
      "         [  931.1440,    25.9648,  -151.3364,  ...,   896.9427,\n",
      "           -181.0362,   361.5302]],\n",
      "\n",
      "        [[-1056.1564,  -259.5440,  -617.0130,  ...,  -978.8630,\n",
      "           2527.1841,  2615.4475],\n",
      "         [ 1095.5505,  -182.4461, -1122.1571,  ...,  1494.2449,\n",
      "           1704.5344,   807.6739],\n",
      "         [   54.2482, -1061.6094,  -250.8617,  ...,   645.6375,\n",
      "            603.7654,  1200.8158],\n",
      "         ...,\n",
      "         [ 1027.9082,   388.5542, -1760.2000,  ...,  1115.8271,\n",
      "           2292.8943,  -874.0480],\n",
      "         [  711.1647,   539.8949,   303.0235,  ...,  2052.0793,\n",
      "            945.2035,   195.5422],\n",
      "         [ -249.5855, -1552.8505,   213.9572,  ...,   731.4401,\n",
      "           -711.8446,   -64.5906]],\n",
      "\n",
      "        [[-1305.0312,    50.8062,   524.9065,  ...,   187.7160,\n",
      "           1025.1987,  1229.1498],\n",
      "         [ 1321.0454,  -389.5916, -2208.6802,  ...,   801.3989,\n",
      "            486.5822, -1251.5345],\n",
      "         [ -512.3868, -1334.3361, -1580.1539,  ...,  1460.9650,\n",
      "           -355.4827,  2307.2617],\n",
      "         ...,\n",
      "         [  272.5098,   960.0861,  -423.0338,  ...,   958.4532,\n",
      "            -67.8875,  -685.9850],\n",
      "         [ 1076.7391,  -358.6599,  -579.3442,  ...,   480.0899,\n",
      "            831.5842,  1915.8657],\n",
      "         [ -635.6608,   657.5330, -2987.3313,  ...,   645.6638,\n",
      "           -127.4116,  1816.3755]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  759.1025,  1078.7628,   -15.5226,  ...,   732.0506,\n",
      "          -1012.8447,   791.8276],\n",
      "         [ -363.4723, -1437.2145,  -816.2613,  ...,  1055.0674,\n",
      "           -352.9359,  -640.4512],\n",
      "         [ -492.2820,   335.0513,  -939.2220,  ...,  -679.7349,\n",
      "            770.3550,   875.1805],\n",
      "         ...,\n",
      "         [-2050.9795,    13.9195, -2176.5801,  ...,  1785.9008,\n",
      "           1117.2544,  -646.1097],\n",
      "         [-2050.9253, -1015.2947, -1314.4299,  ...,   513.4145,\n",
      "           1262.1289,   458.1997],\n",
      "         [ -900.3217,  -524.9344,  1054.9460,  ...,  -106.1986,\n",
      "           -466.1894,  -488.9183]],\n",
      "\n",
      "        [[ -148.7834,   288.0462, -1287.3854,  ...,  1573.7283,\n",
      "            895.0417,   620.5816],\n",
      "         [-1276.9611,   201.2530,  1202.4080,  ...,  1250.5952,\n",
      "           -322.9691,  -171.5168],\n",
      "         [  990.5188,  1222.9434,  -251.5096,  ...,   851.4562,\n",
      "           1280.7598, -1036.5791],\n",
      "         ...,\n",
      "         [ -591.5486,   281.3193,   231.3181,  ...,  1188.4274,\n",
      "           -763.1324,   389.1889],\n",
      "         [  686.0462,   910.8742, -1430.0630,  ...,  1254.9763,\n",
      "            -69.8343,   104.4517],\n",
      "         [ -760.9132,   246.9183,   343.2949,  ...,  1815.3602,\n",
      "           2108.0393,   892.6194]],\n",
      "\n",
      "        [[ -300.0906,  1212.4235, -1900.3066,  ...,   596.0470,\n",
      "            726.0355,  -722.2348],\n",
      "         [  940.2563,   308.4017, -1613.0853,  ...,   265.5887,\n",
      "           1261.6071,  1222.2239],\n",
      "         [   58.4837,     3.9728,   689.1987,  ...,  -659.8209,\n",
      "            871.3577,  1214.2913],\n",
      "         ...,\n",
      "         [  181.1745, -1269.2993,  -789.9881,  ...,  -721.7990,\n",
      "            391.0327,  1265.8047],\n",
      "         [  154.1574,  -122.6439, -2264.9399,  ...,  1193.1385,\n",
      "           -526.4769,   783.4286],\n",
      "         [-1004.2841,   256.0002,   302.3167,  ...,  -380.8195,\n",
      "            -36.5112,  1460.8086]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# allow_tf32_saved = torch.backends.cuda.matmul.allow_tf32\n",
    "# torch.backends.cuda.matmul.allow_tf32 = False\n",
    "# d_ref = torch.mm(aa.to(torch.double), bb.to(torch.double))\n",
    "# torch.backends.cuda.matmul.allow_tf32 = allow_tf32_saved\n",
    "\n",
    "res1 = fn_jit(aa)\n",
    "#res1 = fn_jit(dloss_dx, aa)\n",
    "#res1 = fn_jit(aa, bb)\n",
    "res2 = fn_t(aa)\n",
    "#res2 = fn_t(dloss_dx, aa)\n",
    "#res2 = fn_t(aa, bb)\n",
    "\n",
    "#print(f'd_ref', d_ref[:4, :4])\n",
    "print(f'res1', res1.shape, res1[:4, :4])\n",
    "print(f'res2', res2.shape, res2[:4, :4])\n",
    "print(f'---')\n",
    "#print(f'd_ref', d_ref[-4:, -4:])\n",
    "print(f'res1', res1[-4:, -4:])\n",
    "print(f'res2', res2[-4:, -4:])\n",
    "print(f'------')\n",
    "#print('aa', aa)\n",
    "#print('bb', bb)\n",
    "#print(f'aa[0] * b[:,0]', aa[0] * bb[:,0])\n",
    "#assert torch.allclose(res1, res2, atol=1e-2)\n",
    "assert torch.allclose(res1, res2, atol=1.7e-2, rtol=0), (res1.shape, res2.shape, res1[-4:, -4:], res2[-4:, -4:])\n",
    "#assert torch.allclose(res1, res2), (res1.shape, res2.shape, res1[0:4, 0:4], res2[0:4, 0:4])\n",
    "print(f'res1', res1[-4:, -4:])\n",
    "print(f'res2', res2[-4:, -4:])\n",
    "\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5179e875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_matmul:\n",
      "       N      M      K    Triton     Torch\n",
      "0  768.0  768.0  768.0  3.092352  1.659744\n"
     ]
    }
   ],
   "source": [
    "@triton.testing.perf_report(\n",
    "    triton.testing.Benchmark(\n",
    "        x_names=['N', 'M', 'K'],  # Argument names to use as an x-axis for the plot.\n",
    "        x_vals=[768],\n",
    "        #x_vals=[128 * i for i in range(2, 33)],  # Different possible values for `x_name`.\n",
    "        #x_log=True,  # x axis is logarithmic.\n",
    "        line_arg='provider',  # Argument name whose value corresponds to a different line in the plot.\n",
    "        line_vals=['triton', 'torch'],  # Possible values for `line_arg`.\n",
    "        line_names=['Triton', 'Torch'],  # Label name for the lines.\n",
    "        styles=[('blue', '-'), ('green', '-')],  # Line styles.\n",
    "        ylabel='ms',  # Label name for the y-axis.\n",
    "        plot_name='t_tlayer_ffn_fwd',  # Name for the plot. Used also as a file name for saving the plot.\n",
    "        args={},  # Values for function arguments not in `x_names` and `y_name`.\n",
    "        # TODO T: Use real M i.e. \n",
    "    ))\n",
    "def benchmark(N, M, K, provider):\n",
    "    #dloss_dx = torch.rand(M, N, device=\"cuda\", dtype=torch.float32)    \n",
    "    #x = torch.rand(M, N, device=\"cuda\", dtype=torch.float32)\n",
    "    BS, N, D = 8, 512, 768\n",
    "    x = torch.randn((BS, N, D), device=\"cuda\")\n",
    "#     a = torch.rand(N, K, device=\"cuda\", dtype=torch.float32)\n",
    "#     b = torch.rand(K, M, device=\"cuda\", dtype=torch.float32)    \n",
    "    quantiles = [0.5, 0.2, 0.8]\n",
    "    if provider == 'torch':\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: fn_jit(x), quantiles=quantiles)\n",
    "        #ms, min_ms, max_ms = triton.testing.do_bench(lambda: fn_jit(dloss_dx, x), quantiles=quantiles)\n",
    "        #ms, min_ms, max_ms = triton.testing.do_bench(lambda: fn_jit(aa, bb), quantiles=quantiles)\n",
    "        #ms, min_ms, max_ms = triton.testing.do_bench(lambda: fn_t(aa, bb), quantiles=quantiles)\n",
    "    if provider == 'triton':\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: fn_t(x), quantiles=quantiles)        \n",
    "        #ms, min_ms, max_ms = triton.testing.do_bench(lambda: fn_t(dloss_dx, x), quantiles=quantiles)\n",
    "        #ms, min_ms, max_ms = triton.testing.do_bench(lambda: fn_t(aa, bb), quantiles=quantiles)\n",
    "    #if provider == 'naive':\n",
    "    #    #ms, min_ms, max_ms = triton.testing.do_bench(lambda: fn_naive(x), quantiles=quantiles)\n",
    "    #    ms, min_ms, max_ms = triton.testing.do_bench(lambda: fn_naive(dloss_dx, x), quantiles=quantiles)\n",
    "    #perf = lambda ms: 2 * M * N * K * 1e-12 / (ms * 1e-3) # TODO XXX: investigate whether this is right. In the tutorial they operate on different dtype\n",
    "    perf = lambda ms: ms\n",
    "    return perf(ms), perf(max_ms), perf(min_ms)\n",
    "benchmark.run(print_data=True, show_plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894e4143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.get_device_properties(\"cuda\"))\n",
    "from triton.runtime import driver\n",
    "device = torch.cuda.current_device()\n",
    "properties = driver.active.utils.get_device_properties(device)\n",
    "NUM_SM = properties[\"multiprocessor_count\"]\n",
    "SIZE_SMEM = properties[\"max_shared_mem\"]\n",
    "NUM_REGS = properties[\"max_num_regs\"]\n",
    "WARP_SIZE = properties[\"warpSize\"] # Not 64 as A100\n",
    "properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0894085",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_stages = 4 if SIZE_SMEM > 200000 else 2\n",
    "num_warps = 8\n",
    "print(f'num_stages', num_stages, 'num_warps', num_warps)\n",
    "x_2d = aa.reshape((-1, aa.shape[-1])) # TODO T: without this reshape, this func is 2times faster\n",
    "n_rows, n_cols = x_2d.shape\n",
    "BLOCK_SIZE = triton.next_power_of_2(n_cols) \n",
    "output = torch.empty_like(x_2d)\n",
    "\n",
    "dloss_dx_2d = torch.randn_like(x_2d)\n",
    "kernel = t_log_softmax_bkwd2_k.warmup(dloss_dx_2d, x_2d, output, dloss_dx_2d.stride(0), x_2d.stride(0), output.stride(0), n_rows, n_cols, BLOCK_SIZE=BLOCK_SIZE,\n",
    "                                    num_stages=num_stages, num_warps=num_warps, grid=(1, ))\n",
    "#kernel = t_log_softmax_fwd_k.warmup(x_2d, output, x_2d.stride(0), output.stride(0), n_rows, n_cols, BLOCK_SIZE=BLOCK_SIZE,\n",
    "#                                   num_stages=num_stages, num_warps=num_warps, grid=(1, ))\n",
    "kernel._init_handles()\n",
    "n_regs = kernel.n_regs\n",
    "size_smem = kernel.metadata.shared\n",
    "print(f'n_regs', n_regs, 'size_smem', size_smem)\n",
    "\n",
    "occupancy = NUM_REGS // (n_regs * WARP_SIZE * num_warps)\n",
    "print(f'occupancy', occupancy, SIZE_SMEM // size_smem)\n",
    "occupancy = min(occupancy, SIZE_SMEM // size_smem)\n",
    "num_programs = NUM_SM * occupancy\n",
    "print(f'num_programs', num_programs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a78d533",
   "metadata": {},
   "outputs": [],
   "source": [
    "32\n",
    "2080\n",
    "4128\n",
    "6176"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
