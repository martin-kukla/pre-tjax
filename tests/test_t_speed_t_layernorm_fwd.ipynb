{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89d3acce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                           Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-----------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                          Torch-Compiled Region        95.63%       2.069ms        98.27%       2.127ms       2.127ms       0.000us         0.00%      52.238us      52.238us             1  \n",
      "    triton_per_fused_add_div_mean_mul_std_sub_0         1.34%      28.990us         2.64%      57.101us      57.101us      52.238us       100.00%      52.238us      52.238us             1  \n",
      "                                        triton_         0.00%       0.000us         0.00%       0.000us       0.000us      52.238us       100.00%      52.238us      52.238us             1  \n",
      "                       TorchDynamo Cache Lookup         1.24%      26.880us         1.24%      26.880us      26.880us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                 cuLaunchKernel         1.30%      28.111us         1.30%      28.111us      28.111us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                          cudaDeviceSynchronize         0.49%      10.600us         0.49%      10.600us      10.600us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "-----------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.164ms\n",
      "Self CUDA time total: 52.238us\n",
      "\n",
      "JIT total 0.0007064342498779297\n",
      "Naive total 0.0395197868347168\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from model_triton import *\n",
    "\n",
    "#dloss_dx = torch.randn((2, 512, 3072), device=\"cuda\")\n",
    "#Two shapes are being used: [8, 12, 512, 512], and 4096, 35374\n",
    "layer_params = (torch.randn((768), device=\"cuda\"), torch.randn((768), device=\"cuda\"))\n",
    "#aa = torch.randn((2, 768), device=\"cuda\")\n",
    "aa = torch.randn((8, 512, 768), device=\"cuda\")\n",
    "#aa = torch.randn((4096, 35374), device=\"cuda\")\n",
    "#aa = aa.view(-1)\n",
    "N = 1 #100\n",
    "\n",
    "from functools import partial\n",
    "def fn_naive(x):\n",
    "    return t_layernorm_fwd(layer_params, x)\n",
    "fn_jit = torch.compile(fn_naive)\n",
    "# burn it\n",
    "fn_jit(aa) \n",
    "#fn_jit(dloss_dx, aa) \n",
    "\n",
    "from torch.profiler import profile, record_function, ProfilerActivity, schedule\n",
    "activities = [ProfilerActivity.CPU, ProfilerActivity.CUDA]\n",
    "with profile(activities=activities, record_shapes=True) as prof:\n",
    "    for _ in range(N):\n",
    "        result = fn_jit(aa)\n",
    "        #result = fn_jit(dloss_dx, aa)\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n",
    "\n",
    "import time\n",
    "t0 = time.time()\n",
    "for _ in range(N):\n",
    "    result = fn_jit(aa)\n",
    "    #result = fn_jit(dloss_dx, aa)\n",
    "torch.cuda.synchronize()\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(f'JIT total', total)\n",
    "\n",
    "import time\n",
    "t0 = time.time()\n",
    "for _ in range(N):\n",
    "    result = fn_naive(aa)\n",
    "    #result = fn_naive(dloss_dx, aa)\n",
    "torch.cuda.synchronize()\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(f'Naive total', total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3146f203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import triton\n",
    "# print(triton.runtime.driver.active.get_current_target())\n",
    "# device = \"cuda\" #triton.runtime.driver.active.get_active_torch_device()\n",
    "# properties = triton.runtime.driver.active.utils.get_device_properties(device)\n",
    "# See https://github.com/triton-lang/triton/issues/5628, and https://github.com/triton-lang/triton/issues/5388\n",
    "# properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b797169e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                     Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "        t_layernorm_fwd_k         0.00%       0.000us         0.00%       0.000us       0.000us      55.136us       100.00%      55.136us      55.136us             1  \n",
      "            aten::reshape         0.58%      10.810us         2.54%      47.720us      23.860us       0.000us         0.00%       0.000us       0.000us             2  \n",
      "               aten::view         1.97%      36.910us         1.97%      36.910us      18.455us       0.000us         0.00%       0.000us       0.000us             2  \n",
      "         aten::empty_like         0.72%      13.510us        95.84%       1.800ms       1.800ms       0.000us         0.00%       0.000us       0.000us             1  \n",
      "      aten::empty_strided        95.12%       1.787ms        95.12%       1.787ms       1.787ms       0.000us         0.00%       0.000us       0.000us             1  \n",
      "           cuLaunchKernel         1.15%      21.540us         1.15%      21.540us      21.540us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "    cudaDeviceSynchronize         0.47%       8.851us         0.47%       8.851us       8.851us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.878ms\n",
      "Self CUDA time total: 55.136us\n",
      "\n",
      "total 0.0004200935363769531\n"
     ]
    }
   ],
   "source": [
    "import triton\n",
    "import triton.language as tl\n",
    "\n",
    "# Note that the kernel assumes that n_cols < BLOCK_SIZE\n",
    "@triton.jit\n",
    "def t_layernorm_fwd_k(param1_ptr,\n",
    "                    param2_ptr,\n",
    "                    x_ptr,\n",
    "                    output_ptr,\n",
    "                    input_row_stride,\n",
    "                    output_row_stride,\n",
    "                    n_rows,\n",
    "                    n_cols,\n",
    "                    BLOCK_SIZE: tl.constexpr,\n",
    "                    num_stages: tl.constexpr,\n",
    "                    ):\n",
    "    row_start = tl.program_id(0)\n",
    "    row_step = tl.num_programs(0)\n",
    "    \n",
    "    # Load shared params\n",
    "    # TODO T: I think triton will load them once into shared memory -> confirm\n",
    "    offsets = tl.arange(0, BLOCK_SIZE)\n",
    "    mask = offsets < n_cols\n",
    "    param1 = tl.load(param1_ptr + offsets, mask=mask, other=0.0)\n",
    "    param2 = tl.load(param2_ptr + offsets, mask=mask, other=0.0)    \n",
    "        \n",
    "    for row_idx in tl.range(row_start, n_rows, row_step, num_stages):\n",
    "        x_row_start_ptr = x_ptr + row_idx * input_row_stride    \n",
    "        x = tl.load(x_row_start_ptr + offsets, mask=mask, other=0.0)\n",
    "        \n",
    "        # compute mean and std\n",
    "        sum_x = tl.sum(x, axis=0)\n",
    "        mu = sum_x/ n_cols\n",
    "        x_minus_mu = x - mu\n",
    "        x_minus_mu2 = x_minus_mu * x_minus_mu\n",
    "        sum_x_minus_mu2 = tl.sum(x_minus_mu2, axis=0)\n",
    "        sigma2 = sum_x_minus_mu2 / (n_cols-1)\n",
    "        sigma = tl.sqrt_rn(sigma2)\n",
    "        # TODO T: invesitage numerical differences from pytorch implementation\n",
    "        #print(f'mu', mu, 'sigma', sigma)\n",
    "        \n",
    "        # normalize \n",
    "        norm_x = x_minus_mu/sigma    \n",
    "        \n",
    "        # element-wise projection\n",
    "        output = param1 * norm_x + param2\n",
    "        output_row_start_ptr = output_ptr + row_idx * output_row_stride\n",
    "        tl.store(output_row_start_ptr + offsets, output, mask=mask)\n",
    "    \n",
    "def t_layernorm_fwd_t(layer_params: torch.Tensor, x: torch.Tensor):\n",
    "    x_2d = x.reshape((-1, x.shape[-1])) # TODO T: without this reshape, this func is 2times faster\n",
    "    n_rows, n_cols = x_2d.shape\n",
    "    BLOCK_SIZE = triton.next_power_of_2(n_cols) \n",
    "    output = torch.empty_like(x_2d)\n",
    "    # TODO T: The below numbers were tuned for A10 by choosing num_warps=8\n",
    "    num_warps = 8\n",
    "    num_stages = 2\n",
    "    num_programs = min(n_rows, 480) \n",
    "    t_layernorm_fwd_k[(num_programs,)](layer_params[0], layer_params[1], x_2d, \n",
    "                                       output, x_2d.stride(0), output.stride(0), n_rows, n_cols, \n",
    "                                       BLOCK_SIZE=BLOCK_SIZE, num_warps=num_warps, num_stages=num_stages)\n",
    "    return output.reshape(x.shape)\n",
    "\n",
    "def fn_t(x):\n",
    "    return t_layernorm_fwd_t(layer_params, x)\n",
    "\n",
    "from torch.profiler import profile, record_function, ProfilerActivity, schedule\n",
    "activities = [ProfilerActivity.CPU, ProfilerActivity.CUDA]\n",
    "with profile(activities=activities, record_shapes=True) as prof:\n",
    "    for _ in range(N):\n",
    "        result = fn_t(aa)\n",
    "        #result = fn_t(dloss_dx, aa)\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=20))\n",
    "\n",
    "import time\n",
    "t0 = time.time()\n",
    "for _ in range(N):\n",
    "    result = fn_t(aa)\n",
    "    #result = fn_t(dloss_dx, aa)\n",
    "torch.cuda.synchronize()\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(f'total', total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dd7cca0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "(torch.Size([8, 512, 768]), torch.Size([8, 512, 768]), tensor([[ 0.2838,  3.5992,  1.1048,  ..., -3.9138,  0.6739, -1.0068],\n        [ 0.3081,  1.9939,  1.3103,  ..., -3.4317, -1.2630, -1.4416],\n        [ 0.3306, -1.8754,  2.0491,  ..., -2.6722,  1.5567, -1.2539],\n        [ 0.2578, -1.5582, -0.7187,  ..., -3.3886, -0.8689, -1.8879]],\n       device='cuda:0'), tensor([[ 0.2838,  3.5992,  1.1048,  ..., -3.9138,  0.6739, -1.0068],\n        [ 0.3081,  1.9939,  1.3103,  ..., -3.4317, -1.2630, -1.4416],\n        [ 0.3306, -1.8754,  2.0490,  ..., -2.6722,  1.5566, -1.2539],\n        [ 0.2578, -1.5580, -0.7185,  ..., -3.3884, -0.8689, -1.8879]],\n       device='cuda:0'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m res2 \u001b[38;5;241m=\u001b[39m fn_t(aa)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#res2 = fn_t(dloss_dx, aa)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mallclose(res1, res2, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-2\u001b[39m, rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), (res1\u001b[38;5;241m.\u001b[39mshape, res2\u001b[38;5;241m.\u001b[39mshape, res1[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m:], res2[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m:])\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#assert torch.allclose(res1, res2), (res1[0], res2[0])\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mres1\u001b[39m\u001b[38;5;124m'\u001b[39m, res1\u001b[38;5;241m.\u001b[39mshape, res1[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mAssertionError\u001b[0m: (torch.Size([8, 512, 768]), torch.Size([8, 512, 768]), tensor([[ 0.2838,  3.5992,  1.1048,  ..., -3.9138,  0.6739, -1.0068],\n        [ 0.3081,  1.9939,  1.3103,  ..., -3.4317, -1.2630, -1.4416],\n        [ 0.3306, -1.8754,  2.0491,  ..., -2.6722,  1.5567, -1.2539],\n        [ 0.2578, -1.5582, -0.7187,  ..., -3.3886, -0.8689, -1.8879]],\n       device='cuda:0'), tensor([[ 0.2838,  3.5992,  1.1048,  ..., -3.9138,  0.6739, -1.0068],\n        [ 0.3081,  1.9939,  1.3103,  ..., -3.4317, -1.2630, -1.4416],\n        [ 0.3306, -1.8754,  2.0490,  ..., -2.6722,  1.5566, -1.2539],\n        [ 0.2578, -1.5580, -0.7185,  ..., -3.3884, -0.8689, -1.8879]],\n       device='cuda:0'))"
     ]
    }
   ],
   "source": [
    "res1 = fn_jit(aa)\n",
    "#res1 = fn_jit(dloss_dx, aa)\n",
    "res2 = fn_t(aa)\n",
    "#res2 = fn_t(dloss_dx, aa)\n",
    "\n",
    "assert torch.allclose(res1, res2, atol=1e-2, rtol=0), (res1.shape, res2.shape, res1[0, -4:], res2[0, -4:])\n",
    "#assert torch.allclose(res1, res2), (res1[0], res2[0])\n",
    "print(f'res1', res1.shape, res1[0])\n",
    "print(f'res2', res2.shape, res2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d0ad106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-5.1964e-01, -9.2317e-01, -4.8219e-01,  ..., -3.9431e-01,\n",
      "          -1.2810e-01,  3.1543e-01],\n",
      "         [-2.0826e+00, -1.2466e+00,  1.8060e+00,  ...,  2.0965e-01,\n",
      "           1.2677e+00,  1.0453e+00],\n",
      "         [-3.2024e+00,  1.2447e+00,  1.2724e+00,  ..., -3.2989e-01,\n",
      "           8.7698e-01, -3.5632e-01],\n",
      "         ...,\n",
      "         [-1.5875e+00, -1.9465e-01,  2.7189e-01,  ..., -3.5884e-01,\n",
      "           1.2794e+00,  2.4107e-01],\n",
      "         [-1.1515e+00, -2.0797e+00,  2.0817e+00,  ..., -2.2421e-02,\n",
      "          -4.2768e-01,  3.8299e-01],\n",
      "         [-2.6354e+00,  1.1654e+00,  2.6262e-01,  ..., -1.1016e-01,\n",
      "          -8.1310e-01,  4.1021e-01]],\n",
      "\n",
      "        [[ 3.9872e-01, -8.9222e-01, -1.9155e+00,  ..., -3.7835e-01,\n",
      "           2.3540e+00, -2.3153e-01],\n",
      "         [-1.4556e+00,  7.9443e-01,  3.9355e-01,  ..., -4.1607e-01,\n",
      "           1.6717e+00,  2.0582e-01],\n",
      "         [-1.3239e+00, -2.3227e-01, -6.1886e-01,  ..., -1.2954e-01,\n",
      "           1.6016e+00,  5.2502e-02],\n",
      "         ...,\n",
      "         [ 1.0826e+00, -5.6339e-01, -1.5369e+00,  ..., -1.7963e-01,\n",
      "           1.7286e+00, -6.6292e-02],\n",
      "         [-1.0139e+00,  1.4124e+00,  1.5957e+00,  ..., -2.6340e-04,\n",
      "           4.6073e-01, -1.7296e-01],\n",
      "         [-9.1509e-01,  2.2050e+00,  2.9081e-01,  ..., -5.8678e-02,\n",
      "           1.9525e+00, -4.3889e-02]],\n",
      "\n",
      "        [[-5.9280e-01, -1.6489e+00,  1.8050e-01,  ...,  6.9466e-02,\n",
      "           2.0537e+00, -1.2142e-02],\n",
      "         [ 1.9024e-01, -1.2353e+00, -5.8371e-01,  ...,  2.9345e-02,\n",
      "           1.6825e+00,  2.4940e-02],\n",
      "         [-2.1626e+00,  1.3855e+00,  2.2411e+00,  ...,  1.7439e-02,\n",
      "           1.6982e+00,  1.9079e-02],\n",
      "         ...,\n",
      "         [-3.7184e-01,  1.1605e+00,  5.6691e-01,  ..., -2.2938e-01,\n",
      "           1.1831e+00,  2.2879e-01],\n",
      "         [-1.3006e+00,  1.3748e+00, -8.0142e-04,  ..., -4.7624e-02,\n",
      "           1.0629e+00,  5.5250e-02],\n",
      "         [-1.6862e+00, -2.0790e+00, -5.9575e-01,  ..., -3.9911e-01,\n",
      "           1.0767e+00,  5.7400e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.1978e+00,  5.9633e-01, -9.6316e-01,  ...,  1.0499e-01,\n",
      "           9.1149e-01,  7.0663e-01],\n",
      "         [-1.0605e+00,  4.5132e-01,  7.3367e-01,  ..., -1.0334e-01,\n",
      "           1.4554e+00,  1.3242e-01],\n",
      "         [-5.6618e-01, -4.6655e-01, -3.5781e-01,  ..., -1.5522e-01,\n",
      "           1.2123e+00, -5.8182e-01],\n",
      "         ...,\n",
      "         [ 3.1847e-01,  9.5571e-01,  1.6446e+00,  ..., -2.2597e-01,\n",
      "           1.5608e+00,  2.4701e-02],\n",
      "         [-7.2110e-01,  2.1302e-01, -4.1080e-01,  ...,  2.3821e-02,\n",
      "           2.6506e+00, -5.6042e-01],\n",
      "         [-1.3198e-01,  2.0806e+00,  1.4550e+00,  ..., -5.0115e-01,\n",
      "          -4.2155e-01, -2.1376e-01]],\n",
      "\n",
      "        [[ 1.1491e+00,  3.8068e-01, -3.0786e-01,  ...,  2.5389e-01,\n",
      "           8.0189e-02,  7.3440e-02],\n",
      "         [-7.3514e-01, -2.7069e-01,  3.2933e-01,  ..., -2.5824e-01,\n",
      "           1.7422e+00, -3.5769e-01],\n",
      "         [-2.8671e+00, -7.4016e-01,  3.3617e-01,  ...,  8.6450e-02,\n",
      "           1.3176e+00, -1.2882e-01],\n",
      "         ...,\n",
      "         [-2.0258e-01, -1.8578e+00, -8.4649e-01,  ..., -3.0241e-01,\n",
      "           2.4815e+00, -3.1732e-02],\n",
      "         [-2.7230e+00, -7.3228e-01, -4.5638e-02,  ..., -1.5108e-02,\n",
      "          -3.3541e-01,  9.6476e-01],\n",
      "         [-2.7584e-01,  8.2007e-01, -3.1928e-02,  ..., -6.9229e-02,\n",
      "           2.5317e+00,  6.1585e-01]],\n",
      "\n",
      "        [[-5.8106e-01,  2.7700e+00, -1.6551e+00,  ..., -1.2204e-01,\n",
      "           2.0283e-01,  2.8292e-01],\n",
      "         [-4.6935e-01, -4.4371e+00, -8.1958e-01,  ..., -5.9045e-01,\n",
      "           1.6127e+00,  2.8425e-01],\n",
      "         [-2.0362e+00,  1.9389e-01,  6.7479e-02,  ..., -1.9795e-01,\n",
      "           6.0383e-02,  1.3522e+00],\n",
      "         ...,\n",
      "         [-1.0532e+00, -2.0739e-01,  6.7400e-01,  ...,  4.8171e-02,\n",
      "           1.9444e+00,  5.2581e-01],\n",
      "         [ 7.5337e-01,  2.1910e+00,  1.8372e-01,  ...,  1.5708e-02,\n",
      "           4.2433e-01, -5.2349e-01],\n",
      "         [-1.3894e+00, -1.0525e+00,  2.6708e+00,  ..., -2.7623e-01,\n",
      "           1.0121e+00,  2.1384e-01]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e5e755bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_dropout_fwd:\n",
      "       N      Triton       Torch       naive\n",
      "0  768.0  652.460166  664.216209  126.347996\n"
     ]
    }
   ],
   "source": [
    "@triton.testing.perf_report(\n",
    "    triton.testing.Benchmark(\n",
    "        x_names=['N'],  # Argument names to use as an x-axis for the plot.\n",
    "        x_vals=[768], #[128 * i for i in range(2, 100)],  # Different possible values for `x_name`.\n",
    "        #x_log=True,  # x axis is logarithmic.\n",
    "        line_arg='provider',  # Argument name whose value corresponds to a different line in the plot.\n",
    "        line_vals=['triton', 'torch', 'naive'],  # Possible values for `line_arg`.\n",
    "        line_names=['Triton', 'Torch', 'naive'],  # Label name for the lines.\n",
    "        styles=[('blue', '-'), ('green', '-'), ('orange', '-')],  # Line styles.\n",
    "        ylabel='GB/s',  # Label name for the y-axis.\n",
    "        plot_name='t_dropout_fwd',  # Name for the plot. Used also as a file name for saving the plot.\n",
    "        args={'M':4096},  # Values for function arguments not in `x_names` and `y_name`.\n",
    "        # TODO T: Use real M i.e. \n",
    "    ))\n",
    "def benchmark(M, N, provider):\n",
    "    #dloss_dx = torch.rand(size, device=\"cuda\", dtype=torch.float32)    \n",
    "    x = torch.rand(M, N, device=\"cuda\", dtype=torch.float32)\n",
    "    stream = getattr(torch, \"cuda\").Stream() # TODO XXX XXX: what is this stream about?\n",
    "    getattr(torch, \"cuda\").set_stream(stream)\n",
    "    quantiles = [0.5, 0.2, 0.8]\n",
    "    if provider == 'torch':\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: fn_jit(x), quantiles=quantiles)\n",
    "        #ms, min_ms, max_ms = triton.testing.do_bench(lambda: fn_jit(dloss_dx, x), quantiles=quantiles)\n",
    "    if provider == 'triton':\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: fn_t(x), quantiles=quantiles)        \n",
    "        #ms, min_ms, max_ms = triton.testing.do_bench(lambda: fn_t(dloss_dx, x), quantiles=quantiles)\n",
    "    if provider == 'naive':\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: fn_naive(x), quantiles=quantiles)\n",
    "        #ms, min_ms, max_ms = triton.testing.do_bench(lambda: fn_naive(dloss_dx, x), quantiles=quantiles)\n",
    "    gbps = lambda ms: 3 * x.numel() * x.element_size() * 1e-9 / (ms * 1e-3)\n",
    "    return gbps(ms), gbps(max_ms), gbps(min_ms)\n",
    "benchmark.run(print_data=True, show_plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "afb4b1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_CudaDeviceProperties(name='NVIDIA A10G', major=8, minor=6, total_memory=22723MB, multi_processor_count=80, uuid=df82317b-d317-7368-eed6-8c8a4866f43b, L2_cache_size=6MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_shared_mem': 101376,\n",
       " 'max_num_regs': 65536,\n",
       " 'multiprocessor_count': 80,\n",
       " 'warpSize': 32,\n",
       " 'sm_clock_rate': 1710000,\n",
       " 'mem_clock_rate': 6251000,\n",
       " 'mem_bus_width': 384}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.get_device_properties(\"cuda\"))\n",
    "from triton.runtime import driver\n",
    "device = torch.cuda.current_device()\n",
    "properties = driver.active.utils.get_device_properties(device)\n",
    "NUM_SM = properties[\"multiprocessor_count\"]\n",
    "SIZE_SMEM = properties[\"max_shared_mem\"]\n",
    "NUM_REGS = properties[\"max_num_regs\"]\n",
    "WARP_SIZE = properties[\"warpSize\"] # Not 64 as A100\n",
    "properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "759b10c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_stages 2 num_warps 8\n",
      "n_regs 37 size_smem 4128\n",
      "occupancy 6 24\n",
      "num_programs 480\n"
     ]
    }
   ],
   "source": [
    "num_stages = 4 if SIZE_SMEM > 200000 else 2\n",
    "num_warps = 8\n",
    "x_2d = aa.reshape((-1, aa.shape[-1])) # TODO T: without this reshape, this func is 2times faster\n",
    "n_rows, n_cols = x_2d.shape\n",
    "BLOCK_SIZE = triton.next_power_of_2(n_cols) \n",
    "output = torch.empty_like(x_2d)\n",
    "print(f'num_stages', num_stages, 'num_warps', num_warps)\n",
    "\n",
    "kernel = t_layernorm_fwd_k.warmup(layer_params[0], layer_params[1], x_2d, output, \n",
    "                                  x_2d.stride(0), output.stride(0), n_rows, n_cols, BLOCK_SIZE=BLOCK_SIZE,\n",
    "                                   num_stages=num_stages, num_warps=num_warps, grid=(1, ))\n",
    "kernel._init_handles()\n",
    "n_regs = kernel.n_regs\n",
    "size_smem = kernel.metadata.shared\n",
    "print(f'n_regs', n_regs, 'size_smem', size_smem)\n",
    "\n",
    "occupancy = NUM_REGS // (n_regs * WARP_SIZE * num_warps)\n",
    "size_smem = max(1, size_smem)\n",
    "print(f'occupancy', occupancy, SIZE_SMEM // size_smem)\n",
    "occupancy = min(occupancy, SIZE_SMEM // size_smem)\n",
    "num_programs = NUM_SM * occupancy\n",
    "print(f'num_programs', num_programs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944310f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "32\n",
    "2080\n",
    "4128\n",
    "6176"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
