{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dc44b45",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model_torch_func'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_printoptions(precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m jacrev\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel_torch_func\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m init_transformer_gpt2\n\u001b[1;32m      6\u001b[0m BS, H, N, D \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m64\u001b[39m \u001b[38;5;66;03m# 1, 1, 3, 4 #2, 2, 5, 4\u001b[39;00m\n\u001b[1;32m      7\u001b[0m vocab_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'model_torch_func'"
     ]
    }
   ],
   "source": [
    "#### torch_func's fwd vs triton's fwd on train=False (we can't do this testing for train=True due to different RNGs tooling)\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "torch.set_printoptions(precision=6)\n",
    "from torch.func import jacrev\n",
    "from model_torch_func import init_transformer_gpt2\n",
    "BS, H, N, D = 2, 2, 512, 64 # 1, 1, 3, 4 #2, 2, 5, 4\n",
    "vocab_size = 128\n",
    "layers = 2\n",
    "p_gen_aux = [42] + [43,44,45] * layers\n",
    "layers_params = init_transformer_gpt2(vocab_size, D, layers, H, 4*D, N)\n",
    "y= torch.randint(vocab_size, (BS, N+1), device=\"cuda\").to(torch.int32)\n",
    "mask = torch.ones((BS, N, N), dtype=torch.bool, device=\"cuda\")\n",
    "train = False\n",
    "\n",
    "for i, i_mask in enumerate(mask):\n",
    "    mask[i] = torch.tril(i_mask)\n",
    "    #mask[i] = torch.zeros_like(i_mask)\n",
    "# print(mask)\n",
    "lens = [N]*BS\n",
    "import numpy as np\n",
    "y_indices = torch.tensor(np.vstack([np.arange(el_len) for el_len in lens]), device=\"cuda\")\n",
    "print(f'y_indices', y_indices.shape)\n",
    "\n",
    "from model_torch_func import batched_forward_gpt2\n",
    "from model_triton import t_gpt2_forward_with_acts_t\n",
    "y_in = y[:, :-1]\n",
    "y_out = y[:, 1:]\n",
    "y_indices = y_indices[:, 1:]\n",
    "    \n",
    "res2 = batched_forward_gpt2(layers_params, y_in, mask, y_indices, train)\n",
    "print(res2.shape, res2)\n",
    "#print(res2[1])\n",
    "#print_res_shapes(res2[0]) \n",
    "\n",
    "print(f'----X----')\n",
    "\n",
    "res3, acts3 = t_gpt2_forward_with_acts_t(layers_params, y_in, mask, y_indices, train, p_gen_aux)\n",
    "print(res3.shape, res3)\n",
    "#print_res_shapes(res3[0]) \n",
    "\n",
    "#assert torch.allclose(res2[0], res3[0], rtol=1e-2, atol=5e-3)\n",
    "assert torch.allclose(res2, res3, rtol=1e-2, atol=5e-3) \n",
    "#assert torch.allclose(res2, res3, rtol=1e-3, atol=2e-4)\n",
    "\n",
    "# print(f'----XXX----')\n",
    "\n",
    "# def recursive_assert(a, b):\n",
    "#     if isinstance(a, torch.Tensor):\n",
    "#         assert isinstance(b, torch.Tensor)\n",
    "#         torch.allclose(a, b, rtol=1e-3, atol=1e-4)\n",
    "#     else:\n",
    "#         assert not isinstance(b, torch.Tensor)\n",
    "#         if len(a) != len(b):\n",
    "#             return\n",
    "#         assert len(a) == len(b), f'len(a) {len(a)}, len(b) {len(b)}'\n",
    "#         for i, (ai, bi) in enumerate(zip(a, b)):\n",
    "#             recursive_assert(ai, bi)\n",
    "# recursive_assert(acts2, acts3)\n",
    "# print(f'----XXX----')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c738db2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
