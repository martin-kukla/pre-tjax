{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd01fc6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "(torch.Size([2, 1, 16, 16]), torch.Size([2, 1, 16, 16]), tensor([[[[ 0.3227,  0.2860,  0.0628, -0.0717],\n          [ 0.3847, -0.1799,  0.0733, -0.4351],\n          [ 0.0875,  0.2422,  0.1104,  0.0177],\n          [ 0.4990, -0.0590, -0.1283, -0.1561]]],\n\n\n        [[[ 0.0242, -0.0036, -0.0193, -0.1388],\n          [ 0.0242, -0.0036, -0.0193, -0.1388],\n          [ 0.0242, -0.0036, -0.0193, -0.1388],\n          [ 0.0242, -0.0036, -0.0193, -0.1388]]]], device='cuda:0'), tensor([[[[ 0.3227,  0.2858,  0.0628, -0.0717],\n          [ 0.3845, -0.1799,  0.0733, -0.4351],\n          [ 0.0873,  0.2421,  0.1104,  0.0178],\n          [ 0.4991, -0.0590, -0.1284, -0.1562]]],\n\n\n        [[[ 0.0060, -0.0009, -0.0048, -0.0347],\n          [ 0.0060, -0.0009, -0.0048, -0.0347],\n          [ 0.0060, -0.0009, -0.0048, -0.0347],\n          [ 0.0060, -0.0009, -0.0048, -0.0347]]]], device='cuda:0'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 24\u001b[0m\n\u001b[1;32m     20\u001b[0m result, _ \u001b[38;5;241m=\u001b[39m t_scaled_dot_prod_attn_fwd3(qkv, mask, train, p_gen_aux)\n\u001b[1;32m     22\u001b[0m result2, _ \u001b[38;5;241m=\u001b[39m t_scaled_dot_prod_attn_fwd3_t(qkv, mask, train, p_gen_aux)\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mallclose(result, result2, rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-2\u001b[39m, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m), (result\u001b[38;5;241m.\u001b[39mshape, result2\u001b[38;5;241m.\u001b[39mshape, result[:\u001b[38;5;241m2\u001b[39m, :\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m:], result2[:\u001b[38;5;241m2\u001b[39m, :\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m:])\n",
      "\u001b[0;31mAssertionError\u001b[0m: (torch.Size([2, 1, 16, 16]), torch.Size([2, 1, 16, 16]), tensor([[[[ 0.3227,  0.2860,  0.0628, -0.0717],\n          [ 0.3847, -0.1799,  0.0733, -0.4351],\n          [ 0.0875,  0.2422,  0.1104,  0.0177],\n          [ 0.4990, -0.0590, -0.1283, -0.1561]]],\n\n\n        [[[ 0.0242, -0.0036, -0.0193, -0.1388],\n          [ 0.0242, -0.0036, -0.0193, -0.1388],\n          [ 0.0242, -0.0036, -0.0193, -0.1388],\n          [ 0.0242, -0.0036, -0.0193, -0.1388]]]], device='cuda:0'), tensor([[[[ 0.3227,  0.2858,  0.0628, -0.0717],\n          [ 0.3845, -0.1799,  0.0733, -0.4351],\n          [ 0.0873,  0.2421,  0.1104,  0.0178],\n          [ 0.4991, -0.0590, -0.1284, -0.1562]]],\n\n\n        [[[ 0.0060, -0.0009, -0.0048, -0.0347],\n          [ 0.0060, -0.0009, -0.0048, -0.0347],\n          [ 0.0060, -0.0009, -0.0048, -0.0347],\n          [ 0.0060, -0.0009, -0.0048, -0.0347]]]], device='cuda:0'))"
     ]
    }
   ],
   "source": [
    "# Repro ready\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import torch\n",
    "from model_triton import t_scaled_dot_prod_attn_fwd3, t_scaled_dot_prod_attn_fwd3_t\n",
    "\n",
    "#BS, H, N, D = 2, 2, 512, 64\n",
    "BS, H, N, D = 2, 1, 16, 16\n",
    "# qkv = torch.randn((BS, H, 3, N, D), device=\"cuda\")\n",
    "qkv = torch.randn((1, H, 3, N, D), device=\"cuda\").expand(BS, H, 3, N, D)\n",
    "mask = torch.tril(torch.ones((N,N), dtype=torch.bool, device=\"cuda\")).unsqueeze(0).repeat(BS, 1, 1)\n",
    "train=False #True\n",
    "p_gen_aux = 42\n",
    "N_RUNS = 1 #10\n",
    "\n",
    "# print(mask.shape)\n",
    "k=10\n",
    "mask[1, k+1:, :]=0\n",
    "# print(mask)\n",
    "\n",
    "result, _ = t_scaled_dot_prod_attn_fwd3(qkv, mask, train, p_gen_aux)\n",
    "\n",
    "result2, _ = t_scaled_dot_prod_attn_fwd3_t(qkv, mask, train, p_gen_aux)\n",
    "\n",
    "assert torch.allclose(result, result2, rtol=5e-2, atol=1e-3), (result.shape, result2.shape, result[:2, :2, -4:, -4:], result2[:2, :2, -4:, -4:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
