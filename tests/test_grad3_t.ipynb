{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39c21413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "- 2\n",
      "-- torch.Size([128, 64]) tensor([-0.003505,  0.007882, -0.001664], device='cuda:0')\n",
      "-- torch.Size([128]) tensor([ 0.000964,  0.001854, -0.001920], device='cuda:0')\n",
      "- 1\n",
      "-- torch.Size([512, 64]) tensor([ 3.864176e-05, -6.586349e-05, -3.140170e-04], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([64]) tensor([1.789831e-06, 1.210890e-05, 6.373659e-06], device='cuda:0')\n",
      "-- torch.Size([64]) tensor([-3.012282e-05, -8.887264e-05,  8.828213e-05], device='cuda:0')\n",
      "-- torch.Size([2, 3, 32, 64]) tensor([-2.479468e-05, -2.766168e-05,  4.145396e-05], device='cuda:0')\n",
      "-- torch.Size([64, 64]) tensor([-7.565518e-05,  1.041194e-04,  5.504349e-05], device='cuda:0')\n",
      "-- torch.Size([64]) tensor([-1.286771e-05,  7.743671e-05,  1.872615e-05], device='cuda:0')\n",
      "-- torch.Size([64]) tensor([-1.702363e-05, -4.738345e-05, -7.780627e-05], device='cuda:0')\n",
      "-- torch.Size([256, 64]) tensor([-7.358280e-06, -1.423518e-04,  1.861453e-04], device='cuda:0')\n",
      "-- torch.Size([256]) tensor([-9.753904e-05,  2.259074e-04, -4.182720e-05], device='cuda:0')\n",
      "-- torch.Size([64, 256]) tensor([ 6.241843e-04,  8.731493e-05, -6.259310e-05], device='cuda:0')\n",
      "-- torch.Size([64]) tensor([-0.003279,  0.002466,  0.004588], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([64]) tensor([ 1.417276e-06, -1.509346e-06, -1.034319e-05], device='cuda:0')\n",
      "-- torch.Size([64]) tensor([ 2.959476e-05, -1.149358e-05, -6.231163e-06], device='cuda:0')\n",
      "-- torch.Size([2, 3, 32, 64]) tensor([-1.516863e-05,  1.288465e-05, -2.337114e-05], device='cuda:0')\n",
      "-- torch.Size([64, 64]) tensor([-2.288378e-05,  3.195525e-05,  3.135591e-05], device='cuda:0')\n",
      "-- torch.Size([64]) tensor([ 3.713441e-05, -5.020964e-05,  2.771459e-05], device='cuda:0')\n",
      "-- torch.Size([64]) tensor([ 1.049788e-05,  2.755338e-06, -1.953260e-05], device='cuda:0')\n",
      "-- torch.Size([256, 64]) tensor([ 7.011819e-06, -2.338410e-05, -4.323258e-05], device='cuda:0')\n",
      "-- torch.Size([256]) tensor([ 1.879457e-05, -2.468311e-05,  1.454775e-04], device='cuda:0')\n",
      "-- torch.Size([64, 256]) tensor([-2.122287e-04, -7.507966e-05, -1.082463e-04], device='cuda:0')\n",
      "-- torch.Size([64]) tensor([-0.003637,  0.002410,  0.004621], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([64]) tensor([0.000406, 0.000642, 0.000513], device='cuda:0')\n",
      "-- torch.Size([64]) tensor([-0.000650,  0.000190,  0.000844], device='cuda:0')\n",
      "----XXX----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loc(callsite(\"/efs/notebooks/mkukla/pre-tjax/model_triton.py\":1449:7 at \"/efs/notebooks/mkukla/pre-tjax/model_triton.py\":907:74)): error: operation scheduled before its operands\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "- 2\n",
      "-- torch.Size([128, 64]) tensor([-0.003682,  0.005054,  0.000734], device='cuda:0')\n",
      "-- torch.Size([128]) tensor([ 0.000964,  0.001854, -0.001920], device='cuda:0')\n",
      "- 1\n",
      "-- torch.Size([512, 64]) tensor([ 5.972455e-06, -1.167266e-05, -4.032930e-05], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([64]) tensor([4.132200e-07, 1.563793e-06, 9.823967e-07], device='cuda:0')\n",
      "-- torch.Size([64]) tensor([-4.424945e-06, -1.176063e-05,  1.363217e-05], device='cuda:0')\n",
      "-- torch.Size([2, 3, 32, 64]) tensor([-4.407902e-06, -4.250490e-06,  6.683092e-06], device='cuda:0')\n",
      "-- torch.Size([64, 64]) tensor([-1.154554e-05,  1.674224e-05,  8.602457e-06], device='cuda:0')\n",
      "-- torch.Size([64]) tensor([-1.700682e-06,  1.079263e-05,  9.962064e-07], device='cuda:0')\n",
      "-- torch.Size([64]) tensor([-2.067035e-06, -7.818023e-06, -1.069047e-05], device='cuda:0')\n",
      "-- torch.Size([256, 64]) tensor([-1.694028e-06, -2.026383e-05,  2.860608e-05], device='cuda:0')\n",
      "-- torch.Size([256]) tensor([-1.273283e-05,  3.240734e-05, -3.735968e-06], device='cuda:0')\n",
      "-- torch.Size([64, 256]) tensor([ 9.361412e-05,  1.913655e-05, -8.776751e-06], device='cuda:0')\n",
      "-- torch.Size([64]) tensor([-0.000528,  0.000366,  0.000776], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([64]) tensor([ 3.017240e-07, -1.114972e-07, -1.657612e-06], device='cuda:0')\n",
      "-- torch.Size([64]) tensor([ 4.568310e-06, -2.372113e-06, -5.320781e-07], device='cuda:0')\n",
      "-- torch.Size([2, 3, 32, 64]) tensor([-7.997517e-07,  2.404410e-06, -4.900399e-06], device='cuda:0')\n",
      "-- torch.Size([64, 64]) tensor([-3.297954e-06,  6.482932e-06,  6.611541e-06], device='cuda:0')\n",
      "-- torch.Size([64]) tensor([ 5.154795e-06, -7.373086e-06,  4.205571e-06], device='cuda:0')\n",
      "-- torch.Size([64]) tensor([ 2.261141e-06,  6.574080e-07, -1.991644e-06], device='cuda:0')\n",
      "-- torch.Size([256, 64]) tensor([ 1.184455e-06, -5.790699e-06, -5.968363e-06], device='cuda:0')\n",
      "-- torch.Size([256]) tensor([ 5.260426e-06, -3.826278e-06,  2.276868e-05], device='cuda:0')\n",
      "-- torch.Size([64, 256]) tensor([-2.503600e-05, -1.004867e-05, -1.577080e-05], device='cuda:0')\n",
      "-- torch.Size([64]) tensor([-0.000537,  0.000365,  0.000775], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([64]) tensor([0.000406, 0.000642, 0.000513], device='cuda:0')\n",
      "-- torch.Size([64]) tensor([-0.000650,  0.000190,  0.000844], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#### t_loss_bkwd2 vs t_loss_bkwd3 on train=True\n",
    "import torch\n",
    "torch.set_printoptions(precision=6)\n",
    "from torch.func import jacrev\n",
    "from model_torch_func import init_transformer_gpt2\n",
    "#from model_triton import *\n",
    "from loss_and_optimizer_triton import t_loss, t_loss_bkwd3, t_loss_bkwd3_t\n",
    "BS, H, N, D = 2, 2, 512, 64 # 1, 1, 3, 4 #2, 2, 5, 4\n",
    "vocab_size = 128\n",
    "layers = 2\n",
    "p_gen_aux = [42] + [43,44,45] * layers\n",
    "layers_params = init_transformer_gpt2(vocab_size, D, layers, H, 4*D, N)\n",
    "y= torch.randint(vocab_size, (BS, N+1), device=\"cuda\").to(torch.int32)\n",
    "mask = torch.ones((BS, N, N), dtype=torch.bool, device=\"cuda\")\n",
    "train=False\n",
    "\n",
    "def print_res_shapes(res):\n",
    "    print(len(res))\n",
    "    for it in res:\n",
    "        print(f'-', len(it))\n",
    "        for p in it:\n",
    "            print(f'--', p.shape, p.reshape(-1)[-3:]) # TODO: modify to check different parts\n",
    "\n",
    "for i, i_mask in enumerate(mask):\n",
    "    mask[i] = torch.tril(i_mask)\n",
    "    #mask[i] = torch.zeros_like(i_mask)\n",
    "# print(mask)\n",
    "\n",
    "res2 = t_loss_bkwd3(layers_params, y, mask, None, train, p_gen_aux)\n",
    "#print(res2[1])\n",
    "print_res_shapes(res2[0]) \n",
    "\n",
    "print(f'----XXX----')\n",
    "\n",
    "res3 = t_loss_bkwd3_t(layers_params, y, mask, None, train, p_gen_aux)\n",
    "#print(res3)\n",
    "print_res_shapes(res3[0]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a28ec3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
