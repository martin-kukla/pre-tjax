{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "094e1484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.696425, -0.533204,  0.009236],\n",
      "        [-1.523902, -1.784682,  1.761061]])\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "from torch.func import grad, vjp, jacrev\n",
    "from model_triton import *\n",
    "\n",
    "aa = torch.randn((2,3)) #torch.randn((2, 2, 3))\n",
    "print(aa)\n",
    "print(\"----\")\n",
    "\n",
    "# RELU\n",
    "# print(t_relu_bkwd(aa) * aa)\n",
    "# print(vjp(t_relu_fwd, aa)[0])\n",
    "#print(jacrev(t_relu_fwd)(aa))\n",
    "\n",
    "# GELU\n",
    "# print(jacrev(t_gelu_fwd)(aa))\n",
    "# print(t_gelu_bkwd(aa))\n",
    "#print(t_gelu_bkwd(aa) * aa)\n",
    "\n",
    "# LOG_SOFTMAX\n",
    "# print(jacrev(t_log_softmax_fwd)(aa))\n",
    "# print(t_log_softmax_bkwd(aa))\n",
    "\n",
    "# Embed\n",
    "# from model_torch_func import init_proj_layer\n",
    "# params = (init_proj_layer(4, 2), )\n",
    "# aa =torch.tensor([1, 0, 1])\n",
    "# print(jacrev(t_embed_fwd)(params, aa))\n",
    "# print(t_embed_bkwd(params, aa))\n",
    "\n",
    "# Proj\n",
    "# aa = torch.randn((2,2))\n",
    "# #print(aa)\n",
    "# params = torch.randn((4,2))\n",
    "# #print(t_proj_fwd(params, aa))\n",
    "# res = jacrev(t_proj_fwd)(params, aa)\n",
    "# print(res.shape)\n",
    "# print(res)\n",
    "# res2 = t_proj_bkwd_p(params, aa)\n",
    "# print(res2.shape)\n",
    "# print(res2)\n",
    "# res = jacrev(t_proj_fwd, argnums=1)(params, aa)\n",
    "# print(res.shape, res)\n",
    "# res2 = t_proj_bkwd_x(params, aa)\n",
    "# print(res2.shape, res2)\n",
    "\n",
    "# Linear\n",
    "# aa = torch.randn((2,2))\n",
    "# print(aa)\n",
    "# params = (torch.randn((4,2)), torch.randn((4,)))\n",
    "# res = jacrev(t_linear_fwd)(params, aa)\n",
    "# print(res[0].shape, res[1].shape)\n",
    "# print(res)\n",
    "# res2 = t_linear_bkwd_p(params, aa)\n",
    "# print(res2[0].shape, res2[1].shape)\n",
    "# print(res2)\n",
    "\n",
    "# from model_triton import t_linear_bkwd_x\n",
    "# res = jacrev(t_linear_fwd, argnums=1)(params, aa)\n",
    "# print(res.shape, res)\n",
    "# res2 = t_linear_bkwd_x(params, aa)\n",
    "# print(res2.shape, res2)\n",
    "\n",
    "# LAYERNORM\n",
    "# x = torch.randn((2,3), device=\"cuda\")\n",
    "# print(x)\n",
    "# print(torch.mean(x, axis=-1, keepdims=True), torch.std(x, axis=-1, keepdims = True))\n",
    "# from model_torch_func import init_layernorm_layer\n",
    "# #params = init_layernorm_layer(3) # replace 1, 0s\n",
    "# params = torch.randn((3, ), device=\"cuda\"), torch.zeros((3,), device=\"cuda\")\n",
    "\n",
    "# from model_triton import t_layernorm_bkwd_p\n",
    "# res1 = jacrev(t_layernorm_fwd)(params, x)\n",
    "# res2 = t_layernorm_bkwd_p(params, x)\n",
    "# print(res1[0].shape, res1[0])\n",
    "# print(\"--\")\n",
    "# print(res2[0].shape, res2[0])\n",
    "\n",
    "# from model_triton import t_layernorm_bkwd_x\n",
    "# res1 = jacrev(t_layernorm_fwd, argnums=1)(params, x)\n",
    "# res2 = t_layernorm_bkwd_x(params, x)\n",
    "# print(res1.shape, res1)\n",
    "# print(\"--\")\n",
    "# print(res2.shape, res2)\n",
    "\n",
    "\n",
    "# TLAYER_FFN\n",
    "# aa = torch.randn((3,2), device=\"cuda\")\n",
    "# print(aa)\n",
    "# from model_torch_func import init_tlayer_ffn\n",
    "# from model_triton import t_tlayer_ffn_fwd, t_gelu_fwd, t_linear_bkwd_p, t_gelu_bkwd\n",
    "# from functools import partial\n",
    "# fn = partial(t_tlayer_ffn_fwd, activation_fn=t_gelu_fwd)\n",
    "# params = init_tlayer_ffn(2, 4)\n",
    "# print(fn(params, aa))\n",
    "# print(params[0].shape, params[1].shape)\n",
    "# print(\"--\")\n",
    "\n",
    "# res = jacrev(fn, argnums=0)(params, aa)\n",
    "# print(res[0].shape, res[1].shape, res[2].shape, res[3].shape)\n",
    "# print(res[0],res[1])\n",
    "# #print(res[2], res[3])\n",
    "\n",
    "# res2 = t_tlayer_ffn_bkwd_p(params, aa, t_gelu_fwd)\n",
    "# print(res2[0].shape, res2[1].shape, res2[2].shape, res2[3].shape)\n",
    "# print(res2[0], res2[1])\n",
    "# print(res2[2], res2[3])\n",
    "\n",
    "# res = jacrev(fn, argnums=1)(params, aa)\n",
    "# print(res.shape)\n",
    "# print(res)\n",
    "\n",
    "# res2 = t_tlayer_ffn_bkwd_x(params, aa, t_gelu_fwd)\n",
    "# print(res2.shape)\n",
    "# print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71ec72ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.764597,  0.521342],\n",
      "         [ 1.225475,  1.405953],\n",
      "         [-0.352109,  1.071642]],\n",
      "\n",
      "        [[-0.258679, -0.220236],\n",
      "         [ 0.091375, -0.252992],\n",
      "         [-0.352096, -0.383530]]])\n",
      "torch.Size([2, 3, 4, 4, 2]) torch.Size([2, 3, 4, 4])\n",
      "tensor([[[[1., 0., 0., 0.],\n",
      "          [0., 1., 0., 0.],\n",
      "          [0., 0., 1., 0.],\n",
      "          [0., 0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0., 0.],\n",
      "          [0., 1., 0., 0.],\n",
      "          [0., 0., 1., 0.],\n",
      "          [0., 0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0., 0.],\n",
      "          [0., 1., 0., 0.],\n",
      "          [0., 0., 1., 0.],\n",
      "          [0., 0., 0., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 0., 0.],\n",
      "          [0., 1., 0., 0.],\n",
      "          [0., 0., 1., 0.],\n",
      "          [0., 0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0., 0.],\n",
      "          [0., 1., 0., 0.],\n",
      "          [0., 0., 1., 0.],\n",
      "          [0., 0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0., 0.],\n",
      "          [0., 1., 0., 0.],\n",
      "          [0., 0., 1., 0.],\n",
      "          [0., 0., 0., 1.]]]])\n",
      "torch.Size([2, 3, 4, 4, 2]) torch.Size([2, 3, 4, 4])\n",
      "tensor([[[[1., 0., 0., 0.],\n",
      "          [0., 1., 0., 0.],\n",
      "          [0., 0., 1., 0.],\n",
      "          [0., 0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0., 0.],\n",
      "          [0., 1., 0., 0.],\n",
      "          [0., 0., 1., 0.],\n",
      "          [0., 0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0., 0.],\n",
      "          [0., 1., 0., 0.],\n",
      "          [0., 0., 1., 0.],\n",
      "          [0., 0., 0., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 0., 0.],\n",
      "          [0., 1., 0., 0.],\n",
      "          [0., 0., 1., 0.],\n",
      "          [0., 0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0., 0.],\n",
      "          [0., 1., 0., 0.],\n",
      "          [0., 0., 1., 0.],\n",
      "          [0., 0., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0., 0.],\n",
      "          [0., 1., 0., 0.],\n",
      "          [0., 0., 1., 0.],\n",
      "          [0., 0., 0., 1.]]]])\n"
     ]
    }
   ],
   "source": [
    "# Linear\n",
    "aa = torch.randn((2,3,2))\n",
    "print(aa)\n",
    "params = (torch.randn((4,2)), torch.randn((4,)))\n",
    "res = jacrev(t_linear_fwd)(params, aa)\n",
    "print(res[0].shape, res[1].shape)\n",
    "print(res[1])\n",
    "\n",
    "def t_linear_bkwd_p(layer_params, x): # input: N x D\n",
    "    outdim = layer_params[1].shape[0]\n",
    "\n",
    "    jac1 = t_proj_bkwd_p(layer_params[0], x)\n",
    "    jac2 = torch.eye(outdim, device=x.device).expand(x.shape[:-1] + (outdim, outdim))\n",
    "    return jac1, jac2\n",
    "\n",
    "res2 = t_linear_bkwd_p(params, aa)\n",
    "print(res2[0].shape, res2[1].shape)\n",
    "print(res2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de427c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.901137,  1.467101],\n",
       "         [-0.212698,  0.167734],\n",
       "         [-1.033636,  1.201384]]], device='cuda:0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = torch.randn((1, 3,2), device=\"cuda\")\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e6bd76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.811023,  1.320391],\n",
      "         [-0.191428,  0.150961],\n",
      "         [-0.930272,  1.081246]]], device='cuda:0')\n",
      "torch.Size([1, 3, 2, 1, 3, 2]) tensor([[[[[[0.900000, 0.000000],\n",
      "            [0.000000, 0.000000],\n",
      "            [0.000000, 0.000000]]],\n",
      "\n",
      "\n",
      "          [[[0.000000, 0.900000],\n",
      "            [0.000000, 0.000000],\n",
      "            [0.000000, 0.000000]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[0.000000, 0.000000],\n",
      "            [0.900000, 0.000000],\n",
      "            [0.000000, 0.000000]]],\n",
      "\n",
      "\n",
      "          [[[0.000000, 0.000000],\n",
      "            [0.000000, 0.900000],\n",
      "            [0.000000, 0.000000]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[0.000000, 0.000000],\n",
      "            [0.000000, 0.000000],\n",
      "            [0.900000, 0.000000]]],\n",
      "\n",
      "\n",
      "          [[[0.000000, 0.000000],\n",
      "            [0.000000, 0.000000],\n",
      "            [0.000000, 0.900000]]]]]], device='cuda:0')\n",
      "torch.Size([1, 3, 2, 1, 3, 2]) tensor([[[[[[0.900000, 0.000000],\n",
      "            [0.000000, 0.000000],\n",
      "            [0.000000, 0.000000]]],\n",
      "\n",
      "\n",
      "          [[[0.000000, 0.900000],\n",
      "            [0.000000, 0.000000],\n",
      "            [0.000000, 0.000000]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[0.000000, 0.000000],\n",
      "            [0.900000, 0.000000],\n",
      "            [0.000000, 0.000000]]],\n",
      "\n",
      "\n",
      "          [[[0.000000, 0.000000],\n",
      "            [0.000000, 0.900000],\n",
      "            [0.000000, 0.000000]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[0.000000, 0.000000],\n",
      "            [0.000000, 0.000000],\n",
      "            [0.900000, 0.000000]]],\n",
      "\n",
      "\n",
      "          [[[0.000000, 0.000000],\n",
      "            [0.000000, 0.000000],\n",
      "            [0.000000, 0.900000]]]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# dropout train=False (Note that this jacobian is not needed..)\n",
    "from torch.func import grad, vjp, jacrev\n",
    "from model_triton import *\n",
    "res = t_dropout_fwd(aa, train=False)\n",
    "from functools import partial\n",
    "print(res)\n",
    "\n",
    "fn = partial(t_dropout_fwd, train=False)\n",
    "res = jacrev(fn)(aa)\n",
    "print(res.shape, res)\n",
    "\n",
    "res2 = t_dropout_bkwd(aa, train=False)\n",
    "print(res2.shape, res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6bf935d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 2, 1, 3, 2]) tensor([[[[[[1., 0.],\n",
      "            [0., 0.],\n",
      "            [0., 0.]]],\n",
      "\n",
      "\n",
      "          [[[0., 1.],\n",
      "            [0., 0.],\n",
      "            [0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[0., 0.],\n",
      "            [1., 0.],\n",
      "            [0., 0.]]],\n",
      "\n",
      "\n",
      "          [[[0., 0.],\n",
      "            [0., 1.],\n",
      "            [0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[0., 0.],\n",
      "            [0., 0.],\n",
      "            [1., 0.]]],\n",
      "\n",
      "\n",
      "          [[[0., 0.],\n",
      "            [0., 0.],\n",
      "            [0., 1.]]]]]], device='cuda:0')\n",
      "---\n",
      "torch.Size([1, 3, 2, 1, 3, 2]) tensor([[[[[[1., 0.],\n",
      "            [0., 0.],\n",
      "            [0., 0.]]],\n",
      "\n",
      "\n",
      "          [[[0., 1.],\n",
      "            [0., 0.],\n",
      "            [0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[0., 0.],\n",
      "            [1., 0.],\n",
      "            [0., 0.]]],\n",
      "\n",
      "\n",
      "          [[[0., 0.],\n",
      "            [0., 1.],\n",
      "            [0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[0., 0.],\n",
      "            [0., 0.],\n",
      "            [1., 0.]]],\n",
      "\n",
      "\n",
      "          [[[0., 0.],\n",
      "            [0., 0.],\n",
      "            [0., 1.]]]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# dropout train=True\n",
    "from torch.func import grad, vjp, jacrev\n",
    "from model_triton import *\n",
    "p_gen_aux = 42\n",
    "\n",
    "res = t_dropout_fwd(aa, train=True, p_gen_aux=p_gen_aux)\n",
    "from functools import partial\n",
    "#print(res)\n",
    "\n",
    "fn = partial(t_dropout_fwd, train=True, p_gen_aux=p_gen_aux)\n",
    "res = jacrev(fn)(aa)\n",
    "print(res.shape, res)\n",
    "print(f'---')\n",
    "\n",
    "res2 = t_dropout_bkwd(aa, train=True, p_gen_aux=p_gen_aux)\n",
    "print(res2.shape, res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ca753b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 torch.Size([2, 6, 4, 2, 4])\n",
      "tensor([[[[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0., 0.],\n",
      "           [2., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 2., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 2., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 2.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0., 0.],\n",
      "           [2., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 2., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 2., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 2.]]],\n",
      "\n",
      "\n",
      "         [[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]]]], device='cuda:0')\n",
      "1 torch.Size([2, 6, 4, 2, 4])\n",
      "tensor([[[[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0., 0.],\n",
      "           [2., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 2., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 2., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 2.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0., 0.],\n",
      "           [2., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 2., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 2., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 2.]]],\n",
      "\n",
      "\n",
      "         [[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]]]])\n"
     ]
    }
   ],
   "source": [
    "# Embed\n",
    "from model_torch_func import init_proj_layer\n",
    "params = (init_proj_layer(4, 2), )\n",
    "#aa =torch.tensor([1, 0, 1])\n",
    "aa = torch.randint(2, (2, 6))\n",
    "res=jacrev(t_embed_fwd)(params, aa)\n",
    "print(len(res), res[0].shape)\n",
    "print(res[0])\n",
    "\n",
    "res2=t_embed_bkwd(params, aa)\n",
    "print(len(res2), res2[0].shape)\n",
    "print(res2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9d620d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.9504,  0.5064],\n",
      "         [-1.1646, -0.3184],\n",
      "         [ 0.3456,  0.1814]]], device='cuda:0')\n",
      "tensor([[[    -0.0001,     -0.0001],\n",
      "         [     0.0002,      0.0002],\n",
      "         [    -0.0001,     -0.0001]]], device='cuda:0')\n",
      "torch.Size([4, 2]) torch.Size([4])\n",
      "--\n",
      "torch.Size([1, 3, 2, 1, 3, 2])\n",
      "tensor([[[[[[    -0.0001,     -0.0004],\n",
      "            [     0.0000,      0.0000],\n",
      "            [     0.0000,      0.0000]]],\n",
      "\n",
      "\n",
      "          [[[    -0.0001,     -0.0003],\n",
      "            [     0.0000,      0.0000],\n",
      "            [     0.0000,      0.0000]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[     0.0000,      0.0000],\n",
      "            [    -0.0001,     -0.0004],\n",
      "            [     0.0000,      0.0000]]],\n",
      "\n",
      "\n",
      "          [[[     0.0000,      0.0000],\n",
      "            [    -0.0001,     -0.0003],\n",
      "            [     0.0000,      0.0000]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[     0.0000,      0.0000],\n",
      "            [     0.0000,      0.0000],\n",
      "            [    -0.0001,     -0.0004]]],\n",
      "\n",
      "\n",
      "          [[[     0.0000,      0.0000],\n",
      "            [     0.0000,      0.0000],\n",
      "            [    -0.0001,     -0.0003]]]]]], device='cuda:0')\n",
      "--\n",
      "torch.Size([1, 3, 2, 1, 3, 2])\n",
      "tensor([[[[[[    -0.0001,     -0.0004],\n",
      "            [     0.0000,      0.0000],\n",
      "            [     0.0000,      0.0000]]],\n",
      "\n",
      "\n",
      "          [[[    -0.0001,     -0.0003],\n",
      "            [     0.0000,      0.0000],\n",
      "            [     0.0000,      0.0000]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[     0.0000,      0.0000],\n",
      "            [    -0.0001,     -0.0004],\n",
      "            [     0.0000,      0.0000]]],\n",
      "\n",
      "\n",
      "          [[[     0.0000,      0.0000],\n",
      "            [    -0.0001,     -0.0003],\n",
      "            [     0.0000,      0.0000]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[     0.0000,      0.0000],\n",
      "            [     0.0000,      0.0000],\n",
      "            [    -0.0001,     -0.0004]]],\n",
      "\n",
      "\n",
      "          [[[     0.0000,      0.0000],\n",
      "            [     0.0000,      0.0000],\n",
      "            [    -0.0001,     -0.0003]]]]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:767: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:135.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "# TLAYER_FFN\n",
    "aa = torch.randn((1, 3,2), device=\"cuda\")\n",
    "print(aa)\n",
    "from model_torch_func import init_tlayer_ffn\n",
    "from model_triton import t_tlayer_ffn_fwd, t_gelu_fwd, t_linear_bkwd_p, t_gelu_bkwd\n",
    "from functools import partial\n",
    "fn = partial(t_tlayer_ffn_fwd, activation_fn=t_gelu_fwd)\n",
    "params = init_tlayer_ffn(2, 4)\n",
    "print(fn(params, aa))\n",
    "print(params[0].shape, params[1].shape)\n",
    "print(\"--\")\n",
    "\n",
    "# res = jacrev(fn, argnums=0)(params, aa)\n",
    "# print(res[0].shape, res[1].shape, res[2].shape, res[3].shape)\n",
    "# print(res[0],res[1])\n",
    "# print(res[2], res[3])\n",
    "# print(\"--\")\n",
    "\n",
    "# res2 = t_tlayer_ffn_bkwd_p(params, aa, t_gelu_fwd)\n",
    "# print(res2[0].shape, res2[1].shape, res2[2].shape, res2[3].shape)\n",
    "# print(res2[0], res2[1])\n",
    "# print(res2[2], res2[3])\n",
    "\n",
    "res = jacrev(fn, argnums=1)(params, aa)\n",
    "print(res.shape)\n",
    "print(res)\n",
    "print(\"--\")\n",
    "\n",
    "# def t_tlayer_ffn_bkwd_x(layer_params, x, activation_fn):\n",
    "#     x_2d = x.reshape((-1, x.shape[-1]))\n",
    "    \n",
    "#     act_fn_bkwd = t_gelu_bkwd if activation_fn==t_gelu_fwd else t_relu_bkwd\n",
    "    \n",
    "#     dffn1_dx = t_linear_bkwd_x((layer_params[0], layer_params[1]), x_2d)\n",
    "#     x_2d = t_linear_fwd((layer_params[0], layer_params[1]), x_2d)\n",
    "#     dact_dx = act_fn_bkwd(x_2d)\n",
    "#     x_2d = activation_fn(x_2d)\n",
    "#     dffn2_dx = t_linear_bkwd_x((layer_params[2], layer_params[3]), x_2d)\n",
    "#     dffn2_act_dx = dact_dx * dffn2_dx #Note dact_dx is only 2D, but torch will add other dims\n",
    "#     jac = torch.einsum('abcd,cdef->abef', dffn2_act_dx, dffn1_dx)\n",
    "#     return jac.reshape(x.shape+x.shape)\n",
    "\n",
    "res2 = t_tlayer_ffn_bkwd_x(params, aa, t_gelu_fwd)\n",
    "print(res2.shape)\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a443338f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (454213176.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(torch.matmul(aa, params.reshape((-1, params.shape[-1])).transpose(-2, -1)).)\u001b[0m\n\u001b[0m                                                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from model_triton import *\n",
    "aa = torch.arange(8).reshape((2,2,2))\n",
    "params = torch.arange(12).reshape((2, 3, 2))\n",
    "\n",
    "print(torch.matmul(aa, params.reshape((-1, params.shape[-1])).transpose(-2, -1)).)\n",
    "print(torch.matmul(aa, params.transpose(-2, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c7ebd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 2, 3]) tensor([[[[ 0.7874, -0.8682,  1.7077],\n",
      "          [ 0.3367,  2.4793, -0.9132]],\n",
      "\n",
      "         [[-0.6759,  0.5020,  2.1995],\n",
      "          [-0.4050,  0.4044, -1.4075]],\n",
      "\n",
      "         [[ 1.8927,  0.2770,  0.1400],\n",
      "          [-2.3340, -0.5911,  1.1458]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0719,  0.8006, -0.3591],\n",
      "          [ 0.8510, -2.5076, -1.9545]],\n",
      "\n",
      "         [[-0.3017,  0.7745, -2.8226],\n",
      "          [ 0.2864, -0.8024,  1.7334]],\n",
      "\n",
      "         [[ 1.6732, -1.1712,  0.1737],\n",
      "          [ 1.7747, -0.5364, -1.2671]]]])\n",
      "--\n",
      "torch.Size([2, 3, 2, 3, 2, 3, 3, 2])\n",
      "--\n",
      "torch.Size([2, 3, 2, 3, 2, 3, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# Proj\n",
    "import torch\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "from torch.func import grad, vjp, jacrev\n",
    "from model_triton import *\n",
    "aa = torch.randn((1, 3, 2, 2))\n",
    "#print(aa)\n",
    "params = torch.randn((2, 3, 3, 2))\n",
    "output = t_proj_fwd(params, aa)\n",
    "print(output.shape, output)\n",
    "print(\"--\")\n",
    "res = jacrev(t_proj_fwd)(params, aa)\n",
    "print(res.shape)\n",
    "#print(res)\n",
    "print(\"--\")\n",
    "res2 = t_proj_bkwd_p(params, aa)\n",
    "print(res2.shape)\n",
    "#print(res2)\n",
    "# res = jacrev(t_proj_fwd, argnums=1)(params, aa)\n",
    "# print(res.shape, res)\n",
    "# res2 = t_proj_bkwd_x(params, aa)\n",
    "# print(res2.shape, res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13ecc401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 2, 2, 1, 1, 2, 4]) torch.Size([1, 1, 2, 2, 1, 1, 2, 4])\n",
      "tensor([[[[[[[[ 0.001104, -0.000665, -0.001077,  0.000701],\n",
      "              [ 0.000000,  0.000000,  0.000000,  0.000000]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[-0.001104,  0.000665,  0.001077, -0.000701],\n",
      "              [ 0.000000,  0.000000,  0.000000,  0.000000]]]]],\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          [[[[[ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "              [ 0.001111, -0.000669, -0.001084,  0.000706]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "              [-0.001111,  0.000669,  0.001084, -0.000706]]]]]]]],\n",
      "       device='cuda:0')\n",
      "--\n",
      "torch.Size([1, 1, 2, 2, 1, 1, 2, 4]) torch.Size([1, 1, 2, 2, 1, 1, 2, 4])\n",
      "tensor([[[[[[[[ 0.001104, -0.000665, -0.001077,  0.000701],\n",
      "              [ 0.000000,  0.000000,  0.000000,  0.000000]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[-0.001104,  0.000665,  0.001077, -0.000701],\n",
      "              [ 0.000000,  0.000000,  0.000000,  0.000000]]]]],\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          [[[[[ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "              [ 0.001111, -0.000669, -0.001084,  0.000706]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "              [-0.001111,  0.000669,  0.001084, -0.000706]]]]]]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# t_scaled_dot_prod_attn: numerical instablity in attn_bkwd\n",
    "import torch\n",
    "torch.set_printoptions(precision=6)\n",
    "from torch.func import jacrev\n",
    "from model_triton import *\n",
    "BS, H, N, D = 1, 1, 2, 4 #Works for 3, 2, 2, 1!\n",
    "qkv= torch.randn((BS, H, 3, N, D), device=\"cuda\")\n",
    "mask = torch.ones((BS, N, N), dtype=torch.bool, device=\"cuda\")\n",
    "from functools import partial\n",
    "\n",
    "def attn_fwd(q, k, mask):\n",
    "    attn = torch.matmul(q, torch.transpose(k, -2, -1))\n",
    "    attn = attn / math.sqrt(D)\n",
    "    attn = torch.where(torch.unsqueeze(mask,dim=1), attn, torch.full_like(attn, -1e9)) # Note, instead of usign -jnp.inf, which results in NaNs (NIT: probably better to use jax.numpy.finfo)\n",
    "    return torch.exp(t_log_softmax_fwd(attn)) #TODO XXX: numerical stability\n",
    "\n",
    "q, k, _ = torch.unbind(qkv, dim=2)\n",
    "# #fn = partial(attn_fwd, mask=mask) #this works\n",
    "fn = partial(t_softmax_attn_fwd, mask=mask, train=False)\n",
    "res1 = jacrev(fn)(q, k)\n",
    "res2 = jacrev(fn, argnums=1)(q, k)\n",
    "print(res1.shape, res2.shape)\n",
    "print(res1)\n",
    "#print(res2)\n",
    "print(\"--\")\n",
    "\n",
    "### Repro for numerical isntability!\n",
    "def attn_bkwd(q, k, mask): # Do all ops in 3d instead of 4d\n",
    "    attn = torch.matmul(q, torch.transpose(k, -2, -1))\n",
    "    attn = attn / math.sqrt(D)\n",
    "    attn = torch.where(torch.unsqueeze(mask,dim=1), attn, torch.full_like(attn, -1e9)) # Note, instead of usign -jnp.inf, which results in NaNs (NIT: probably better to use jax.numpy.finfo)\n",
    "    dattn_dx = torch.exp(t_log_softmax_fwd(attn))[..., None, None, None, None] * t_log_softmax_bkwd(attn) \n",
    "    #dattn_dx = t_log_softmax_bkwd(attn) # TODO XXX: numerical stability\n",
    "    jac1 = torch.matmul(dattn_dx, k/math.sqrt(D))\n",
    "    jac2 = torch.matmul(q.transpose(-2,-1)/math.sqrt(D), dattn_dx).transpose(-2,-1)\n",
    "    return jac1, jac2\n",
    "\n",
    "# This works modulo numerical instability\n",
    "# res2 = attn_bkwd(q, k, mask)\n",
    "# print(res2[0].shape, res2[1].shape)\n",
    "# print(res2[0])\n",
    "# print(res2[1])\n",
    "\n",
    "from model_triton import _mult_jacs_in_2d\n",
    "\n",
    "# def t_softmax_attn_bkwd(q, k, mask, train):\n",
    "#     D = q.shape[-1]\n",
    "#     attn = torch.matmul(q, torch.transpose(k, -2, -1))\n",
    "#     attn = attn / math.sqrt(D)\n",
    "#     attn = torch.where(torch.unsqueeze(mask,dim=1), attn, torch.full_like(attn, -1e9)) # Note, instead of usign -jnp.inf, which results in NaNs (NIT: probably better to use jax.numpy.finfo)\n",
    "#     # TODO XXX: would the below line cause numerical stabliity issues?\n",
    "#     sa = torch.exp(t_log_softmax_fwd(attn)) \n",
    "#     #sa = t_dropout_fwd(sa, train)\n",
    "#     jac_dropout = t_dropout_bkwd(sa, train)\n",
    "#     #TODO: Note, we are overloading _mult.., as right is not Jacobian...\n",
    "#     sa = _mult_jacs_in_2d(jac_dropout, [sa], sa)[0] \n",
    "    \n",
    "#     # TODO XXX: Clean up below..\n",
    "#     d_dropout_dx = 1 #0.9 # TODO: XXX add proper dropout \n",
    "#     jac_sa_x = d_dropout_dx * sa[..., None, None, None, None] * t_log_softmax_bkwd(attn)\n",
    "#     jac1 = torch.matmul(jac_sa_x, k/math.sqrt(D))\n",
    "#     jac2 = torch.matmul(q.transpose(-2,-1), jac_sa_x/math.sqrt(D)).transpose(-2,-1)\n",
    "#     # Account for mask:\n",
    "#     jac_mask = torch.unsqueeze(mask,dim=1)[..., None, None, None, None]\n",
    "#     jac1 = torch.where(jac_mask, jac1, 0)\n",
    "#     jac2 = torch.where(jac_mask, jac2, 0)\n",
    "#     return jac1, jac2\n",
    "\n",
    "# This works modulo numerical instability\n",
    "res2 = t_softmax_attn_bkwd(q, k, mask, False)\n",
    "print(res2[0].shape, res2[1].shape)\n",
    "print(res2[0])\n",
    "#print(res2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57708f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[[[[-0.011142,  0.017495],\n",
      "              [ 0.000000,  0.000000]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.011142, -0.017495],\n",
      "              [ 0.000000,  0.000000]]]]],\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          [[[[[ 0.000000,  0.000000],\n",
      "              [-0.143701,  0.225636]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.000000,  0.000000],\n",
      "              [ 0.143701, -0.225636]]]]]]]], device='cuda:0')\n",
      "tensor([[[[[[[[-0.013766,  0.014875],\n",
      "              [ 0.013766, -0.014875]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.013766, -0.014875],\n",
      "              [-0.013766,  0.014875]]]]],\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          [[[[[-0.106701,  0.024888],\n",
      "              [ 0.106701, -0.024888]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.106701, -0.024888],\n",
      "              [-0.106701,  0.024888]]]]]]]], device='cuda:0')\n",
      "--\n",
      "torch.Size([1, 1, 2, 2, 1, 1, 2, 2]) torch.Size([1, 1, 2, 2, 1, 1, 2, 2])\n",
      "tensor([[[[[[[[-0.011142,  0.017495],\n",
      "              [ 0.000000,  0.000000]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.011142, -0.017495],\n",
      "              [ 0.000000,  0.000000]]]]],\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          [[[[[ 0.000000,  0.000000],\n",
      "              [-0.143701,  0.225636]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.000000,  0.000000],\n",
      "              [ 0.143701, -0.225636]]]]]]]], device='cuda:0')\n",
      "tensor([[[[[[[[-0.013766,  0.014875],\n",
      "              [ 0.013766, -0.014875]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.013766, -0.014875],\n",
      "              [-0.013766,  0.014875]]]]],\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          [[[[[-0.106701,  0.024888],\n",
      "              [ 0.106701, -0.024888]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.106701, -0.024888],\n",
      "              [-0.106701,  0.024888]]]]]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# t_softmax_attn_bkwd: mask + train=False\n",
    "import torch\n",
    "torch.set_printoptions(precision=6)\n",
    "from torch.func import jacrev\n",
    "from model_triton import *\n",
    "BS, H, N, D = 1, 1, 2, 2 #Works for 3, 2, 2, 1!\n",
    "qkv= torch.randn((BS, H, 3, N, D), device=\"cuda\")\n",
    "mask = torch.ones((BS, N, N), dtype=torch.bool, device=\"cuda\")\n",
    "# for i, i_mask in enumerate(mask):\n",
    "#     mask[i] = torch.tril(i_mask)\n",
    "#    mask[i] = torch.zeros_like(i_mask)\n",
    "from functools import partial\n",
    "\n",
    "q, k, _ = torch.unbind(qkv, dim=2)\n",
    "# #fn = partial(attn_fwd, mask=mask) #this works\n",
    "fn = partial(t_softmax_attn_fwd, mask=mask, train=False)\n",
    "res1 = jacrev(fn)(q, k)\n",
    "res2 = jacrev(fn, argnums=1)(q, k)\n",
    "#print(res1.shape, res2.shape)\n",
    "print(res1)\n",
    "print(res2)\n",
    "print(\"--\")\n",
    "\n",
    "# This works modulo numerical instability\n",
    "res2 = t_softmax_attn_bkwd(q, k, mask, False)\n",
    "print(res2[0].shape, res2[1].shape)\n",
    "print(res2[0])\n",
    "print(res2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaf437e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[[[[ 0.018750, -0.003784],\n",
      "              [ 0.000000,  0.000000]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[-0.018750,  0.003784],\n",
      "              [ 0.000000,  0.000000]]]]],\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          [[[[[ 0.000000,  0.000000],\n",
      "              [ 0.018709, -0.003776]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.000000,  0.000000],\n",
      "              [-0.018709,  0.003776]]]]]]]], device='cuda:0')\n",
      "tensor([[[[[[[[-0.106762, -0.111337],\n",
      "              [ 0.106762,  0.111337]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.106762,  0.111337],\n",
      "              [-0.106762, -0.111337]]]]],\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          [[[[[-0.226691,  0.041643],\n",
      "              [ 0.226691, -0.041643]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.226691, -0.041643],\n",
      "              [-0.226691,  0.041643]]]]]]]], device='cuda:0')\n",
      "--\n",
      "torch.Size([1, 1, 2, 2, 1, 1, 2, 2]) torch.Size([1, 1, 2, 2, 1, 1, 2, 2])\n",
      "tensor([[[[[[[[ 0.018750, -0.003784],\n",
      "              [ 0.000000,  0.000000]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[-0.018750,  0.003784],\n",
      "              [ 0.000000,  0.000000]]]]],\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          [[[[[ 0.000000,  0.000000],\n",
      "              [ 0.018709, -0.003776]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.000000,  0.000000],\n",
      "              [-0.018709,  0.003776]]]]]]]], device='cuda:0')\n",
      "tensor([[[[[[[[-0.106762, -0.111337],\n",
      "              [ 0.106762,  0.111337]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.106762,  0.111337],\n",
      "              [-0.106762, -0.111337]]]]],\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          [[[[[-0.226691,  0.041643],\n",
      "              [ 0.226691, -0.041643]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.226691, -0.041643],\n",
      "              [-0.226691,  0.041643]]]]]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# t_softmax_attn_bkwd: mask + train=True\n",
    "import torch\n",
    "torch.set_printoptions(precision=6)\n",
    "from torch.func import jacrev\n",
    "from model_triton import *\n",
    "BS, H, N, D = 1, 1, 2, 2 #Works for 3, 2, 2, 1!\n",
    "p_gen_aux = 42\n",
    "qkv= torch.randn((BS, H, 3, N, D), device=\"cuda\")\n",
    "mask = torch.ones((BS, N, N), dtype=torch.bool, device=\"cuda\")\n",
    "# for i, i_mask in enumerate(mask):\n",
    "#     mask[i] = torch.tril(i_mask)\n",
    "#    mask[i] = torch.zeros_like(i_mask)\n",
    "from functools import partial\n",
    "\n",
    "q, k, _ = torch.unbind(qkv, dim=2)\n",
    "# #fn = partial(attn_fwd, mask=mask) #this works\n",
    "fn = partial(t_softmax_attn_fwd, mask=mask, train=True, p_gen_aux=p_gen_aux)\n",
    "res1 = jacrev(fn)(q, k)\n",
    "res2 = jacrev(fn, argnums=1)(q, k)\n",
    "#print(res1.shape, res2.shape)\n",
    "print(res1)\n",
    "print(res2)\n",
    "print(\"--\")\n",
    "\n",
    "# This works modulo numerical instability\n",
    "res2 = t_softmax_attn_bkwd(q, k, mask, True, p_gen_aux)\n",
    "print(res2[0].shape, res2[1].shape)\n",
    "print(res2[0])\n",
    "print(res2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c6196f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 2, 4, 1, 1, 2, 4]) torch.Size([1, 1, 2, 4, 1, 1, 2, 4]) torch.Size([1, 1, 2, 4, 1, 1, 2, 4])\n",
      "tensor([[[[[[[[-0.036859,  0.082568,  0.102044, -0.241970],\n",
      "              [ 0.000000,  0.000000,  0.000000,  0.000000]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.012432, -0.027849, -0.034417,  0.081612],\n",
      "              [ 0.000000,  0.000000,  0.000000,  0.000000]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.045745, -0.102473, -0.126645,  0.300305],\n",
      "              [ 0.000000,  0.000000,  0.000000,  0.000000]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.005014, -0.011233, -0.013882,  0.032919],\n",
      "              [ 0.000000,  0.000000,  0.000000,  0.000000]]]]],\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          [[[[[ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "              [-0.035206,  0.078865,  0.097468, -0.231120]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "              [ 0.011874, -0.026600, -0.032874,  0.077953]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "              [ 0.043694, -0.097878, -0.120966,  0.286840]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "              [ 0.004790, -0.010729, -0.013260,  0.031442]]]]]]]],\n",
      "       device='cuda:0')\n",
      "--\n",
      "torch.Size([1, 1, 2, 4, 1, 1, 2, 4]) torch.Size([1, 1, 2, 4, 1, 1, 2, 4]) torch.Size([1, 1, 2, 4, 1, 1, 2, 4])\n",
      "tensor([[[[[[[[-0.036859,  0.082568,  0.102044, -0.241970],\n",
      "              [ 0.000000,  0.000000,  0.000000,  0.000000]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.012432, -0.027849, -0.034417,  0.081612],\n",
      "              [ 0.000000,  0.000000,  0.000000,  0.000000]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.045745, -0.102473, -0.126645,  0.300305],\n",
      "              [ 0.000000,  0.000000,  0.000000,  0.000000]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.005014, -0.011233, -0.013882,  0.032919],\n",
      "              [ 0.000000,  0.000000,  0.000000,  0.000000]]]]],\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          [[[[[ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "              [-0.035206,  0.078865,  0.097468, -0.231120]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "              [ 0.011874, -0.026600, -0.032874,  0.077953]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "              [ 0.043694, -0.097878, -0.120966,  0.286839]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "              [ 0.004790, -0.010729, -0.013260,  0.031442]]]]]]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# t_scaled_dot_prod_attn + train=False\n",
    "import torch\n",
    "torch.set_printoptions(precision=6)\n",
    "from torch.func import jacrev\n",
    "from model_triton import *\n",
    "BS, H, N, D = 1, 1, 2, 4\n",
    "qkv= torch.randn((BS, H, 3, N, D), device=\"cuda\")\n",
    "mask = torch.ones((BS, N, N), dtype=torch.bool, device=\"cuda\")\n",
    "from functools import partial\n",
    "\n",
    "#output1 = t_scaled_dot_prod_attn_fwd(qkv, mask, False)\n",
    "\n",
    "fn = partial(t_scaled_dot_prod_attn_fwd, mask=mask, train=False)\n",
    "res = jacrev(fn)(qkv)\n",
    "# print(res.shape)\n",
    "dq,dk,dv = res.unbind(-3)\n",
    "print(dq.shape, dk.shape, dv.shape)\n",
    "print(dq)\n",
    "#print(dk)\n",
    "#print(dv)\n",
    "print(\"--\")\n",
    "\n",
    "from model_triton import _mult_jacs_in_2d\n",
    "\n",
    "res2 = t_scaled_dot_prod_attn_bkwd(qkv, mask, False)\n",
    "print(res2[0].shape, res2[1].shape, res2[2].shape)\n",
    "print(res2[0])\n",
    "#print(res2[1])\n",
    "#print(res2[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97a103fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 2, 4, 1, 1, 2, 4]) torch.Size([1, 1, 2, 4, 1, 1, 2, 4]) torch.Size([1, 1, 2, 4, 1, 1, 2, 4])\n",
      "tensor([[[[[[[[-0.041449,  0.025426, -0.049119,  0.098434],\n",
      "              [ 0.000000,  0.000000,  0.000000,  0.000000]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.040940, -0.025114,  0.048515, -0.097226],\n",
      "              [ 0.000000,  0.000000,  0.000000,  0.000000]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[-0.127264,  0.078069, -0.150814,  0.302233],\n",
      "              [ 0.000000,  0.000000,  0.000000,  0.000000]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[-0.026101,  0.016011, -0.030930,  0.061985],\n",
      "              [ 0.000000,  0.000000,  0.000000,  0.000000]]]]],\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          [[[[[ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "              [-0.035494,  0.021774, -0.042063,  0.084294]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "              [ 0.035059, -0.021506,  0.041546, -0.083259]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "              [-0.108982,  0.066854, -0.129149,  0.258816]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "              [-0.022351,  0.013711, -0.026487,  0.053081]]]]]]]],\n",
      "       device='cuda:0')\n",
      "--\n",
      "torch.Size([1, 1, 2, 4, 1, 1, 2, 4]) torch.Size([1, 1, 2, 4, 1, 1, 2, 4]) torch.Size([1, 1, 2, 4, 1, 1, 2, 4])\n",
      "tensor([[[[[[[[-0.041449,  0.025426, -0.049119,  0.098434],\n",
      "              [ 0.000000,  0.000000,  0.000000,  0.000000]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.040940, -0.025114,  0.048515, -0.097226],\n",
      "              [ 0.000000,  0.000000,  0.000000,  0.000000]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[-0.127264,  0.078069, -0.150814,  0.302233],\n",
      "              [ 0.000000,  0.000000,  0.000000,  0.000000]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[-0.026101,  0.016011, -0.030930,  0.061985],\n",
      "              [ 0.000000,  0.000000,  0.000000,  0.000000]]]]],\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          [[[[[ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "              [-0.035494,  0.021774, -0.042063,  0.084294]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "              [ 0.035059, -0.021506,  0.041546, -0.083259]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "              [-0.108982,  0.066854, -0.129149,  0.258816]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "              [-0.022351,  0.013711, -0.026487,  0.053081]]]]]]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:767: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:135.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "# t_scaled_dot_prod_attn + train=True\n",
    "import torch\n",
    "torch.set_printoptions(precision=6)\n",
    "from torch.func import jacrev\n",
    "from model_triton import *\n",
    "BS, H, N, D = 1, 1, 2, 4\n",
    "p_gen_aux = 42\n",
    "qkv= torch.randn((BS, H, 3, N, D), device=\"cuda\")\n",
    "mask = torch.ones((BS, N, N), dtype=torch.bool, device=\"cuda\")\n",
    "from functools import partial\n",
    "\n",
    "#output1 = t_scaled_dot_prod_attn_fwd(qkv, mask, False)\n",
    "\n",
    "fn = partial(t_scaled_dot_prod_attn_fwd, mask=mask, train=True, p_gen_aux=p_gen_aux)\n",
    "res = jacrev(fn)(qkv)\n",
    "# print(res.shape)\n",
    "dq,dk,dv = res.unbind(-3)\n",
    "print(dq.shape, dk.shape, dv.shape)\n",
    "print(dq)\n",
    "#print(dk)\n",
    "#print(dv)\n",
    "print(\"--\")\n",
    "\n",
    "from model_triton import _mult_jacs_in_2d\n",
    "\n",
    "res2 = t_scaled_dot_prod_attn_bkwd(qkv, mask, True, p_gen_aux)\n",
    "print(res2[0].shape, res2[1].shape, res2[2].shape)\n",
    "print(res2[0])\n",
    "#print(res2[1])\n",
    "#print(res2[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0420c177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_params torch.Size([2, 3, 2, 4])\n",
      "output torch.Size([1, 2, 2, 2])\n",
      "3 torch.Size([1, 2, 2, 2, 1, 2, 4]) torch.Size([1, 2, 2, 2, 1, 2, 4]) torch.Size([1, 2, 2, 2, 1, 2, 4])\n",
      "tensor([[[[[[[-9.023733e-06, -5.758845e-06, -1.051356e-06,  5.490635e-06],\n",
      "             [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "           [[[-5.143159e-06, -3.282307e-06, -5.992299e-07,  3.129438e-06],\n",
      "             [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]]],\n",
      "\n",
      "\n",
      "\n",
      "          [[[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "             [-9.023734e-06, -5.758847e-06, -1.051356e-06,  5.490637e-06]]],\n",
      "\n",
      "\n",
      "           [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "             [-5.143162e-06, -3.282309e-06, -5.992304e-07,  3.129440e-06]]]]],\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "         [[[[[-3.768324e-06, -1.482875e-06,  9.540058e-07,  2.383768e-06],\n",
      "             [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "           [[[ 5.717741e-06,  2.249991e-06, -1.447529e-06, -3.616930e-06],\n",
      "             [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]]],\n",
      "\n",
      "\n",
      "\n",
      "          [[[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "             [-3.768324e-06, -1.482875e-06,  9.540058e-07,  2.383768e-06]]],\n",
      "\n",
      "\n",
      "           [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "             [ 5.717741e-06,  2.249991e-06, -1.447529e-06, -3.616931e-06]]]]]]],\n",
      "       device='cuda:0')\n",
      "--\n",
      "3 torch.Size([1, 2, 2, 2, 1, 2, 4]) torch.Size([1, 2, 2, 2, 1, 2, 4]) torch.Size([1, 2, 2, 2, 1, 2, 4])\n",
      "tensor([[[[[[[-9.023731e-06, -5.758844e-06, -1.051356e-06,  5.490635e-06],\n",
      "             [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "           [[[-5.143159e-06, -3.282307e-06, -5.992298e-07,  3.129438e-06],\n",
      "             [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]]],\n",
      "\n",
      "\n",
      "\n",
      "          [[[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "             [-9.023731e-06, -5.758845e-06, -1.051356e-06,  5.490635e-06]]],\n",
      "\n",
      "\n",
      "           [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "             [-5.143160e-06, -3.282307e-06, -5.992300e-07,  3.129439e-06]]]]],\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "         [[[[[-3.768325e-06, -1.482875e-06,  9.540061e-07,  2.383768e-06],\n",
      "             [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "           [[[ 5.717741e-06,  2.249991e-06, -1.447529e-06, -3.616931e-06],\n",
      "             [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]]],\n",
      "\n",
      "\n",
      "\n",
      "          [[[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "             [-3.768325e-06, -1.482875e-06,  9.540065e-07,  2.383769e-06]]],\n",
      "\n",
      "\n",
      "           [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "             [ 5.717741e-06,  2.249991e-06, -1.447529e-06, -3.616931e-06]]]]]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# t_tlayer_attn_heads_fwd + train=False\n",
    "import torch\n",
    "torch.set_printoptions(precision=6)\n",
    "from torch.func import jacrev\n",
    "from model_torch_func import init_tlayer_attn_heads\n",
    "from model_triton import *\n",
    "BS, H, N, D = 1, 2, 2, 4\n",
    "layer_params = init_tlayer_attn_heads(D, H)\n",
    "qkv= torch.randn((BS, 3, N, D), device=\"cuda\").unbind(-3)\n",
    "mask = torch.ones((BS, N, N), dtype=torch.bool, device=\"cuda\")\n",
    "from functools import partial\n",
    "\n",
    "output = t_tlayer_attn_heads_fwd(layer_params, qkv, mask=mask, train=False)\n",
    "print(\"layer_params\", layer_params.shape)\n",
    "print(\"output\", output.shape)\n",
    "\n",
    "# fn = partial(t_tlayer_attn_heads_fwd, mask=mask, train=False)\n",
    "# res = jacrev(fn)(layer_params, qkv)\n",
    "# print(res.shape)\n",
    "# print(res)\n",
    "# print(\"--\")\n",
    "\n",
    "from model_triton import _mult_jacs_in_2d\n",
    "\n",
    "# print(\"--\")\n",
    "# res2 = t_tlayer_attn_heads_bkwd_p(layer_params, qkv, mask, False)\n",
    "# print(res2.shape)\n",
    "# print(res)\n",
    "\n",
    "fn = partial(t_tlayer_attn_heads_fwd, mask=mask, train=False)\n",
    "res = jacrev(fn, argnums=1)(layer_params, qkv)\n",
    "print(len(res), res[0].shape, res[1].shape, res[2].shape)\n",
    "print(res[0])\n",
    "print(\"--\")\n",
    "\n",
    "res2 = t_tlayer_attn_heads_bkwd_x(layer_params, qkv, mask, False)\n",
    "#print(res2.shape)\n",
    "print(len(res2), res2[0].shape, res2[1].shape, res2[2].shape)\n",
    "print(res2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04790b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_params torch.Size([2, 3, 2, 4])\n",
      "output torch.Size([1, 2, 2, 2])\n",
      "torch.Size([1, 2, 2, 2, 2, 3, 2, 4])\n",
      "tensor([[[[[[[[ 5.740308e-07, -1.442009e-06,  3.217673e-06, -1.204639e-05],\n",
      "              [ 2.437348e-06, -6.122803e-06,  1.366232e-05, -5.114925e-05]],\n",
      "\n",
      "             [[ 3.343014e-05, -4.790054e-06,  3.907021e-05,  3.111871e-05],\n",
      "              [ 2.655931e-05, -3.805566e-06,  3.104018e-05,  2.472294e-05]],\n",
      "\n",
      "             [[-7.261819e-01, -8.083431e-01, -5.263261e-01, -3.129264e-01],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "            [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[-4.369687e-07,  1.097699e-06, -2.449385e-06,  9.170058e-06],\n",
      "              [-1.855380e-06,  4.660856e-06, -1.040015e-05,  3.893630e-05]],\n",
      "\n",
      "             [[-2.544799e-05,  3.646332e-06, -2.974138e-05, -2.368847e-05],\n",
      "              [-2.021771e-05,  2.896904e-06, -2.362868e-05, -1.881982e-05]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [-7.261819e-01, -8.083431e-01, -5.263261e-01, -3.129264e-01]]],\n",
      "\n",
      "\n",
      "            [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]]]],\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          [[[[[-1.332683e-05,  6.402447e-05, -5.316203e-06, -2.266208e-05],\n",
      "              [-5.658605e-05,  2.718495e-04, -2.257273e-05, -9.622376e-05]],\n",
      "\n",
      "             [[-8.132054e-05,  1.165205e-05, -9.504031e-05, -7.569788e-05],\n",
      "              [ 8.559551e-05, -1.226459e-05,  1.000365e-04,  7.967725e-05]],\n",
      "\n",
      "             [[-7.262778e-01, -8.082851e-01, -5.263206e-01, -3.129208e-01],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "            [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 1.014477e-05, -4.873727e-05,  4.046847e-06,  1.725103e-05],\n",
      "              [ 4.307494e-05, -2.069397e-04,  1.718302e-05,  7.324831e-05]],\n",
      "\n",
      "             [[ 6.190356e-05, -8.869887e-06,  7.234744e-05,  5.762342e-05],\n",
      "              [-6.515777e-05,  9.336160e-06, -7.615067e-05, -6.065262e-05]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [-7.262778e-01, -8.082851e-01, -5.263206e-01, -3.129208e-01]]],\n",
      "\n",
      "\n",
      "            [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]]]]],\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "         [[[[[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "            [[[ 1.601872e-06, -4.024025e-06,  8.979139e-06, -3.361628e-05],\n",
      "              [ 6.778451e-08, -1.702798e-07,  3.799594e-07, -1.422500e-06]],\n",
      "\n",
      "             [[-2.757203e-06,  3.950672e-07, -3.222377e-06, -2.566565e-06],\n",
      "              [-2.745582e-07,  3.934019e-08, -3.208795e-07, -2.555747e-07]],\n",
      "\n",
      "             [[-7.260721e-01, -8.084093e-01, -5.263324e-01, -3.129328e-01],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "            [[[-2.202182e-06,  5.532050e-06, -1.234412e-05,  4.621415e-05],\n",
      "              [-9.318718e-08,  2.340932e-07, -5.223516e-07,  1.955590e-06]],\n",
      "\n",
      "             [[ 3.790480e-06, -5.431211e-07,  4.429980e-06,  3.528399e-06],\n",
      "              [ 3.774504e-07, -5.408310e-08,  4.411308e-07,  3.513527e-07]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [-7.260721e-01, -8.084093e-01, -5.263324e-01, -3.129328e-01]]]]],\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          [[[[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "            [[[-3.718944e-05,  1.786647e-04, -1.483523e-05, -6.324010e-05],\n",
      "              [-1.573701e-06,  7.560342e-06, -6.277648e-07, -2.676056e-06]],\n",
      "\n",
      "             [[ 4.528889e-05, -6.489237e-06,  5.292967e-05,  4.215752e-05],\n",
      "              [-4.266120e-05,  6.112736e-06, -4.985865e-05, -3.971151e-05]],\n",
      "\n",
      "             [[-7.261842e-01, -8.083416e-01, -5.263259e-01, -3.129262e-01],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "            [[[ 5.112639e-05, -2.456204e-04,  2.039482e-05,  8.693968e-05],\n",
      "              [ 2.163455e-06, -1.039363e-05,  8.630237e-07,  3.678924e-06]],\n",
      "\n",
      "             [[-6.226116e-05,  8.921124e-06, -7.276536e-05, -5.795628e-05],\n",
      "              [ 5.864871e-05, -8.403513e-06,  6.854346e-05,  5.459362e-05]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [-7.261842e-01, -8.083416e-01, -5.263259e-01, -3.129262e-01]]]]]]]],\n",
      "       device='cuda:0')\n",
      "--\n",
      "torch.Size([1, 2, 2, 2, 2, 3, 2, 4])\n",
      "tensor([[[[[[[[ 5.740308e-07, -1.442009e-06,  3.217673e-06, -1.204639e-05],\n",
      "              [ 2.437348e-06, -6.122803e-06,  1.366232e-05, -5.114925e-05]],\n",
      "\n",
      "             [[ 3.343014e-05, -4.790054e-06,  3.907021e-05,  3.111871e-05],\n",
      "              [ 2.655931e-05, -3.805566e-06,  3.104018e-05,  2.472294e-05]],\n",
      "\n",
      "             [[-7.261819e-01, -8.083431e-01, -5.263261e-01, -3.129264e-01],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "            [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[-4.369687e-07,  1.097699e-06, -2.449385e-06,  9.170058e-06],\n",
      "              [-1.855380e-06,  4.660856e-06, -1.040015e-05,  3.893630e-05]],\n",
      "\n",
      "             [[-2.544799e-05,  3.646332e-06, -2.974138e-05, -2.368847e-05],\n",
      "              [-2.021771e-05,  2.896904e-06, -2.362868e-05, -1.881982e-05]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [-7.261819e-01, -8.083431e-01, -5.263261e-01, -3.129264e-01]]],\n",
      "\n",
      "\n",
      "            [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]]]],\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          [[[[[-1.332683e-05,  6.402447e-05, -5.316203e-06, -2.266208e-05],\n",
      "              [-5.658605e-05,  2.718495e-04, -2.257273e-05, -9.622376e-05]],\n",
      "\n",
      "             [[-8.132054e-05,  1.165205e-05, -9.504031e-05, -7.569788e-05],\n",
      "              [ 8.559551e-05, -1.226459e-05,  1.000365e-04,  7.967725e-05]],\n",
      "\n",
      "             [[-7.262778e-01, -8.082851e-01, -5.263206e-01, -3.129208e-01],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "            [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 1.014477e-05, -4.873727e-05,  4.046847e-06,  1.725103e-05],\n",
      "              [ 4.307494e-05, -2.069397e-04,  1.718302e-05,  7.324831e-05]],\n",
      "\n",
      "             [[ 6.190356e-05, -8.869887e-06,  7.234744e-05,  5.762342e-05],\n",
      "              [-6.515777e-05,  9.336160e-06, -7.615067e-05, -6.065262e-05]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [-7.262778e-01, -8.082851e-01, -5.263206e-01, -3.129208e-01]]],\n",
      "\n",
      "\n",
      "            [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]]]]],\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "         [[[[[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "            [[[ 1.601872e-06, -4.024025e-06,  8.979139e-06, -3.361628e-05],\n",
      "              [ 6.778451e-08, -1.702798e-07,  3.799594e-07, -1.422500e-06]],\n",
      "\n",
      "             [[-2.757203e-06,  3.950672e-07, -3.222377e-06, -2.566565e-06],\n",
      "              [-2.745582e-07,  3.934019e-08, -3.208795e-07, -2.555747e-07]],\n",
      "\n",
      "             [[-7.260721e-01, -8.084093e-01, -5.263324e-01, -3.129328e-01],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "            [[[-2.202182e-06,  5.532050e-06, -1.234412e-05,  4.621415e-05],\n",
      "              [-9.318718e-08,  2.340932e-07, -5.223516e-07,  1.955590e-06]],\n",
      "\n",
      "             [[ 3.790480e-06, -5.431211e-07,  4.429980e-06,  3.528399e-06],\n",
      "              [ 3.774504e-07, -5.408310e-08,  4.411308e-07,  3.513527e-07]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [-7.260721e-01, -8.084093e-01, -5.263324e-01, -3.129328e-01]]]]],\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          [[[[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "            [[[-3.718944e-05,  1.786647e-04, -1.483523e-05, -6.324010e-05],\n",
      "              [-1.573701e-06,  7.560342e-06, -6.277648e-07, -2.676056e-06]],\n",
      "\n",
      "             [[ 4.528889e-05, -6.489237e-06,  5.292967e-05,  4.215752e-05],\n",
      "              [-4.266120e-05,  6.112736e-06, -4.985865e-05, -3.971151e-05]],\n",
      "\n",
      "             [[-7.261842e-01, -8.083416e-01, -5.263259e-01, -3.129262e-01],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "            [[[ 5.112639e-05, -2.456204e-04,  2.039482e-05,  8.693968e-05],\n",
      "              [ 2.163455e-06, -1.039363e-05,  8.630237e-07,  3.678924e-06]],\n",
      "\n",
      "             [[-6.226116e-05,  8.921124e-06, -7.276536e-05, -5.795628e-05],\n",
      "              [ 5.864871e-05, -8.403513e-06,  6.854346e-05,  5.459362e-05]],\n",
      "\n",
      "             [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "              [-7.261842e-01, -8.083416e-01, -5.263259e-01, -3.129262e-01]]]]]]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# t_tlayer_attn_heads_fwd + train=True\n",
    "import torch\n",
    "torch.set_printoptions(precision=6)\n",
    "from torch.func import jacrev\n",
    "from model_torch_func import init_tlayer_attn_heads\n",
    "from model_triton import *\n",
    "BS, H, N, D = 1, 2, 2, 4\n",
    "p_gen_aux = 42\n",
    "layer_params = init_tlayer_attn_heads(D, H)\n",
    "qkv= torch.randn((BS, 3, N, D), device=\"cuda\").unbind(-3)\n",
    "mask = torch.ones((BS, N, N), dtype=torch.bool, device=\"cuda\")\n",
    "from functools import partial\n",
    "\n",
    "output = t_tlayer_attn_heads_fwd(layer_params, qkv, mask=mask, train=True, p_gen_aux=p_gen_aux)\n",
    "print(\"layer_params\", layer_params.shape)\n",
    "print(\"output\", output.shape)\n",
    "\n",
    "fn = partial(t_tlayer_attn_heads_fwd, mask=mask, train=False)\n",
    "res = jacrev(fn)(layer_params, qkv)\n",
    "print(res.shape)\n",
    "print(res)\n",
    "print(\"--\")\n",
    "\n",
    "res2 = t_tlayer_attn_heads_bkwd_p(layer_params, qkv, mask, False)\n",
    "print(res2.shape)\n",
    "print(res)\n",
    "\n",
    "# fn = partial(t_tlayer_attn_heads_fwd, mask=mask, train=True, p_gen_aux=p_gen_aux)\n",
    "# res = jacrev(fn, argnums=1)(layer_params, qkv)\n",
    "# print(len(res), res[0].shape, res[1].shape, res[2].shape)\n",
    "# print(res[0])\n",
    "# print(\"--\")\n",
    "\n",
    "# res2 = t_tlayer_attn_heads_bkwd_x(layer_params, qkv, mask, True, p_gen_aux)\n",
    "# #print(res2.shape)\n",
    "# print(len(res2), res2[0].shape, res2[1].shape, res2[2].shape)\n",
    "# print(res2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e246efd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 torch.Size([1, 2, 4, 2, 3, 2, 4]) torch.Size([1, 2, 4, 4, 4])\n",
      "tensor([[[[[ 6.278919e-07,  1.590083e-06, -1.384409e-06, -7.190078e-07],\n",
      "           [-2.743195e-06, -6.946909e-06,  6.048343e-06,  3.141271e-06]],\n",
      "\n",
      "          [[ 2.412633e-06,  1.746262e-06, -5.243527e-06,  1.698564e-06],\n",
      "           [-7.732598e-07, -5.596850e-07,  1.680574e-06, -5.443975e-07]],\n",
      "\n",
      "          [[ 5.128642e-03,  2.609785e-03,  1.131797e-02,  2.197274e-02],\n",
      "           [ 1.001887e-03,  5.098252e-04,  2.210982e-03,  4.292406e-03]]],\n",
      "\n",
      "\n",
      "         [[[-9.239161e-08, -2.339739e-07,  2.037099e-07,  1.057989e-07],\n",
      "           [ 7.573799e-08,  1.918000e-07, -1.669911e-07, -8.672863e-08]],\n",
      "\n",
      "          [[ 8.058645e-08,  5.832843e-08, -1.751436e-07,  5.673522e-08],\n",
      "           [-6.968085e-08, -5.043496e-08,  1.514418e-07, -4.905736e-08]],\n",
      "\n",
      "          [[-2.393427e-03, -1.218390e-03, -5.280560e-03, -1.024892e-02],\n",
      "           [-1.412790e-02, -7.191901e-03, -3.117005e-02, -6.049726e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 7.319467e-08,  1.853593e-07, -1.613835e-07, -8.381624e-08],\n",
      "           [-3.197800e-07, -8.098157e-07,  7.050680e-07,  3.661846e-07]],\n",
      "\n",
      "          [[ 2.812457e-07,  2.035655e-07, -6.112489e-07,  1.980052e-07],\n",
      "           [-9.014050e-08, -6.524365e-08,  1.959080e-07, -6.346156e-08]],\n",
      "\n",
      "          [[ 2.324059e-03,  1.182632e-03,  5.128773e-03,  9.957014e-03],\n",
      "           [-1.138004e-03, -5.790903e-04, -2.511367e-03, -4.875574e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 2.025289e-09,  5.128873e-09, -4.465466e-09, -2.319187e-09],\n",
      "           [-1.660230e-09, -4.204392e-09,  3.660564e-09,  1.901153e-09]],\n",
      "\n",
      "          [[-1.766512e-09, -1.278601e-09,  3.839272e-09, -1.243676e-09],\n",
      "           [ 1.527454e-09,  1.105570e-09, -3.319711e-09,  1.075372e-09]],\n",
      "\n",
      "          [[ 3.337647e-03,  1.699051e-03,  7.363771e-03,  1.429218e-02],\n",
      "           [ 1.219672e-03,  6.208821e-04,  2.690933e-03,  5.222773e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.260503e-07, -3.192117e-07,  2.779224e-07,  1.443420e-07],\n",
      "           [ 5.507010e-07,  1.394603e-06, -1.214215e-06, -6.306154e-07]],\n",
      "\n",
      "          [[-4.843401e-07, -3.505651e-07,  1.052647e-06, -3.409896e-07],\n",
      "           [ 1.552332e-07,  1.123577e-07, -3.373780e-07,  1.092887e-07]],\n",
      "\n",
      "          [[-4.862871e-03, -2.474543e-03, -1.073146e-02, -2.083409e-02],\n",
      "           [ 2.585329e-03,  1.315583e-03,  5.705347e-03,  1.107638e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.273986e-08, -3.226261e-08,  2.808952e-08,  1.458859e-08],\n",
      "           [ 1.044349e-08,  2.644726e-08, -2.302637e-08, -1.195899e-08]],\n",
      "\n",
      "          [[ 1.111205e-08,  8.042893e-09, -2.415051e-08,  7.823206e-09],\n",
      "           [-9.608278e-09, -6.954466e-09,  2.088227e-08, -6.764509e-09]],\n",
      "\n",
      "          [[ 5.675446e-03,  2.889123e-03,  1.252160e-02,  2.430290e-02],\n",
      "           [-2.846080e-04, -1.448816e-04, -6.279238e-04, -1.218723e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-3.590808e-07, -9.093415e-07,  7.917204e-07,  4.111884e-07],\n",
      "           [ 1.568788e-06,  3.972821e-06, -3.458946e-06, -1.796441e-06]],\n",
      "\n",
      "          [[-1.379744e-06, -9.986582e-07,  2.998685e-06, -9.713804e-07],\n",
      "           [ 4.422143e-07,  3.200745e-07, -9.610922e-07,  3.113318e-07]],\n",
      "\n",
      "          [[-2.256414e-04, -1.148210e-04, -4.979493e-04, -9.667201e-04],\n",
      "           [-2.540961e-03, -1.293005e-03, -5.607434e-03, -1.088629e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.169363e-08, -5.493727e-08,  4.783126e-08,  2.484168e-08],\n",
      "           [ 1.778334e-08,  4.503480e-08, -3.920966e-08, -2.036396e-08]],\n",
      "\n",
      "          [[ 1.892177e-08,  1.369557e-08, -4.112387e-08,  1.332148e-08],\n",
      "           [-1.636112e-08, -1.184217e-08,  3.555866e-08, -1.151871e-08]],\n",
      "\n",
      "          [[ 5.246127e-03,  2.670576e-03,  1.157440e-02,  2.246451e-02],\n",
      "           [-1.708417e-03, -8.696810e-04, -3.769240e-03, -7.315635e-03]]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[ 0.014641,  0.038727, -0.010887,  0.041504],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000]],\n",
      "\n",
      "        [[ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [ 0.014641,  0.038727, -0.010887,  0.041504],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000]],\n",
      "\n",
      "        [[ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [ 0.014641,  0.038727, -0.010887,  0.041504],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000]],\n",
      "\n",
      "        [[ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [ 0.014641,  0.038727, -0.010887,  0.041504]]], device='cuda:0')\n",
      "--\n",
      "--\n",
      "2 torch.Size([1, 2, 4, 2, 3, 2, 4]) torch.Size([1, 2, 4, 4, 4])\n",
      "tensor([[[[[ 6.278916e-07,  1.590082e-06, -1.384409e-06, -7.190075e-07],\n",
      "           [-2.743195e-06, -6.946908e-06,  6.048342e-06,  3.141271e-06]],\n",
      "\n",
      "          [[ 2.412632e-06,  1.746262e-06, -5.243525e-06,  1.698564e-06],\n",
      "           [-7.732596e-07, -5.596848e-07,  1.680574e-06, -5.443974e-07]],\n",
      "\n",
      "          [[ 5.128641e-03,  2.609785e-03,  1.131797e-02,  2.197274e-02],\n",
      "           [ 1.001887e-03,  5.098252e-04,  2.210982e-03,  4.292406e-03]]],\n",
      "\n",
      "\n",
      "         [[[-9.239116e-08, -2.339727e-07,  2.037089e-07,  1.057984e-07],\n",
      "           [ 7.573759e-08,  1.917990e-07, -1.669902e-07, -8.672816e-08]],\n",
      "\n",
      "          [[ 8.058578e-08,  5.832795e-08, -1.751421e-07,  5.673474e-08],\n",
      "           [-6.968042e-08, -5.043465e-08,  1.514409e-07, -4.905706e-08]],\n",
      "\n",
      "          [[-2.393427e-03, -1.218390e-03, -5.280560e-03, -1.024892e-02],\n",
      "           [-1.412790e-02, -7.191901e-03, -3.117005e-02, -6.049726e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 7.319466e-08,  1.853592e-07, -1.613835e-07, -8.381623e-08],\n",
      "           [-3.197800e-07, -8.098158e-07,  7.050680e-07,  3.661846e-07]],\n",
      "\n",
      "          [[ 2.812457e-07,  2.035655e-07, -6.112487e-07,  1.980052e-07],\n",
      "           [-9.014052e-08, -6.524364e-08,  1.959080e-07, -6.346158e-08]],\n",
      "\n",
      "          [[ 2.324059e-03,  1.182632e-03,  5.128772e-03,  9.957013e-03],\n",
      "           [-1.138004e-03, -5.790903e-04, -2.511367e-03, -4.875574e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 2.025272e-09,  5.128828e-09, -4.465425e-09, -2.319166e-09],\n",
      "           [-1.660215e-09, -4.204354e-09,  3.660531e-09,  1.901135e-09]],\n",
      "\n",
      "          [[-1.766484e-09, -1.278581e-09,  3.839210e-09, -1.243656e-09],\n",
      "           [ 1.527426e-09,  1.105550e-09, -3.319652e-09,  1.075353e-09]],\n",
      "\n",
      "          [[ 3.337647e-03,  1.699051e-03,  7.363771e-03,  1.429218e-02],\n",
      "           [ 1.219672e-03,  6.208821e-04,  2.690933e-03,  5.222773e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.260503e-07, -3.192117e-07,  2.779225e-07,  1.443420e-07],\n",
      "           [ 5.507010e-07,  1.394604e-06, -1.214215e-06, -6.306156e-07]],\n",
      "\n",
      "          [[-4.843401e-07, -3.505651e-07,  1.052646e-06, -3.409895e-07],\n",
      "           [ 1.552332e-07,  1.123577e-07, -3.373781e-07,  1.092887e-07]],\n",
      "\n",
      "          [[-4.862870e-03, -2.474543e-03, -1.073146e-02, -2.083409e-02],\n",
      "           [ 2.585329e-03,  1.315583e-03,  5.705347e-03,  1.107638e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.273982e-08, -3.226250e-08,  2.808943e-08,  1.458854e-08],\n",
      "           [ 1.044345e-08,  2.644716e-08, -2.302628e-08, -1.195895e-08]],\n",
      "\n",
      "          [[ 1.111198e-08,  8.042848e-09, -2.415037e-08,  7.823163e-09],\n",
      "           [-9.608256e-09, -6.954451e-09,  2.088223e-08, -6.764493e-09]],\n",
      "\n",
      "          [[ 5.675446e-03,  2.889123e-03,  1.252160e-02,  2.430290e-02],\n",
      "           [-2.846080e-04, -1.448816e-04, -6.279238e-04, -1.218723e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-3.590807e-07, -9.093412e-07,  7.917201e-07,  4.111883e-07],\n",
      "           [ 1.568787e-06,  3.972820e-06, -3.458945e-06, -1.796440e-06]],\n",
      "\n",
      "          [[-1.379744e-06, -9.986578e-07,  2.998684e-06, -9.713801e-07],\n",
      "           [ 4.422141e-07,  3.200743e-07, -9.610917e-07,  3.113317e-07]],\n",
      "\n",
      "          [[-2.256414e-04, -1.148210e-04, -4.979493e-04, -9.667200e-04],\n",
      "           [-2.540960e-03, -1.293005e-03, -5.607434e-03, -1.088629e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.169347e-08, -5.493686e-08,  4.783091e-08,  2.484149e-08],\n",
      "           [ 1.778320e-08,  4.503445e-08, -3.920935e-08, -2.036379e-08]],\n",
      "\n",
      "          [[ 1.892157e-08,  1.369542e-08, -4.112344e-08,  1.332134e-08],\n",
      "           [-1.636100e-08, -1.184208e-08,  3.555839e-08, -1.151863e-08]],\n",
      "\n",
      "          [[ 5.246127e-03,  2.670576e-03,  1.157440e-02,  2.246451e-02],\n",
      "           [-1.708417e-03, -8.696811e-04, -3.769240e-03, -7.315635e-03]]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[ 0.014641,  0.038727, -0.010887,  0.041504],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000]],\n",
      "\n",
      "        [[ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [ 0.014641,  0.038727, -0.010887,  0.041504],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000]],\n",
      "\n",
      "        [[ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [ 0.014641,  0.038727, -0.010887,  0.041504],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000]],\n",
      "\n",
      "        [[ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [ 0.014641,  0.038727, -0.010887,  0.041504]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# t_tlayer_attn_fwd + train=False\n",
    "import torch\n",
    "torch.set_printoptions(precision=6)\n",
    "from torch.func import jacrev\n",
    "from model_torch_func import init_tlayer_attn\n",
    "from model_triton import *\n",
    "BS, H, N, D = 1, 2, 2, 4 # It doesn't work for 1, 2, 2, 2\n",
    "layer_params = init_tlayer_attn(D, H)\n",
    "qkv= torch.randn((BS, 3, N, D), device=\"cuda\").unbind(-3)\n",
    "mask = torch.ones((BS, N, N), dtype=torch.bool, device=\"cuda\")\n",
    "from functools import partial\n",
    "fn = partial(t_tlayer_attn_fwd, mask=mask, train=False)\n",
    "res = jacrev(fn)(layer_params, qkv)\n",
    "print(len(res), res[0].shape, res[1].shape)\n",
    "print(res[0][0][0])\n",
    "print(res[1][0][0])\n",
    "#print(res)\n",
    "print(\"--\")\n",
    "\n",
    "res2 = t_tlayer_attn_bkwd_p(layer_params, qkv, mask, False)\n",
    "print(\"--\")\n",
    "print(len(res2), res2[0].shape, res2[1].shape)\n",
    "print(res2[0][0][0])\n",
    "print(res2[1][0][0])\n",
    "\n",
    "# ####\n",
    "\n",
    "# res = jacrev(fn, argnums=1)(layer_params, qkv)\n",
    "# print(type(res), len(res), res[0].shape, res[1].shape)\n",
    "# print(res[0][0])\n",
    "# print(f'--')\n",
    "\n",
    "# from model_triton import _mult_jacs_in_2d\n",
    "\n",
    "# res2 = t_tlayer_attn_bkwd_x(layer_params, qkv, mask, False)\n",
    "# print(f'--')\n",
    "# print(type(res2), len(res2), res2[0].shape, res2[1].shape)\n",
    "# print(res2[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dbf11eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 torch.Size([1, 2, 4, 2, 3, 2, 4]) torch.Size([1, 2, 4, 4, 4])\n",
      "tensor([[[[[ 9.888595e-06, -1.494707e-05,  9.430310e-06, -1.461163e-05],\n",
      "           [-1.096886e-06,  1.657994e-06, -1.046051e-06,  1.620786e-06]],\n",
      "\n",
      "          [[ 1.617867e-05, -2.441726e-05, -3.441375e-06,  1.620722e-05],\n",
      "           [ 1.399617e-05, -2.112338e-05, -2.977134e-06,  1.402087e-05]],\n",
      "\n",
      "          [[-1.827737e-02, -3.571232e-02,  3.943164e-02,  8.377606e-03],\n",
      "           [-1.575727e-02, -3.078827e-02,  3.399476e-02,  7.222490e-03]]],\n",
      "\n",
      "\n",
      "         [[[-4.840731e-06,  7.316990e-06, -4.616389e-06,  7.152784e-06],\n",
      "           [-6.914753e-07,  1.045197e-06, -6.594290e-07,  1.021741e-06]],\n",
      "\n",
      "          [[ 2.600796e-06, -3.925188e-06, -5.532168e-07,  2.605384e-06],\n",
      "           [ 6.263246e-06, -9.452651e-06, -1.332259e-06,  6.274297e-06]],\n",
      "\n",
      "          [[ 1.305933e-02,  2.551670e-02, -2.815323e-02, -6.026927e-03],\n",
      "           [ 5.355588e-03,  1.046432e-02, -1.154555e-02, -2.471623e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.767318e-06, -4.182930e-06,  2.639068e-06, -4.089058e-06],\n",
      "           [-3.069630e-07,  4.639888e-07, -2.927369e-07,  4.535761e-07]],\n",
      "\n",
      "          [[ 4.527592e-06, -6.833158e-06, -9.630667e-07,  4.535581e-06],\n",
      "           [ 3.916822e-06, -5.911367e-06, -8.331492e-07,  3.923732e-06]],\n",
      "\n",
      "          [[ 6.976824e-03,  1.363208e-02, -1.505181e-02, -3.197893e-03],\n",
      "           [-6.412138e-03, -1.252874e-02,  1.383356e-02,  2.939063e-03]]],\n",
      "\n",
      "\n",
      "         [[[-4.231097e-07,  6.395500e-07, -4.035008e-07,  6.251974e-07],\n",
      "           [-6.043921e-08,  9.135667e-08, -5.763816e-08,  8.930646e-08]],\n",
      "\n",
      "          [[ 2.273256e-07, -3.430855e-07, -4.835456e-08,  2.277266e-07],\n",
      "           [ 5.474463e-07, -8.262199e-07, -1.164476e-07,  5.484122e-07]],\n",
      "\n",
      "          [[ 5.922501e-03,  1.157201e-02, -1.276770e-02, -2.733257e-03],\n",
      "           [-6.776758e-03, -1.324115e-02,  1.460930e-02,  3.127499e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-5.896474e-06,  8.912794e-06, -5.623203e-06,  8.712776e-06],\n",
      "           [ 6.540627e-07, -9.886462e-07,  6.237504e-07, -9.664593e-07]],\n",
      "\n",
      "          [[-9.647185e-06,  1.455978e-05,  2.052058e-06, -9.664207e-06],\n",
      "           [-8.345783e-06,  1.259567e-05,  1.775236e-06, -8.360508e-06]],\n",
      "\n",
      "          [[-1.626416e-04, -3.177869e-04,  3.508833e-04,  7.454833e-05],\n",
      "           [ 1.122773e-02,  2.193796e-02, -2.422272e-02, -5.146334e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.232070e-06,  1.862331e-06, -1.174970e-06,  1.820538e-06],\n",
      "           [-1.759953e-07,  2.660251e-07, -1.678389e-07,  2.600551e-07]],\n",
      "\n",
      "          [[ 6.619586e-07, -9.990448e-07, -1.408056e-07,  6.631265e-07],\n",
      "           [ 1.594131e-06, -2.405903e-06, -3.390886e-07,  1.596944e-06]],\n",
      "\n",
      "          [[ 7.906588e-03,  1.544873e-02, -1.704498e-02, -3.648920e-03],\n",
      "           [-5.581222e-03, -1.090518e-02,  1.203197e-02,  2.575755e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 7.014959e-06, -1.060344e-05,  6.689852e-06, -1.036548e-05],\n",
      "           [-7.781298e-07,  1.176179e-06, -7.420676e-07,  1.149784e-06]],\n",
      "\n",
      "          [[ 1.147713e-05, -1.732158e-05, -2.441308e-06,  1.149738e-05],\n",
      "           [ 9.928868e-06, -1.498490e-05, -2.111975e-06,  9.946388e-06]],\n",
      "\n",
      "          [[-1.249528e-02, -2.441464e-02,  2.695734e-02,  5.727326e-03],\n",
      "           [-1.125613e-02, -2.199346e-02,  2.428401e-02,  5.159352e-03]]],\n",
      "\n",
      "\n",
      "         [[[-2.572889e-06,  3.889041e-06, -2.453649e-06,  3.801764e-06],\n",
      "           [-3.675249e-07,  5.555309e-07, -3.504920e-07,  5.430638e-07]],\n",
      "\n",
      "          [[ 1.382345e-06, -2.086270e-06, -2.940393e-07,  1.384784e-06],\n",
      "           [ 3.328967e-06, -5.024162e-06, -7.081064e-07,  3.334841e-06]],\n",
      "\n",
      "          [[ 8.233877e-03,  1.608822e-02, -1.775055e-02, -3.799966e-03],\n",
      "           [ 8.876137e-04,  1.734314e-03, -1.913513e-03, -4.096370e-04]]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[-0.012810, -0.057892,  0.001993,  0.008423],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000]],\n",
      "\n",
      "        [[ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [-0.012810, -0.057892,  0.001993,  0.008423],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000]],\n",
      "\n",
      "        [[ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [-0.012810, -0.057892,  0.001993,  0.008423],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000]],\n",
      "\n",
      "        [[ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [-0.012810, -0.057892,  0.001993,  0.008423]]], device='cuda:0')\n",
      "--\n",
      "--\n",
      "2 torch.Size([1, 2, 4, 2, 3, 2, 4]) torch.Size([1, 2, 4, 4, 4])\n",
      "tensor([[[[[ 9.888598e-06, -1.494708e-05,  9.430314e-06, -1.461164e-05],\n",
      "           [-1.096886e-06,  1.657993e-06, -1.046051e-06,  1.620785e-06]],\n",
      "\n",
      "          [[ 1.617868e-05, -2.441727e-05, -3.441378e-06,  1.620722e-05],\n",
      "           [ 1.399618e-05, -2.112339e-05, -2.977136e-06,  1.402087e-05]],\n",
      "\n",
      "          [[-1.827737e-02, -3.571232e-02,  3.943164e-02,  8.377604e-03],\n",
      "           [-1.575727e-02, -3.078827e-02,  3.399476e-02,  7.222491e-03]]],\n",
      "\n",
      "\n",
      "         [[[-4.840731e-06,  7.316990e-06, -4.616389e-06,  7.152785e-06],\n",
      "           [-6.914753e-07,  1.045197e-06, -6.594290e-07,  1.021741e-06]],\n",
      "\n",
      "          [[ 2.600796e-06, -3.925187e-06, -5.532168e-07,  2.605384e-06],\n",
      "           [ 6.263245e-06, -9.452650e-06, -1.332259e-06,  6.274297e-06]],\n",
      "\n",
      "          [[ 1.305933e-02,  2.551670e-02, -2.815323e-02, -6.026928e-03],\n",
      "           [ 5.355588e-03,  1.046431e-02, -1.154555e-02, -2.471623e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.767320e-06, -4.182933e-06,  2.639069e-06, -4.089060e-06],\n",
      "           [-3.069629e-07,  4.639888e-07, -2.927368e-07,  4.535760e-07]],\n",
      "\n",
      "          [[ 4.527596e-06, -6.833163e-06, -9.630681e-07,  4.535584e-06],\n",
      "           [ 3.916824e-06, -5.911370e-06, -8.331501e-07,  3.923734e-06]],\n",
      "\n",
      "          [[ 6.976823e-03,  1.363208e-02, -1.505181e-02, -3.197892e-03],\n",
      "           [-6.412139e-03, -1.252874e-02,  1.383356e-02,  2.939064e-03]]],\n",
      "\n",
      "\n",
      "         [[[-4.231098e-07,  6.395503e-07, -4.035010e-07,  6.251975e-07],\n",
      "           [-6.043921e-08,  9.135668e-08, -5.763817e-08,  8.930649e-08]],\n",
      "\n",
      "          [[ 2.273256e-07, -3.430854e-07, -4.835454e-08,  2.277266e-07],\n",
      "           [ 5.474462e-07, -8.262198e-07, -1.164476e-07,  5.484121e-07]],\n",
      "\n",
      "          [[ 5.922501e-03,  1.157201e-02, -1.276770e-02, -2.733256e-03],\n",
      "           [-6.776758e-03, -1.324115e-02,  1.460930e-02,  3.127499e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-5.896477e-06,  8.912799e-06, -5.623206e-06,  8.712780e-06],\n",
      "           [ 6.540623e-07, -9.886456e-07,  6.237501e-07, -9.664587e-07]],\n",
      "\n",
      "          [[-9.647190e-06,  1.455979e-05,  2.052061e-06, -9.664212e-06],\n",
      "           [-8.345785e-06,  1.259567e-05,  1.775238e-06, -8.360511e-06]],\n",
      "\n",
      "          [[-1.626416e-04, -3.177869e-04,  3.508833e-04,  7.454830e-05],\n",
      "           [ 1.122773e-02,  2.193796e-02, -2.422273e-02, -5.146334e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.232071e-06,  1.862332e-06, -1.174970e-06,  1.820538e-06],\n",
      "           [-1.759954e-07,  2.660252e-07, -1.678389e-07,  2.600552e-07]],\n",
      "\n",
      "          [[ 6.619585e-07, -9.990447e-07, -1.408056e-07,  6.631263e-07],\n",
      "           [ 1.594131e-06, -2.405903e-06, -3.390885e-07,  1.596944e-06]],\n",
      "\n",
      "          [[ 7.906587e-03,  1.544873e-02, -1.704498e-02, -3.648919e-03],\n",
      "           [-5.581222e-03, -1.090518e-02,  1.203197e-02,  2.575755e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 7.014960e-06, -1.060344e-05,  6.689854e-06, -1.036548e-05],\n",
      "           [-7.781293e-07,  1.176179e-06, -7.420672e-07,  1.149783e-06]],\n",
      "\n",
      "          [[ 1.147714e-05, -1.732158e-05, -2.441310e-06,  1.149739e-05],\n",
      "           [ 9.928872e-06, -1.498491e-05, -2.111977e-06,  9.946390e-06]],\n",
      "\n",
      "          [[-1.249528e-02, -2.441464e-02,  2.695734e-02,  5.727327e-03],\n",
      "           [-1.125613e-02, -2.199346e-02,  2.428401e-02,  5.159354e-03]]],\n",
      "\n",
      "\n",
      "         [[[-2.572889e-06,  3.889042e-06, -2.453649e-06,  3.801764e-06],\n",
      "           [-3.675249e-07,  5.555310e-07, -3.504920e-07,  5.430639e-07]],\n",
      "\n",
      "          [[ 1.382345e-06, -2.086270e-06, -2.940394e-07,  1.384784e-06],\n",
      "           [ 3.328967e-06, -5.024162e-06, -7.081065e-07,  3.334841e-06]],\n",
      "\n",
      "          [[ 8.233876e-03,  1.608822e-02, -1.775055e-02, -3.799964e-03],\n",
      "           [ 8.876137e-04,  1.734314e-03, -1.913513e-03, -4.096370e-04]]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[-0.012810, -0.057892,  0.001993,  0.008423],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000]],\n",
      "\n",
      "        [[ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [-0.012810, -0.057892,  0.001993,  0.008423],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000]],\n",
      "\n",
      "        [[ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [-0.012810, -0.057892,  0.001993,  0.008423],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000]],\n",
      "\n",
      "        [[ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [ 0.000000,  0.000000,  0.000000,  0.000000],\n",
      "         [-0.012810, -0.057892,  0.001993,  0.008423]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:767: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:135.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "# t_tlayer_attn_fwd + train=True\n",
    "import torch\n",
    "torch.set_printoptions(precision=6)\n",
    "from torch.func import jacrev\n",
    "from model_torch_func import init_tlayer_attn\n",
    "from model_triton import *\n",
    "BS, H, N, D = 1, 2, 2, 4 # It doesn't work for 1, 2, 2, 2\n",
    "p_gen_aux = 42\n",
    "layer_params = init_tlayer_attn(D, H)\n",
    "qkv= torch.randn((BS, 3, N, D), device=\"cuda\").unbind(-3)\n",
    "mask = torch.ones((BS, N, N), dtype=torch.bool, device=\"cuda\")\n",
    "from functools import partial\n",
    "fn = partial(t_tlayer_attn_fwd, mask=mask, train=True, p_gen_aux=p_gen_aux)\n",
    "res = jacrev(fn)(layer_params, qkv)\n",
    "print(len(res), res[0].shape, res[1].shape)\n",
    "print(res[0][0][0])\n",
    "print(res[1][0][0])\n",
    "#print(res)\n",
    "print(\"--\")\n",
    "\n",
    "res2 = t_tlayer_attn_bkwd_p(layer_params, qkv, mask, True, p_gen_aux)\n",
    "print(\"--\")\n",
    "print(len(res2), res2[0].shape, res2[1].shape)\n",
    "print(res2[0][0][0])\n",
    "print(res2[1][0][0])\n",
    "\n",
    "# ####\n",
    "\n",
    "# res = jacrev(fn, argnums=1)(layer_params, qkv)\n",
    "# print(type(res), len(res), res[0].shape, res[1].shape)\n",
    "# print(res[0][0])\n",
    "# print(f'--')\n",
    "\n",
    "# from model_triton import _mult_jacs_in_2d\n",
    "\n",
    "# res2 = t_tlayer_attn_bkwd_x(layer_params, qkv, mask, False)\n",
    "# print(f'--')\n",
    "# print(type(res2), len(res2), res2[0].shape, res2[1].shape)\n",
    "# print(res2[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdb62b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 4])\n",
      "---\n",
      "torch.Size([1, 2, 4, 1, 2, 4]) tensor([[[[[[ 9.996231e-01,  1.438149e-04,  5.101071e-05,  1.821585e-04],\n",
      "            [-4.071151e-04,  2.044572e-04, -2.376328e-05,  2.264212e-04]]],\n",
      "\n",
      "\n",
      "          [[[-1.047538e-04,  1.000091e+00, -2.112311e-05,  3.476722e-05],\n",
      "            [-1.282808e-04,  2.834288e-05, -3.153478e-05,  1.314727e-04]]],\n",
      "\n",
      "\n",
      "          [[[ 8.463881e-05, -4.487316e-05,  9.999972e-01, -3.699768e-05],\n",
      "            [ 1.001096e-04, -1.238897e-04, -4.321824e-05,  6.699841e-05]]],\n",
      "\n",
      "\n",
      "          [[[ 2.538253e-05, -6.186862e-05,  3.257946e-05,  1.000004e+00],\n",
      "            [ 5.246916e-05, -1.176246e-04, -5.776919e-05,  1.229246e-04]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[-3.770274e-04,  1.437872e-04,  5.104710e-05,  1.821931e-04],\n",
      "            [ 9.995930e-01,  2.044537e-04, -2.375363e-05,  2.263845e-04]]],\n",
      "\n",
      "\n",
      "          [[[-1.046268e-04,  9.099802e-05, -2.109664e-05,  3.472545e-05],\n",
      "            [-1.284503e-04,  1.000028e+00, -3.145642e-05,  1.313463e-04]]],\n",
      "\n",
      "\n",
      "          [[[ 8.426186e-05, -4.436851e-05, -2.965979e-06, -3.692735e-05],\n",
      "            [ 1.006111e-04, -1.237528e-04,  9.999571e-01,  6.607152e-05]]],\n",
      "\n",
      "\n",
      "          [[[ 2.504112e-05, -6.189365e-05,  3.273284e-05,  4.119720e-06],\n",
      "            [ 5.279165e-05, -1.178790e-04, -5.781198e-05,  1.000123e+00]]]]]],\n",
      "       device='cuda:0')\n",
      "---\n",
      "torch.Size([1, 2, 4, 1, 2, 4]) tensor([[[[[[ 9.996230e-01,  1.438149e-04,  5.101071e-05,  1.821585e-04],\n",
      "            [-4.071151e-04,  2.044572e-04, -2.376326e-05,  2.264211e-04]]],\n",
      "\n",
      "\n",
      "          [[[-1.047538e-04,  1.000091e+00, -2.112310e-05,  3.476721e-05],\n",
      "            [-1.282808e-04,  2.834288e-05, -3.153479e-05,  1.314727e-04]]],\n",
      "\n",
      "\n",
      "          [[[ 8.463882e-05, -4.487317e-05,  9.999973e-01, -3.699769e-05],\n",
      "            [ 1.001096e-04, -1.238897e-04, -4.321826e-05,  6.699839e-05]]],\n",
      "\n",
      "\n",
      "          [[[ 2.538254e-05, -6.186863e-05,  3.257948e-05,  1.000004e+00],\n",
      "            [ 5.246920e-05, -1.176246e-04, -5.776919e-05,  1.229246e-04]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[-3.770274e-04,  1.437872e-04,  5.104711e-05,  1.821931e-04],\n",
      "            [ 9.995929e-01,  2.044537e-04, -2.375361e-05,  2.263845e-04]]],\n",
      "\n",
      "\n",
      "          [[[-1.046268e-04,  9.099802e-05, -2.109664e-05,  3.472545e-05],\n",
      "            [-1.284503e-04,  1.000029e+00, -3.145643e-05,  1.313463e-04]]],\n",
      "\n",
      "\n",
      "          [[[ 8.426185e-05, -4.436851e-05, -2.965971e-06, -3.692737e-05],\n",
      "            [ 1.006111e-04, -1.237528e-04,  9.999571e-01,  6.607150e-05]]],\n",
      "\n",
      "\n",
      "          [[[ 2.504112e-05, -6.189366e-05,  3.273285e-05,  4.119726e-06],\n",
      "            [ 5.279164e-05, -1.178790e-04, -5.781197e-05,  1.000123e+00]]]]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# t_gpt2_tlayer_fwd_sublock1_fwd Train=False\n",
    "import torch\n",
    "torch.set_printoptions(precision=6)\n",
    "from torch.func import jacrev\n",
    "from model_torch_func import init_tlayer_gpt2\n",
    "from model_triton import *\n",
    "BS, H, N, D = 1, 2, 2, 4\n",
    "layer_params = init_tlayer_gpt2(D, H, 4*D, 1)\n",
    "y= torch.randn((BS, N, D), device=\"cuda\")\n",
    "mask = torch.ones((BS, N, N), dtype=torch.bool, device=\"cuda\")\n",
    "res = t_gpt2_tlayer_sublock1_fwd(layer_params[:-6], y, mask, False)\n",
    "print(res.shape)\n",
    "print(\"---\")\n",
    "\n",
    "from functools import partial\n",
    "fn = partial(t_gpt2_tlayer_sublock1_fwd, mask=mask, train=False)\n",
    "res = jacrev(fn)(layer_params[:-6], y)\n",
    "# print(len(res), res[0].shape, res[1].shape, res[2].shape, res[3].shape)\n",
    "# print(res[1])\n",
    "# #print(res[1])\n",
    "# print(\"---\")\n",
    "\n",
    "from model_triton import _mult_jacs_in_2d\n",
    "\n",
    "# res2 = t_gpt2_tlayer_sublock1_bkwd_p(layer_params[:-6], y, mask, train=False)\n",
    "# print(len(res2), res2[0].shape, res2[1].shape, res2[2].shape, res2[3].shape)\n",
    "# print(res2[1])\n",
    "\n",
    "res = jacrev(fn, argnums=1)(layer_params[:-6], y)\n",
    "print(res.shape, res)\n",
    "print(\"---\")\n",
    "\n",
    "res2 = t_gpt2_tlayer_sublock1_bkwd_x(layer_params[:-6], y, mask, train=False)\n",
    "print(res2.shape, res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bee3d4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 4])\n",
      "---\n",
      "4 torch.Size([1, 2, 4, 4]) torch.Size([1, 2, 4, 4]) torch.Size([1, 2, 4, 2, 3, 2, 4]) torch.Size([1, 2, 4, 4, 4])\n",
      "tensor([[[[-1.228441e-04,  1.492486e-04, -4.761901e-04, -1.169280e-04],\n",
      "          [-5.437012e-04,  2.777719e-04,  1.680864e-04, -7.518192e-06],\n",
      "          [ 6.221797e-05, -4.882399e-04, -1.135939e-04,  9.591794e-04],\n",
      "          [-5.936526e-04,  4.759873e-04, -2.091079e-04, -3.034194e-04]],\n",
      "\n",
      "         [[-1.228441e-04,  1.492486e-04, -4.761901e-04, -1.169280e-04],\n",
      "          [-5.437012e-04,  2.777719e-04,  1.680864e-04, -7.518185e-06],\n",
      "          [ 6.221791e-05, -4.882399e-04, -1.135939e-04,  9.591795e-04],\n",
      "          [-5.936526e-04,  4.759874e-04, -2.091079e-04, -3.034194e-04]]]],\n",
      "       device='cuda:0')\n",
      "---\n",
      "4 torch.Size([1, 2, 4, 4]) torch.Size([1, 2, 4, 4]) torch.Size([1, 2, 4, 2, 3, 2, 4]) torch.Size([1, 2, 4, 4, 4])\n",
      "tensor([[[[-1.228441e-04,  1.492486e-04, -4.761901e-04, -1.169280e-04],\n",
      "          [-5.437012e-04,  2.777719e-04,  1.680864e-04, -7.518199e-06],\n",
      "          [ 6.221797e-05, -4.882399e-04, -1.135939e-04,  9.591794e-04],\n",
      "          [-5.936526e-04,  4.759874e-04, -2.091079e-04, -3.034194e-04]],\n",
      "\n",
      "         [[-1.228441e-04,  1.492486e-04, -4.761901e-04, -1.169280e-04],\n",
      "          [-5.437012e-04,  2.777719e-04,  1.680864e-04, -7.518192e-06],\n",
      "          [ 6.221794e-05, -4.882399e-04, -1.135939e-04,  9.591795e-04],\n",
      "          [-5.936526e-04,  4.759874e-04, -2.091079e-04, -3.034194e-04]]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# t_gpt2_tlayer_fwd_sublock1_fwd Train=True\n",
    "import torch\n",
    "torch.set_printoptions(precision=6)\n",
    "from torch.func import jacrev\n",
    "from model_torch_func import init_tlayer_gpt2\n",
    "from model_triton import *\n",
    "BS, H, N, D = 1, 2, 2, 4\n",
    "layer_params = init_tlayer_gpt2(D, H, 4*D, 1)\n",
    "p_gen_aux = [42, 43]\n",
    "y= torch.randn((BS, N, D), device=\"cuda\")\n",
    "mask = torch.ones((BS, N, N), dtype=torch.bool, device=\"cuda\")\n",
    "res = t_gpt2_tlayer_sublock1_fwd(layer_params[:-6], y, mask, True, p_gen_aux)\n",
    "print(res.shape)\n",
    "print(\"---\")\n",
    "\n",
    "from functools import partial\n",
    "fn = partial(t_gpt2_tlayer_sublock1_fwd, mask=mask, train=True, p_gen_aux=p_gen_aux)\n",
    "res = jacrev(fn)(layer_params[:-6], y)\n",
    "print(len(res), res[0].shape, res[1].shape, res[2].shape, res[3].shape)\n",
    "print(res[1])\n",
    "#print(res[1])\n",
    "print(\"---\")\n",
    "\n",
    "res2 = t_gpt2_tlayer_sublock1_bkwd_p(layer_params[:-6], y, mask, train=True, p_gen_aux=p_gen_aux)\n",
    "print(len(res2), res2[0].shape, res2[1].shape, res2[2].shape, res2[3].shape)\n",
    "print(res2[1])\n",
    "\n",
    "# res = jacrev(fn, argnums=1)(layer_params[:-6], y)\n",
    "# print(res.shape, res)\n",
    "# print(\"---\")\n",
    "\n",
    "# res2 = t_gpt2_tlayer_sublock1_bkwd_x(layer_params[:-6], y, mask, train=True, p_gen_aux=p_gen_aux)\n",
    "# print(res2.shape, res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de477958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO XXX: think what to do about the device here?\n",
    "BIG_NR=1_000_000\n",
    "def _p_gen_aux_split(device, p_gen_aux=None, n=2):\n",
    "    if p_gen_aux is None:\n",
    "        return [None] * n\n",
    "    generator = torch.Generator(device=device).manual_seed(p_gen_aux)\n",
    "    return torch.randint(0, BIG_NR, (n,), device=device, generator=generator).tolist()\n",
    "device=\"cuda\"\n",
    "aa, bb = _p_gen_aux_split(device, 42, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2852bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 2])\n",
      "tensor([[[-0.0004, -0.0004],\n",
      "         [-0.0004, -0.0004]]], device='cuda:0')\n",
      "---\n",
      "6 torch.Size([1, 2, 2, 2]) torch.Size([1, 2, 2, 2]) torch.Size([1, 2, 2, 8, 2]) torch.Size([1, 2, 2, 8])\n",
      "tensor([[[[-3.2364e-04, -4.2486e-05],\n",
      "          [-4.6472e-04,  7.8919e-05]],\n",
      "\n",
      "         [[-3.2364e-04, -4.2486e-05],\n",
      "          [-4.6472e-04,  7.8919e-05]]]], device='cuda:0')\n",
      "tensor([[[[ 4.5769e-04, -6.0085e-05],\n",
      "          [ 6.5722e-04,  1.1161e-04]],\n",
      "\n",
      "         [[ 4.5769e-04, -6.0085e-05],\n",
      "          [ 6.5722e-04,  1.1161e-04]]]], device='cuda:0')\n",
      "tensor([[[[[ 0.0055,  0.0161, -0.0165,  0.0053,  0.0069, -0.0065,  0.0049,\n",
      "             0.0076],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "             0.0000]],\n",
      "\n",
      "          [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "             0.0000],\n",
      "           [ 0.0055,  0.0161, -0.0165,  0.0053,  0.0069, -0.0065,  0.0049,\n",
      "             0.0076]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0055,  0.0161, -0.0165,  0.0053,  0.0069, -0.0065,  0.0049,\n",
      "             0.0076],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "             0.0000]],\n",
      "\n",
      "          [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "             0.0000],\n",
      "           [ 0.0055,  0.0161, -0.0165,  0.0053,  0.0069, -0.0065,  0.0049,\n",
      "             0.0076]]]]], device='cuda:0')\n",
      "tensor([[[[0.9000, 0.0000],\n",
      "          [0.0000, 0.9000]],\n",
      "\n",
      "         [[0.9000, 0.0000],\n",
      "          [0.0000, 0.9000]]]], device='cuda:0')\n",
      "---\n",
      "6 torch.Size([1, 2, 2, 2]) torch.Size([1, 2, 2, 2]) torch.Size([1, 2, 2, 8, 2]) torch.Size([1, 2, 2, 8])\n",
      "tensor([[[[-3.2364e-04, -4.2486e-05],\n",
      "          [-4.6472e-04,  7.8919e-05]],\n",
      "\n",
      "         [[-3.2364e-04, -4.2486e-05],\n",
      "          [-4.6472e-04,  7.8919e-05]]]], device='cuda:0')\n",
      "tensor([[[[ 4.5769e-04, -6.0085e-05],\n",
      "          [ 6.5722e-04,  1.1161e-04]],\n",
      "\n",
      "         [[ 4.5769e-04, -6.0085e-05],\n",
      "          [ 6.5722e-04,  1.1161e-04]]]], device='cuda:0')\n",
      "tensor([[[[[ 0.0055,  0.0161, -0.0165,  0.0053,  0.0069, -0.0065,  0.0049,\n",
      "             0.0076],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "             0.0000]],\n",
      "\n",
      "          [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "             0.0000],\n",
      "           [ 0.0055,  0.0161, -0.0165,  0.0053,  0.0069, -0.0065,  0.0049,\n",
      "             0.0076]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0055,  0.0161, -0.0165,  0.0053,  0.0069, -0.0065,  0.0049,\n",
      "             0.0076],\n",
      "           [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "             0.0000]],\n",
      "\n",
      "          [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "             0.0000],\n",
      "           [ 0.0055,  0.0161, -0.0165,  0.0053,  0.0069, -0.0065,  0.0049,\n",
      "             0.0076]]]]], device='cuda:0')\n",
      "tensor([[[[0.9000, 0.0000],\n",
      "          [0.0000, 0.9000]],\n",
      "\n",
      "         [[0.9000, 0.0000],\n",
      "          [0.0000, 0.9000]]]], device='cuda:0')\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# t_gpt2_tlayer_fwd_sublock2_fwd Train=False\n",
    "import torch\n",
    "#torch.set_printoptions(precision=6)\n",
    "from torch.func import jacrev\n",
    "from model_torch_func import init_tlayer_gpt2\n",
    "from model_triton import *\n",
    "BS, H, N, D = 1, 1, 2, 2\n",
    "layer_params = init_tlayer_gpt2(D, H, 4*D, 1) #, 0.00000001)\n",
    "y= torch.randn((BS, N, D), device=\"cuda\")\n",
    "mask = torch.ones((BS, N, N), dtype=torch.bool, device=\"cuda\")\n",
    "y = t_gpt2_tlayer_sublock1_fwd(layer_params[:-6], y, mask, False)\n",
    "res = t_gpt2_tlayer_sublock2_fwd(layer_params[-6:], y, False)\n",
    "print(res.shape)\n",
    "print(res-y)\n",
    "print(\"---\")\n",
    "\n",
    "from functools import partial\n",
    "fn = partial(t_gpt2_tlayer_sublock2_fwd, train=False)\n",
    "res = jacrev(fn)(layer_params[-6:], y)\n",
    "print(len(res), res[0].shape, res[1].shape, res[2].shape, res[3].shape)\n",
    "print(res[0])\n",
    "print(res[1])\n",
    "print(res[-2])\n",
    "print(res[-1])\n",
    "print(\"---\")\n",
    "\n",
    "res2 = t_gpt2_tlayer_sublock2_bkwd_p(layer_params[-6:], y, train=False)\n",
    "print(len(res2), res2[0].shape, res2[1].shape, res2[2].shape, res2[3].shape)\n",
    "print(res2[0])\n",
    "print(res2[1])\n",
    "print(res2[-2])\n",
    "print(res2[-1])\n",
    "print(\"---\")\n",
    "\n",
    "# TODO XXX: The below one is tricky to test I think\n",
    "# res = jacrev(fn, argnums=1)(layer_params[-6:], y)\n",
    "# print(res.shape, res)\n",
    "# print(\"---\")\n",
    "\n",
    "# from model_triton import _mult_jacs_in_2d\n",
    "\n",
    "# res2 = t_gpt2_tlayer_sublock2_bkwd_x(layer_params[-6:], y, train=False)\n",
    "# print(res2.shape, res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70a9ab41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 2])\n",
      "tensor([[[ 0.6491, -1.0533],\n",
      "         [-0.9334, -2.6817]]], device='cuda:0')\n",
      "---\n",
      "torch.Size([1, 2, 2, 1, 2, 2]) tensor([[[[[[ 1.4552e-11,  0.0000e+00],\n",
      "            [ 0.0000e+00,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "          [[[-1.0914e-11,  1.0914e-11],\n",
      "            [ 0.0000e+00,  0.0000e+00]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[ 0.0000e+00,  0.0000e+00],\n",
      "            [-1.4552e-11,  5.8208e-11]]],\n",
      "\n",
      "\n",
      "          [[[ 0.0000e+00,  0.0000e+00],\n",
      "            [ 7.2760e-12, -2.1828e-11]]]]]], device='cuda:0')\n",
      "---\n",
      "torch.Size([1, 2, 2, 1, 2, 2]) tensor([[[[[[ 3.5061e-11, -3.5061e-11],\n",
      "            [ 0.0000e+00,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "          [[[-7.6507e-12,  7.6507e-12],\n",
      "            [ 0.0000e+00,  0.0000e+00]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[ 0.0000e+00,  0.0000e+00],\n",
      "            [-2.6688e-11,  5.9933e-11]]],\n",
      "\n",
      "\n",
      "          [[[ 0.0000e+00,  0.0000e+00],\n",
      "            [ 5.0634e-12, -1.2318e-11]]]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# t_gpt2_tlayer_fwd_sublock2_fwd Train=True\n",
    "import torch\n",
    "#torch.set_printoptions(precision=6)\n",
    "from torch.func import jacrev\n",
    "from model_torch_func import init_tlayer_gpt2\n",
    "from model_triton import *\n",
    "BS, H, N, D = 1, 1, 2, 2\n",
    "p_gen_aux = 42\n",
    "layer_params = init_tlayer_gpt2(D, H, 4*D, 1) #, 0.00000001)\n",
    "y= torch.randn((BS, N, D), device=\"cuda\")\n",
    "mask = torch.ones((BS, N, N), dtype=torch.bool, device=\"cuda\")\n",
    "y = t_gpt2_tlayer_sublock1_fwd(layer_params[:-6], y, mask, False) # this can be train=False\n",
    "res = t_gpt2_tlayer_sublock2_fwd(layer_params[-6:], y, True, p_gen_aux)\n",
    "print(res.shape)\n",
    "print(res-y)\n",
    "print(\"---\")\n",
    "\n",
    "from functools import partial\n",
    "fn = partial(t_gpt2_tlayer_sublock2_fwd, train=True, p_gen_aux=p_gen_aux)\n",
    "# res = jacrev(fn)(layer_params[-6:], y)\n",
    "# print(len(res), res[0].shape, res[1].shape, res[2].shape, res[3].shape)\n",
    "# print(res[0])\n",
    "# print(res[1])\n",
    "# print(res[-2])\n",
    "# print(res[-1])\n",
    "# print(\"---\")\n",
    "\n",
    "# res2 = t_gpt2_tlayer_sublock2_bkwd_p(layer_params[-6:], y, train=True, p_gen_aux=p_gen_aux)\n",
    "# print(len(res2), res2[0].shape, res2[1].shape, res2[2].shape, res2[3].shape)\n",
    "# print(res2[0])\n",
    "# print(res2[1])\n",
    "# print(res2[-2])\n",
    "# print(res2[-1])\n",
    "# print(\"---\")\n",
    "\n",
    "#TODO XXX: The below one is tricky to test I think\n",
    "res = jacrev(fn, argnums=1)(layer_params[-6:], y)\n",
    "print(res.shape, res)\n",
    "print(\"---\")\n",
    "\n",
    "from model_triton import _mult_jacs_in_2d\n",
    "\n",
    "res2 = t_gpt2_tlayer_sublock2_bkwd_x(layer_params[-6:], y, train=True, p_gen_aux=p_gen_aux)\n",
    "print(res2.shape, res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e28932ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 4])\n",
      "---\n",
      "10\n",
      "- 2\n",
      "-- torch.Size([2, 4, 4]) tensor([-5.724964e-05,  9.969356e-04,  1.239672e-04], device='cuda:0')\n",
      "-- torch.Size([2, 4, 4]) tensor([ 2.495298e-04, -2.664233e-04, -9.784271e-05], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 4]) tensor([-0.000383, -0.000923, -0.000587], device='cuda:0')\n",
      "-- torch.Size([2, 4, 4]) tensor([-0.000382, -0.000922, -0.000586], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 2, 3, 2, 4]) tensor([-0.002566,  0.018484,  0.003612], device='cuda:0')\n",
      "-- torch.Size([2, 4, 2, 3, 2, 4]) tensor([ 0.011171, -0.004898, -0.002812], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 4, 4]) tensor([ 0.001943,  0.031369, -0.006014], device='cuda:0')\n",
      "-- torch.Size([2, 4, 4, 4]) tensor([ 0.004878, -0.011782, -0.013972], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 4]) tensor([ 1.968648e-04,  3.995623e-04, -4.111990e-05], device='cuda:0')\n",
      "-- torch.Size([2, 4, 4]) tensor([ 0.000222, -0.000427, -0.000456], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 4]) tensor([-0.000453, -0.000440,  0.000646], device='cuda:0')\n",
      "-- torch.Size([2, 4, 4]) tensor([-0.000441, -0.000313,  0.000488], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 16, 4]) tensor([0.003822, 0.007991, 0.000560], device='cuda:0')\n",
      "-- torch.Size([2, 4, 16, 4]) tensor([ 0.004580, -0.012393,  0.008482], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 16]) tensor([ 0.004433, -0.000558, -0.008792], device='cuda:0')\n",
      "-- torch.Size([2, 4, 16]) tensor([ 0.004495, -0.000546, -0.009070], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 4, 16]) tensor([-0.007140, -0.007133, -0.015777], device='cuda:0')\n",
      "-- torch.Size([2, 4, 4, 16]) tensor([-0.003371, -0.012921, -0.007710], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 4]) tensor([0.000000, 0.000000, 0.900000], device='cuda:0')\n",
      "-- torch.Size([2, 4, 4]) tensor([0.000000, 0.000000, 0.900000], device='cuda:0')\n",
      "---XXX---\n",
      "10\n",
      "- 2\n",
      "-- torch.Size([2, 4, 4]) tensor([-5.724961e-05,  9.969358e-04,  1.239673e-04], device='cuda:0')\n",
      "-- torch.Size([2, 4, 4]) tensor([ 2.495298e-04, -2.664232e-04, -9.784278e-05], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 4]) tensor([-0.000383, -0.000923, -0.000587], device='cuda:0')\n",
      "-- torch.Size([2, 4, 4]) tensor([-0.000382, -0.000922, -0.000586], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 2, 3, 2, 4]) tensor([-0.002566,  0.018484,  0.003612], device='cuda:0')\n",
      "-- torch.Size([2, 4, 2, 3, 2, 4]) tensor([ 0.011171, -0.004898, -0.002812], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 4, 4]) tensor([ 0.001943,  0.031369, -0.006014], device='cuda:0')\n",
      "-- torch.Size([2, 4, 4, 4]) tensor([ 0.004879, -0.011784, -0.013975], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 4]) tensor([ 1.968648e-04,  3.995623e-04, -4.111990e-05], device='cuda:0')\n",
      "-- torch.Size([2, 4, 4]) tensor([ 0.000222, -0.000427, -0.000456], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 4]) tensor([-0.000453, -0.000440,  0.000646], device='cuda:0')\n",
      "-- torch.Size([2, 4, 4]) tensor([-0.000441, -0.000313,  0.000488], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 16, 4]) tensor([0.003823, 0.007993, 0.000560], device='cuda:0')\n",
      "-- torch.Size([2, 4, 16, 4]) tensor([ 0.004579, -0.012392,  0.008481], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 16]) tensor([ 0.004433, -0.000558, -0.008792], device='cuda:0')\n",
      "-- torch.Size([2, 4, 16]) tensor([ 0.004495, -0.000546, -0.009070], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 4, 16]) tensor([-0.007141, -0.007134, -0.015779], device='cuda:0')\n",
      "-- torch.Size([2, 4, 4, 16]) tensor([-0.003371, -0.012923, -0.007711], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 4]) tensor([0.000000, 0.000000, 0.900000], device='cuda:0')\n",
      "-- torch.Size([2, 4, 4]) tensor([0.000000, 0.000000, 0.900000], device='cuda:0')\n",
      "---XXX---\n"
     ]
    }
   ],
   "source": [
    "# t_tlayer_fwd_gpt2 + train=False\n",
    "import torch\n",
    "torch.set_printoptions(precision=6)\n",
    "from torch.func import jacrev\n",
    "from model_torch_func import init_tlayer_gpt2\n",
    "from model_triton import *\n",
    "BS, H, N, D = 2, 2, 2, 4\n",
    "layer_params = init_tlayer_gpt2(D, H, 4*D, 1)\n",
    "y= torch.randn((BS, N, D), device=\"cuda\")\n",
    "mask = torch.ones((BS, N, N), dtype=torch.bool, device=\"cuda\")\n",
    "res = t_gpt2_tlayer_fwd(layer_params, y, mask, False)\n",
    "print(res.shape)\n",
    "print(\"---\")\n",
    "\n",
    "def print_res_shapes(res):\n",
    "    print(len(res))\n",
    "    for it in res:\n",
    "        print(f'-', len(it))\n",
    "        for p in it:\n",
    "            print(f'--', p.shape, p.reshape(-1)[-3:]) # TODO: modify to check different parts\n",
    "\n",
    "\n",
    "from functools import partial\n",
    "fn = partial(t_gpt2_tlayer_fwd, mask=mask, train=False)\n",
    "res = jacrev(fn)(layer_params, y)\n",
    "print_res_shapes(res)\n",
    "print(\"---XXX---\")\n",
    "\n",
    "res2 = t_gpt2_tlayer_bkwd_p(layer_params, y, mask, train=False)\n",
    "print_res_shapes(res2)\n",
    "print(\"---XXX---\")\n",
    "\n",
    "# res = jacrev(fn, argnums=1)(layer_params, y)\n",
    "# print(res.shape)\n",
    "# print(res)\n",
    "# print(\"---\")\n",
    "\n",
    "# res2 = t_gpt2_tlayer_bkwd_x(layer_params, y, mask, train=False)\n",
    "# print(res2.shape)\n",
    "# print(res2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53b2faf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 4])\n",
      "---\n",
      "10\n",
      "- 2\n",
      "-- torch.Size([2, 4, 4]) tensor([2.081779e-04, 4.265390e-04, 1.291633e-06], device='cuda:0')\n",
      "-- torch.Size([2, 4, 4]) tensor([1.358328e-05, 2.727477e-04, 3.581074e-06], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 4]) tensor([-2.026328e-04,  6.400786e-04, -8.274857e-06], device='cuda:0')\n",
      "-- torch.Size([2, 4, 4]) tensor([-2.031429e-04,  6.401073e-04, -7.973516e-06], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 2, 3, 2, 4]) tensor([-0.006227,  0.004037, -0.001009], device='cuda:0')\n",
      "-- torch.Size([2, 4, 2, 3, 2, 4]) tensor([-0.000403,  0.002582, -0.002552], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 4, 4]) tensor([-0.017456, -0.039551,  0.000631], device='cuda:0')\n",
      "-- torch.Size([2, 4, 4, 4]) tensor([ 0.001274, -0.016754, -0.002354], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 4]) tensor([ 2.511118e-04, -1.108891e-03, -6.672889e-05], device='cuda:0')\n",
      "-- torch.Size([2, 4, 4]) tensor([-0.000299, -0.000188,  0.000237], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 4]) tensor([-0.000212, -0.000929, -0.000229], device='cuda:0')\n",
      "-- torch.Size([2, 4, 4]) tensor([-0.000227, -0.000969, -0.000247], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 16, 4]) tensor([-0.002341,  0.002360,  0.000575], device='cuda:0')\n",
      "-- torch.Size([2, 4, 16, 4]) tensor([ 0.002671,  0.000393, -0.001946], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 16]) tensor([ 0.003662, -0.005603,  0.001978], device='cuda:0')\n",
      "-- torch.Size([2, 4, 16]) tensor([ 0.003659, -0.005418,  0.002027], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 4, 16]) tensor([-0.000679, -0.002695, -0.012337], device='cuda:0')\n",
      "-- torch.Size([2, 4, 4, 16]) tensor([-0.000972, -0.012718, -0.005032], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 4]) tensor([0., 0., 1.], device='cuda:0')\n",
      "-- torch.Size([2, 4, 4]) tensor([0., 0., 1.], device='cuda:0')\n",
      "---XXX---\n",
      "10\n",
      "- 2\n",
      "-- torch.Size([2, 4, 4]) tensor([2.081779e-04, 4.265390e-04, 1.291632e-06], device='cuda:0')\n",
      "-- torch.Size([2, 4, 4]) tensor([1.358328e-05, 2.727477e-04, 3.581074e-06], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 4]) tensor([-2.026328e-04,  6.400786e-04, -8.274864e-06], device='cuda:0')\n",
      "-- torch.Size([2, 4, 4]) tensor([-2.031429e-04,  6.401073e-04, -7.973511e-06], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 2, 3, 2, 4]) tensor([-0.006227,  0.004037, -0.001009], device='cuda:0')\n",
      "-- torch.Size([2, 4, 2, 3, 2, 4]) tensor([-0.000403,  0.002582, -0.002552], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 4, 4]) tensor([-0.017458, -0.039556,  0.000631], device='cuda:0')\n",
      "-- torch.Size([2, 4, 4, 4]) tensor([ 0.001274, -0.016752, -0.002353], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 4]) tensor([ 2.511118e-04, -1.108891e-03, -6.672891e-05], device='cuda:0')\n",
      "-- torch.Size([2, 4, 4]) tensor([-0.000299, -0.000188,  0.000237], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 4]) tensor([-0.000212, -0.000929, -0.000229], device='cuda:0')\n",
      "-- torch.Size([2, 4, 4]) tensor([-0.000227, -0.000969, -0.000247], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 16, 4]) tensor([-0.002341,  0.002360,  0.000575], device='cuda:0')\n",
      "-- torch.Size([2, 4, 16, 4]) tensor([ 0.002671,  0.000392, -0.001946], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 16]) tensor([ 0.003662, -0.005603,  0.001978], device='cuda:0')\n",
      "-- torch.Size([2, 4, 16]) tensor([ 0.003659, -0.005418,  0.002027], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 4, 16]) tensor([-0.000679, -0.002695, -0.012337], device='cuda:0')\n",
      "-- torch.Size([2, 4, 4, 16]) tensor([-0.000972, -0.012718, -0.005032], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 4, 4]) tensor([0., 0., 1.], device='cuda:0')\n",
      "-- torch.Size([2, 4, 4]) tensor([0., 0., 1.], device='cuda:0')\n",
      "---XXX---\n"
     ]
    }
   ],
   "source": [
    "# t_tlayer_fwd_gpt2 + train=True\n",
    "import torch\n",
    "torch.set_printoptions(precision=6)\n",
    "from torch.func import jacrev\n",
    "from model_torch_func import init_tlayer_gpt2\n",
    "from model_triton import *\n",
    "BS, H, N, D = 2, 2, 2, 4\n",
    "p_gen_aux = [42, 43, 44]\n",
    "layer_params = init_tlayer_gpt2(D, H, 4*D, 1)\n",
    "y= torch.randn((BS, N, D), device=\"cuda\")\n",
    "mask = torch.ones((BS, N, N), dtype=torch.bool, device=\"cuda\")\n",
    "res = t_gpt2_tlayer_fwd(layer_params, y, mask, True, p_gen_aux=p_gen_aux)\n",
    "print(res.shape)\n",
    "print(\"---\")\n",
    "\n",
    "def print_res_shapes(res):\n",
    "    print(len(res))\n",
    "    for it in res:\n",
    "        print(f'-', len(it))\n",
    "        for p in it:\n",
    "            print(f'--', p.shape, p.reshape(-1)[-3:]) # TODO: modify to check different parts\n",
    "\n",
    "\n",
    "from functools import partial\n",
    "fn = partial(t_gpt2_tlayer_fwd, mask=mask, train=True, p_gen_aux=p_gen_aux)\n",
    "res = jacrev(fn)(layer_params, y)\n",
    "print_res_shapes(res)\n",
    "print(\"---XXX---\")\n",
    "\n",
    "res2 = t_gpt2_tlayer_bkwd_p(layer_params, y, mask, train=True, p_gen_aux=p_gen_aux)\n",
    "print_res_shapes(res2)\n",
    "print(\"---XXX---\")\n",
    "\n",
    "# res = jacrev(fn, argnums=1)(layer_params, y)\n",
    "# print(res.shape)\n",
    "# print(res)\n",
    "# print(\"---\")\n",
    "\n",
    "# res2 = t_gpt2_tlayer_bkwd_x(layer_params, y, mask, train=False)\n",
    "# print(res2.shape)\n",
    "# print(res2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "235d3223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [0, 1]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.randn((2, N))\n",
    "torch.arange(y.shape[1]).unsqueeze(0).expand(*y.shape)\n",
    "#.expand(y.shape[0], 1)\n",
    "#res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "438ffb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 2])\n",
      "torch.Size([1, 2, 2])\n",
      "tensor([[[[[1., 0.],\n",
      "           [0., 0.]],\n",
      "\n",
      "          [[0., 1.],\n",
      "           [0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0.],\n",
      "           [1., 0.]],\n",
      "\n",
      "          [[0., 0.],\n",
      "           [0., 1.]]]]], device='cuda:0')\n",
      "tensor([[0, 1],\n",
      "        [0, 1]], device='cuda:0')\n",
      "len 1\n",
      "tensor([[[[[1., 0.],\n",
      "           [0., 0.]],\n",
      "\n",
      "          [[0., 1.],\n",
      "           [0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0.],\n",
      "           [1., 0.]],\n",
      "\n",
      "          [[0., 0.],\n",
      "           [0., 1.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[1., 0.],\n",
      "           [0., 0.]],\n",
      "\n",
      "          [[0., 1.],\n",
      "           [0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0.],\n",
      "           [1., 0.]],\n",
      "\n",
      "          [[0., 0.],\n",
      "           [0., 1.]]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.func import jacrev\n",
    "from model_torch_func import init_tlayer_gpt2\n",
    "from model_triton import *\n",
    "\n",
    "BS, H, N, D = 1, 1, 2, 2\n",
    "vocab_size=12\n",
    "layers=1\n",
    "params = init_transformer_gpt2(vocab_size, D, layers, H, 4*D, N)\n",
    "y= torch.randint(vocab_size, (BS, N), device=\"cuda\")\n",
    "def fn(params, y):\n",
    "    return y + params\n",
    "y = t_embed_fwd(params[0], y)\n",
    "print(y.shape)\n",
    "res= fn(params[1][0], y)\n",
    "print(res.shape)\n",
    "\n",
    "res = jacrev(fn)(params[1][0], y)\n",
    "print(res)\n",
    "\n",
    "def fn_bkwd(params, y):\n",
    "    y = y.reshape((-1, y.shape[-1]))\n",
    "    indices = torch.arange(y.shape[1], device=y.device).unsqueeze(0).expand(*y.shape) # we \n",
    "    print(indices)\n",
    "    jac_pos_enc = list(t_embed_bkwd(params[1], indices))\n",
    "    print(f'len', len(jac_pos_enc))\n",
    "    #jac_pos_enc[0]\n",
    "    jac_pos_enc[0][jac_pos_enc[0]!=0] = 1\n",
    "#    jac_pos_enc = [jac_pos_enc[0], ]\n",
    "#    jac_pos_enc = [jac_pos_enc[0] / (params[1][0].shape[1] * 2), ]\n",
    "    return jac_pos_enc\n",
    "\n",
    "res = fn_bkwd(params, y)\n",
    "print(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddde67ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 4])\n",
      "---\n",
      "5\n",
      "- 2\n",
      "-- torch.Size([1, 2, 4, 6, 4]) tensor([0., 0., 0.], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 6]) tensor([0., 0., 0.], device='cuda:0')\n",
      "- 1\n",
      "-- torch.Size([1, 2, 4, 2, 4]) tensor([-4.178149, -3.614153,  9.409573], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([ 0.000436, -0.003398,  0.001194], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([-0.000888,  0.005572, -0.003817], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 2, 3, 2, 4]) tensor([-0.070617, -0.087650, -0.044986], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4, 4]) tensor([-0.201005, -0.245705,  0.369999], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([-5.039283e-03,  6.397760e-05, -1.143041e-03], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([ 0.005527, -0.000223,  0.004835], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 16, 4]) tensor([0.042090, 0.012909, 0.010935], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 16]) tensor([ 0.088869, -0.090330, -0.046223], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4, 16]) tensor([0.110321, 0.061848, 0.029441], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([-4.189424, -3.612936,  9.426817], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([-6.224815e-04,  1.709849e-05, -7.149593e-04], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([ 1.271174e-03, -2.878036e-05,  2.300125e-03], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 2, 3, 2, 4]) tensor([0.000726, 0.000910, 0.000461], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4, 4]) tensor([ 0.030374, -0.075998, -0.181419], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([-0.005513,  0.001674, -0.001236], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([ 0.006058, -0.006111,  0.005079], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 16, 4]) tensor([0.052607, 0.015833, 0.014062], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 16]) tensor([ 0.103114, -0.037734, -0.057807], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4, 16]) tensor([-0.072167,  0.187214, -0.097388], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([-4.214969, -3.506169,  9.350953], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([ 0.000000,  0.000000, -0.258508], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([0., 0., 1.], device='cuda:0')\n",
      "---XXXX--\n",
      "layers_jacs_x[0].shape torch.Size([1, 2, 4, 1, 2, 4]) jac_dropout.shape torch.Size([1, 2, 4, 1, 2, 4])\n",
      "5\n",
      "- 2\n",
      "-- torch.Size([1, 2, 4, 6, 4]) tensor([0., 0., 0.], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 6]) tensor([0., 0., 0.], device='cuda:0')\n",
      "- 1\n",
      "-- torch.Size([1, 2, 4, 2, 4]) tensor([-4.178148, -3.614153,  9.409572], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([ 0.000436, -0.003398,  0.001194], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([-0.000888,  0.005572, -0.003817], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 2, 3, 2, 4]) tensor([-0.070617, -0.087650, -0.044986], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4, 4]) tensor([-0.201069, -0.245783,  0.370117], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([-5.039283e-03,  6.397758e-05, -1.143041e-03], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([ 0.005527, -0.000223,  0.004835], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 16, 4]) tensor([0.042087, 0.012908, 0.010934], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 16]) tensor([ 0.088869, -0.090330, -0.046223], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4, 16]) tensor([0.110327, 0.061851, 0.029442], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([-4.189423, -3.612935,  9.426817], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([-6.224812e-04,  1.709862e-05, -7.149595e-04], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([ 1.271174e-03, -2.878060e-05,  2.300126e-03], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 2, 3, 2, 4]) tensor([0.000726, 0.000910, 0.000461], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4, 4]) tensor([ 0.030379, -0.076011, -0.181449], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([-0.005513,  0.001674, -0.001236], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([ 0.006058, -0.006111,  0.005079], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 16, 4]) tensor([0.052614, 0.015835, 0.014064], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 16]) tensor([ 0.103114, -0.037734, -0.057807], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4, 16]) tensor([-0.072163,  0.187202, -0.097382], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([-4.214968, -3.506169,  9.350953], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([-0.000000, -0.000000, -0.258508], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([0., 0., 1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# t_gpt2_tlayers_fwd + train=False\n",
    "import torch\n",
    "torch.set_printoptions(precision=6)\n",
    "from torch.func import jacrev\n",
    "from model_torch_func import init_tlayer_gpt2\n",
    "from model_triton import *\n",
    "BS, H, N, D = 1, 2, 2, 4\n",
    "vocab_size = 6\n",
    "layers = 2\n",
    "layers_params = init_transformer_gpt2(vocab_size, D, layers, H, 4*D, N)\n",
    "y= torch.randint(vocab_size, (BS, N), device=\"cuda\")\n",
    "mask = torch.ones((BS, N, N), dtype=torch.bool, device=\"cuda\")\n",
    "res = t_gpt2_tlayers_fwd(layers_params, y, mask, None, False)\n",
    "print(res.shape)\n",
    "\n",
    "print(\"---\")\n",
    "\n",
    "def print_res_shapes(res):\n",
    "    print(len(res))\n",
    "    for it in res:\n",
    "        print(f'-', len(it))\n",
    "        for p in it:\n",
    "            print(f'--', p.shape, p.reshape(-1)[-3:]) # TODO: modify to check different parts\n",
    "\n",
    "from functools import partial\n",
    "fn = partial(t_gpt2_tlayers_fwd, mask=mask, indices=None, train=False)\n",
    "res = jacrev(fn)(layers_params, y)\n",
    "print_res_shapes(res)\n",
    "print(\"---XXXX--\")\n",
    "\n",
    "res2 = t_gpt2_tlayers_bkwd_p(layers_params, y, mask, None, train=False)\n",
    "print_res_shapes(res2) \n",
    "#print(res2[0])\n",
    "#print(res2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f932eb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 4])\n",
      "---\n",
      "5\n",
      "- 2\n",
      "-- torch.Size([1, 2, 4, 6, 4]) tensor([0., 0., 0.], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 6]) tensor([0., 0., 0.], device='cuda:0')\n",
      "- 1\n",
      "-- torch.Size([1, 2, 4, 2, 4]) tensor([-4.556520, -1.069513, 13.938005], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([-0.003073, -0.003849,  0.001485], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([-0.013222,  0.004133, -0.004684], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 2, 3, 2, 4]) tensor([ 0.034813, -0.139275, -0.047691], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4, 4]) tensor([-0.135330, -0.044505,  0.306945], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([-0.001051, -0.015113,  0.003353], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([0.004411, 0.011853, 0.007323], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 16, 4]) tensor([-0.006158, -0.032420,  0.011833], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 16]) tensor([ 0.112122, -0.007073,  0.025366], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4, 16]) tensor([ 0.429916,  0.057772, -0.193782], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([-4.354026, -1.194099, 13.958805], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([0.000954, 0.004351, 0.000632], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([ 0.003919, -0.004635, -0.001981], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 2, 3, 2, 4]) tensor([-0.029742,  0.114747,  0.039048], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4, 4]) tensor([ 0.154211,  0.013442, -0.603630], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([-0.000808, -0.000555, -0.001770], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([ 0.003419,  0.000435, -0.003867], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 16, 4]) tensor([-0.005396, -0.029111,  0.010456], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 16]) tensor([0.025056, 0.065258, 0.022849], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4, 16]) tensor([-0.226644,  0.084617, -0.042790], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([-4.482968, -1.136939, 14.039040], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([0.000000, 0.000000, 0.454558], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([0., 0., 1.], device='cuda:0')\n",
      "---XXXX--\n",
      "layers_jacs_x[0].shape torch.Size([1, 2, 4, 1, 2, 4]) jac_dropout.shape torch.Size([1, 2, 4, 1, 2, 4])\n",
      "5\n",
      "- 2\n",
      "-- torch.Size([1, 2, 4, 6, 4]) tensor([0., 0., 0.], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 6]) tensor([0., 0., 0.], device='cuda:0')\n",
      "- 1\n",
      "-- torch.Size([1, 2, 4, 2, 4]) tensor([-4.556518, -1.069513, 13.938007], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([-0.003073, -0.003849,  0.001485], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([-0.013222,  0.004133, -0.004684], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 2, 3, 2, 4]) tensor([ 0.034813, -0.139275, -0.047691], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4, 4]) tensor([-0.135344, -0.044510,  0.306977], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([-0.001051, -0.015113,  0.003353], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([0.004411, 0.011853, 0.007323], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 16, 4]) tensor([-0.006156, -0.032413,  0.011830], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 16]) tensor([ 0.112122, -0.007073,  0.025366], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4, 16]) tensor([ 0.429958,  0.057778, -0.193801], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([-4.354026, -1.194099, 13.958806], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([0.000954, 0.004351, 0.000632], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([ 0.003919, -0.004635, -0.001981], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 2, 3, 2, 4]) tensor([-0.029742,  0.114747,  0.039048], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4, 4]) tensor([ 0.154243,  0.013444, -0.603755], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([-0.000808, -0.000555, -0.001770], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([ 0.003419,  0.000435, -0.003867], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 16, 4]) tensor([-0.005397, -0.029119,  0.010460], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 16]) tensor([0.025056, 0.065258, 0.022849], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4, 16]) tensor([-0.226643,  0.084616, -0.042790], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([-4.482968, -1.136939, 14.039040], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([0.000000, 0.000000, 0.454558], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([0., 0., 1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# t_gpt2_tlayers_fwd + train=True\n",
    "import torch\n",
    "torch.set_printoptions(precision=6)\n",
    "from torch.func import jacrev\n",
    "from model_torch_func import init_tlayer_gpt2\n",
    "from model_triton import *\n",
    "BS, H, N, D = 1, 2, 2, 4\n",
    "vocab_size = 6\n",
    "layers = 2\n",
    "p_gen_aux = [42] + [43,44,45] * layers\n",
    "layers_params = init_transformer_gpt2(vocab_size, D, layers, H, 4*D, N)\n",
    "y= torch.randint(vocab_size, (BS, N), device=\"cuda\")\n",
    "mask = torch.ones((BS, N, N), dtype=torch.bool, device=\"cuda\")\n",
    "res = t_gpt2_tlayers_fwd(layers_params, y, mask, None, True, p_gen_aux=p_gen_aux)\n",
    "print(res.shape)\n",
    "\n",
    "print(\"---\")\n",
    "\n",
    "def print_res_shapes(res):\n",
    "    print(len(res))\n",
    "    for it in res:\n",
    "        print(f'-', len(it))\n",
    "        for p in it:\n",
    "            print(f'--', p.shape, p.reshape(-1)[-3:]) # TODO: modify to check different parts\n",
    "\n",
    "from functools import partial\n",
    "fn = partial(t_gpt2_tlayers_fwd, mask=mask, indices=None, train=True, p_gen_aux=p_gen_aux)\n",
    "res = jacrev(fn)(layers_params, y)\n",
    "print_res_shapes(res)\n",
    "print(\"---XXXX--\")\n",
    "\n",
    "res2 = t_gpt2_tlayers_bkwd_p(layers_params, y, mask, None, True, p_gen_aux)\n",
    "print_res_shapes(res2) \n",
    "#print(res2[0])\n",
    "#print(res2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16c1a714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "5\n",
      "- 2\n",
      "-- torch.Size([2, 2, 6, 6, 4]) tensor([-0.023876,  0.895180,  0.913492], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 6]) tensor([0., 0., 1.], device='cuda:0')\n",
      "- 1\n",
      "-- torch.Size([2, 2, 6, 2, 4]) tensor([-0.027715,  0.554218, -0.194621], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([-1.625612e-05, -4.947522e-05,  2.133402e-05], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([-7.278824e-05, -2.352890e-04, -2.047363e-04], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 2, 3, 2, 4]) tensor([ 0.001080,  0.001016, -0.000505], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4, 4]) tensor([ 0.000274,  0.000275, -0.001408], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([ 1.603317e-05, -3.487642e-05, -4.740024e-05], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([ 2.512884e-04,  1.676124e-04, -3.700890e-05], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 16, 4]) tensor([-4.349073e-05,  1.361640e-04, -8.490586e-04], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 16]) tensor([-0.000826,  0.002028, -0.000667], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4, 16]) tensor([0.002004, 0.006177, 0.001032], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([-0.036222,  0.553942, -0.190550], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([-1.984930e-05, -2.153260e-06,  2.302995e-05], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([-9.251987e-05, -1.012022e-05, -2.355694e-04], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 2, 3, 2, 4]) tensor([ 0.000252,  0.000253, -0.000116], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4, 4]) tensor([0.001863, 0.001672, 0.001322], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([-4.710343e-06, -4.608614e-06, -2.948110e-04], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([-8.363288e-05,  2.181862e-05, -2.285479e-04], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 16, 4]) tensor([-0.000212,  0.000796, -0.004865], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 16]) tensor([ 0.001562,  0.000651, -0.003770], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4, 16]) tensor([-0.001776,  0.003744,  0.002867], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([-0.036460,  0.547920, -0.187887], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([-7.087892e-05, -2.047091e-03,  5.907665e-03], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([-0.002246,  0.009601,  0.004535], device='cuda:0')\n",
      "---XXXX--\n",
      "tensor([[[False, False],\n",
      "         [False, False]],\n",
      "\n",
      "        [[False, False],\n",
      "         [False, False]]], device='cuda:0')\n",
      "5\n",
      "- 2\n",
      "-- torch.Size([2, 2, 6, 6, 4]) tensor([-0.023870,  0.895193,  0.913494], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 6]) tensor([0., 0., 1.], device='cuda:0')\n",
      "- 1\n",
      "-- torch.Size([2, 2, 6, 2, 4]) tensor([-0.027728,  0.554225, -0.194620], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([-1.626021e-05, -4.946796e-05,  2.141974e-05], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([-7.279612e-05, -2.353698e-04, -2.047083e-04], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 2, 3, 2, 4]) tensor([ 0.001081,  0.001017, -0.000506], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4, 4]) tensor([ 0.000274,  0.000274, -0.001408], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([ 1.603507e-05, -3.487708e-05, -4.740467e-05], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([ 2.512934e-04,  1.676142e-04, -3.701129e-05], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 16, 4]) tensor([-4.351476e-05,  1.362736e-04, -8.496965e-04], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 16]) tensor([-0.000826,  0.002028, -0.000668], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4, 16]) tensor([0.002004, 0.006177, 0.001032], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([-0.036231,  0.553951, -0.190551], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([-1.983094e-05, -2.191666e-06,  2.349548e-05], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([-9.257564e-05, -1.016033e-05, -2.355170e-04], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 2, 3, 2, 4]) tensor([ 0.000252,  0.000253, -0.000117], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4, 4]) tensor([0.001866, 0.001674, 0.001324], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([-4.711499e-06, -4.608651e-06, -2.948131e-04], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([-8.362949e-05,  2.181902e-05, -2.285511e-04], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 16, 4]) tensor([-0.000212,  0.000796, -0.004865], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 16]) tensor([ 0.001562,  0.000651, -0.003770], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4, 16]) tensor([-0.001776,  0.003744,  0.002867], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([-0.036467,  0.547930, -0.187889], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([-7.091383e-05, -2.047069e-03,  5.907627e-03], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([-0.002246,  0.009601,  0.004535], device='cuda:0')\n",
      "---XXXX--\n",
      "layers_jacs_x[0].shape torch.Size([2, 2, 4, 2, 2, 4]) jac_dropout.shape torch.Size([2, 2, 4, 2, 2, 4])\n",
      "5\n",
      "- 2\n",
      "-- torch.Size([2, 2, 6, 6, 4]) tensor([-0.023870,  0.895193,  0.913494], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 6]) tensor([0., 0., 1.], device='cuda:0')\n",
      "- 1\n",
      "-- torch.Size([2, 2, 6, 2, 4]) tensor([-0.027728,  0.554225, -0.194620], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([-1.626022e-05, -4.946795e-05,  2.141973e-05], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([-7.279611e-05, -2.353698e-04, -2.047083e-04], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 2, 3, 2, 4]) tensor([ 0.001081,  0.001017, -0.000506], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4, 4]) tensor([ 0.000274,  0.000274, -0.001408], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([ 1.603507e-05, -3.487707e-05, -4.740463e-05], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([ 2.512933e-04,  1.676142e-04, -3.701124e-05], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 16, 4]) tensor([-4.350083e-05,  1.362268e-04, -8.494092e-04], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 16]) tensor([-0.000826,  0.002028, -0.000668], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4, 16]) tensor([0.002004, 0.006178, 0.001032], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([-0.036231,  0.553951, -0.190551], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([-1.983095e-05, -2.191656e-06,  2.349549e-05], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([-9.257568e-05, -1.016032e-05, -2.355171e-04], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 2, 3, 2, 4]) tensor([ 0.000252,  0.000253, -0.000117], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4, 4]) tensor([0.001866, 0.001675, 0.001324], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([-4.711493e-06, -4.608648e-06, -2.948131e-04], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([-8.362938e-05,  2.181900e-05, -2.285510e-04], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 16, 4]) tensor([-0.000212,  0.000796, -0.004864], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 16]) tensor([ 0.001562,  0.000651, -0.003770], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4, 16]) tensor([-0.001776,  0.003744,  0.002867], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([-0.036467,  0.547930, -0.187889], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([-7.091383e-05, -2.047069e-03,  5.907627e-03], device='cuda:0')\n",
      "-- torch.Size([2, 2, 6, 4]) tensor([-0.002246,  0.009601,  0.004535], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# t_gpt2_forward + train=False\n",
    "import torch\n",
    "torch.set_printoptions(precision=6)\n",
    "from torch.func import jacrev\n",
    "from model_torch_func import init_tlayer_gpt2\n",
    "from model_triton import *\n",
    "BS, H, N, D = 2, 2, 2, 4\n",
    "vocab_size = 6\n",
    "layers = 2\n",
    "layers_params = init_transformer_gpt2(vocab_size, D, layers, H, 4*D, N)\n",
    "y= torch.randint(vocab_size, (BS, N), device=\"cuda\")\n",
    "mask = torch.ones((BS, N, N), dtype=torch.bool, device=\"cuda\")\n",
    "res = t_gpt2_forward(layers_params, y, mask, None, False)\n",
    "\n",
    "print(\"---\")\n",
    "\n",
    "def print_res_shapes(res):\n",
    "    print(len(res))\n",
    "    for it in res:\n",
    "        print(f'-', len(it))\n",
    "        for p in it:\n",
    "            print(f'--', p.shape, p.reshape(-1)[-3:]) # TODO: modify to check different parts\n",
    "\n",
    "from functools import partial\n",
    "fn = partial(t_gpt2_forward, y_mask=mask, y_indices=None, train=False)\n",
    "res = jacrev(fn)(layers_params, y)\n",
    "print_res_shapes(res)\n",
    "print(\"---XXXX--\")\n",
    "for i, i_mask in enumerate(mask):\n",
    "    #mask[i] = torch.tril(i_mask)\n",
    "    mask[i] = torch.zeros_like(i_mask)\n",
    "print(mask)\n",
    "fn = partial(t_gpt2_forward, y_mask=mask, y_indices=None, train=False)\n",
    "res = jacrev(fn)(layers_params, y)\n",
    "print_res_shapes(res)\n",
    "print(\"---XXXX--\")\n",
    "\n",
    "res2 = t_gpt2_bkwd_p(layers_params, y, mask, None, train=False)\n",
    "print_res_shapes(res2) \n",
    "#print(res2[0])\n",
    "#print(res2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ac52f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res.shape torch.Size([2, 5, 6])\n",
      "---\n",
      "5\n",
      "- 2\n",
      "-- torch.Size([2, 5, 6, 6, 4]) tensor([-0.137782,  1.369160, -0.406006], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 6]) tensor([0., 0., 1.], device='cuda:0')\n",
      "- 1\n",
      "-- torch.Size([2, 5, 6, 5, 4]) tensor([-0.142560,  0.030283,  0.000000], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([9.807979e-05, 5.954188e-05, 1.136734e-05], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([ 1.731989e-04,  1.015569e-04, -1.746008e-05], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 2, 3, 2, 4]) tensor([-0.000856, -0.001002,  0.000880], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4, 4]) tensor([ 0.001300,  0.004768, -0.002701], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([-1.308097e-06, -2.329485e-06,  4.134895e-05], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([-9.912897e-06, -1.599405e-06, -9.898079e-05], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 16, 4]) tensor([-1.658287e-06, -2.319309e-05,  8.260810e-06], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 16]) tensor([ 3.807084e-04,  1.531135e-05, -1.795098e-05], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4, 16]) tensor([-0.002651, -0.001530, -0.005198], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([-0.142096,  0.029796,  0.155064], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([ 2.937228e-05, -3.748945e-05,  2.155548e-05], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([ 5.201357e-05, -4.639488e-05, -3.386604e-05], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 2, 3, 2, 4]) tensor([ 0.001409,  0.001670, -0.001430], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4, 4]) tensor([0.000972, 0.000670, 0.000410], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([-1.392590e-05,  6.654514e-05, -2.751922e-05], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([-1.007619e-04,  5.062900e-05,  6.689699e-05], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 16, 4]) tensor([-8.058478e-05, -7.665521e-04,  2.399035e-04], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 16]) tensor([-0.000776,  0.000701, -0.000583], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4, 16]) tensor([-4.657265e-05,  5.612299e-04,  3.153970e-05], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([-0.141786,  0.029776,  0.154578], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([ 0.001676,  0.079378, -0.006923], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([0.011372, 0.060674, 0.017055], device='cuda:0')\n",
      "---XXXX--\n",
      "tensor([[[False, False, False, False, False],\n",
      "         [False, False, False, False, False],\n",
      "         [False, False, False, False, False],\n",
      "         [False, False, False, False, False],\n",
      "         [False, False, False, False, False]],\n",
      "\n",
      "        [[False, False, False, False, False],\n",
      "         [False, False, False, False, False],\n",
      "         [False, False, False, False, False],\n",
      "         [False, False, False, False, False],\n",
      "         [False, False, False, False, False]]], device='cuda:0')\n",
      "5\n",
      "- 2\n",
      "-- torch.Size([2, 5, 6, 6, 4]) tensor([-0.137781,  1.369159, -0.406006], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 6]) tensor([0., 0., 1.], device='cuda:0')\n",
      "- 1\n",
      "-- torch.Size([2, 5, 6, 5, 4]) tensor([-0.142560,  0.030283,  0.000000], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([9.800398e-05, 5.959357e-05, 1.137489e-05], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([ 1.732068e-04,  1.015700e-04, -1.746970e-05], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 2, 3, 2, 4]) tensor([-0.000856, -0.001004,  0.000880], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4, 4]) tensor([ 0.001300,  0.004768, -0.002699], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([-1.307901e-06, -2.329335e-06,  4.134874e-05], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([-9.912726e-06, -1.598817e-06, -9.898008e-05], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 16, 4]) tensor([-1.659500e-06, -2.319754e-05,  8.262032e-06], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 16]) tensor([ 3.807094e-04,  1.530532e-05, -1.795099e-05], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4, 16]) tensor([-0.002651, -0.001530, -0.005198], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([-0.142096,  0.029795,  0.155065], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([ 2.937008e-05, -3.744567e-05,  2.154883e-05], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([ 5.201073e-05, -4.640390e-05, -3.385073e-05], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 2, 3, 2, 4]) tensor([ 0.001410,  0.001669, -0.001430], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4, 4]) tensor([0.000972, 0.000669, 0.000412], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([-1.392576e-05,  6.654547e-05, -2.751918e-05], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([-1.007615e-04,  5.062923e-05,  6.689695e-05], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 16, 4]) tensor([-8.058478e-05, -7.665521e-04,  2.399035e-04], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 16]) tensor([-0.000776,  0.000701, -0.000583], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4, 16]) tensor([-4.657265e-05,  5.612299e-04,  3.153970e-05], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([-0.141786,  0.029776,  0.154578], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([ 0.001676,  0.079378, -0.006923], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([0.011372, 0.060674, 0.017055], device='cuda:0')\n",
      "---XXXX--\n",
      "layers_jacs_x[0].shape torch.Size([2, 5, 4, 2, 5, 4]) jac_dropout.shape torch.Size([2, 5, 4, 2, 5, 4])\n",
      "5\n",
      "- 2\n",
      "-- torch.Size([2, 5, 6, 6, 4]) tensor([-0.137781,  1.369159, -0.406006], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 6]) tensor([0., 0., 1.], device='cuda:0')\n",
      "- 1\n",
      "-- torch.Size([2, 5, 6, 5, 4]) tensor([-0.142560,  0.030283,  0.000000], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([9.800396e-05, 5.959355e-05, 1.137489e-05], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([ 1.732068e-04,  1.015699e-04, -1.746970e-05], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 2, 3, 2, 4]) tensor([-0.000856, -0.001004,  0.000880], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4, 4]) tensor([ 0.001300,  0.004770, -0.002700], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([-1.307901e-06, -2.329329e-06,  4.134874e-05], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([-9.912724e-06, -1.598802e-06, -9.898004e-05], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 16, 4]) tensor([-1.659453e-06, -2.319486e-05,  8.261087e-06], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 16]) tensor([ 3.807089e-04,  1.530533e-05, -1.795124e-05], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4, 16]) tensor([-0.002652, -0.001531, -0.005200], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([-0.142096,  0.029795,  0.155065], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([ 2.937009e-05, -3.744567e-05,  2.154883e-05], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([ 5.201074e-05, -4.640391e-05, -3.385073e-05], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 2, 3, 2, 4]) tensor([ 0.001410,  0.001669, -0.001430], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4, 4]) tensor([0.000972, 0.000669, 0.000412], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([-1.392577e-05,  6.654547e-05, -2.751918e-05], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([-1.007615e-04,  5.062924e-05,  6.689695e-05], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 16, 4]) tensor([-8.059382e-05, -7.666379e-04,  2.399303e-04], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 16]) tensor([-0.000776,  0.000701, -0.000583], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4, 16]) tensor([-4.658364e-05,  5.613624e-04,  3.154715e-05], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([-0.141786,  0.029776,  0.154577], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([ 0.001676,  0.079378, -0.006923], device='cuda:0')\n",
      "-- torch.Size([2, 5, 6, 4]) tensor([0.011372, 0.060674, 0.017055], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# t_gpt2_forward + train=True\n",
    "import torch\n",
    "torch.set_printoptions(precision=6)\n",
    "from torch.func import jacrev\n",
    "from model_torch_func import init_tlayer_gpt2\n",
    "from model_triton import *\n",
    "BS, H, N, D = 2, 2, 5, 4\n",
    "vocab_size = 6\n",
    "layers = 2\n",
    "p_gen_aux = [42] + [43,44,45] * layers\n",
    "layers_params = init_transformer_gpt2(vocab_size, D, layers, H, 4*D, N)\n",
    "y= torch.randint(vocab_size, (BS, N), device=\"cuda\")\n",
    "mask = torch.ones((BS, N, N), dtype=torch.bool, device=\"cuda\")\n",
    "res = t_gpt2_forward(layers_params, y, mask, None, True, p_gen_aux)\n",
    "print(f'res.shape', res.shape)\n",
    "\n",
    "print(\"---\")\n",
    "\n",
    "def print_res_shapes(res):\n",
    "    print(len(res))\n",
    "    for it in res:\n",
    "        print(f'-', len(it))\n",
    "        for p in it:\n",
    "            print(f'--', p.shape, p.reshape(-1)[-3:]) # TODO: modify to check different parts\n",
    "\n",
    "from functools import partial\n",
    "fn = partial(t_gpt2_forward, y_mask=mask, y_indices=None, train=True, p_gen_aux=p_gen_aux)\n",
    "res = jacrev(fn)(layers_params, y)\n",
    "print_res_shapes(res)\n",
    "print(\"---XXXX--\")\n",
    "for i, i_mask in enumerate(mask):\n",
    "    #mask[i] = torch.tril(i_mask)\n",
    "    mask[i] = torch.zeros_like(i_mask)\n",
    "print(mask)\n",
    "fn = partial(t_gpt2_forward, y_mask=mask, y_indices=None, train=True, p_gen_aux=p_gen_aux)\n",
    "res = jacrev(fn)(layers_params, y)\n",
    "print_res_shapes(res)\n",
    "print(\"---XXXX--\")\n",
    "\n",
    "res2 = t_gpt2_bkwd_p(layers_params, y, mask, None, train=True, p_gen_aux=p_gen_aux)\n",
    "print_res_shapes(res2) \n",
    "#print(res2[0])\n",
    "#print(res2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa4d85f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_labels tensor([[2, 0],\n",
      "        [2, 1],\n",
      "        [2, 0],\n",
      "        [2, 1]], device='cuda:0')\n",
      "2 tensor(1.605373, device='cuda:0')\n",
      "---\n",
      "2 torch.Size([4, 2, 3])\n",
      "tensor([[[ 0.021246,  0.117412, -0.138658],\n",
      "         [ 0.000000,  0.000000,  0.000000]],\n",
      "\n",
      "        [[ 0.015352,  0.091664, -0.107017],\n",
      "         [ 0.060215, -0.130583,  0.070369]],\n",
      "\n",
      "        [[ 0.103066,  0.052031, -0.155097],\n",
      "         [ 0.000000,  0.000000,  0.000000]],\n",
      "\n",
      "        [[ 0.093773,  0.005562, -0.099334],\n",
      "         [ 0.011291, -0.136737,  0.125446]]], device='cuda:0')\n",
      "--\n",
      "torch.Size([4, 2, 3])\n",
      "tensor([[[ 0.021246,  0.117412, -0.138658],\n",
      "         [ 0.000000,  0.000000,  0.000000]],\n",
      "\n",
      "        [[ 0.015352,  0.091664, -0.107017],\n",
      "         [ 0.060215, -0.130583,  0.070369]],\n",
      "\n",
      "        [[ 0.103066,  0.052031, -0.155097],\n",
      "         [ 0.000000,  0.000000,  0.000000]],\n",
      "\n",
      "        [[ 0.093773,  0.005562, -0.099334],\n",
      "         [ 0.011291, -0.136737,  0.125446]]], device='cuda:0')\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# t_avg_cross_entropy_loss\n",
    "import torch\n",
    "from torch.func import jacrev\n",
    "from loss_and_optimizer_triton import t_avg_cross_entropy_loss, t_avg_cross_entropy_loss_bkwd\n",
    "from model_triton import t_log_softmax_fwd, t_log_softmax_bkwd\n",
    "BS, N, V = 4, 2, 3\n",
    "y_labels = torch.randint(0, V, (BS, N), device=\"cuda\")\n",
    "y_logits = torch.randn((BS, N, V), device=\"cuda\")\n",
    "print(\"y_labels\", y_labels)\n",
    "\n",
    "output = t_avg_cross_entropy_loss(y_labels, y_logits)\n",
    "print(len(output), output[0])\n",
    "print('---')\n",
    "\n",
    "res = jacrev(t_avg_cross_entropy_loss, argnums=1, has_aux=True)(y_labels, y_logits)\n",
    "print(len(res), res[0].shape)\n",
    "print(res[0])\n",
    "print('--')\n",
    "\n",
    "res2 = t_avg_cross_entropy_loss_bkwd(y_labels, y_logits)\n",
    "print(res2.shape)\n",
    "print(res2)\n",
    "print('--') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5110c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(1.794387, device='cuda:0'), (tensor(1.794387, device='cuda:0'), tensor(0., device='cuda:0'), tensor(1., device='cuda:0')))\n",
      "---\n",
      "(tensor(1.794387, device='cuda:0'), tensor(0., device='cuda:0'), tensor(1., device='cuda:0'))\n",
      "5\n",
      "- 2\n",
      "-- torch.Size([6, 4]) tensor([-0.127124,  0.055105,  0.100168], device='cuda:0')\n",
      "-- torch.Size([6]) tensor([ 0.164353,  0.163971, -0.580547], device='cuda:0')\n",
      "- 1\n",
      "-- torch.Size([2, 4]) tensor([-0.628850, -0.075747,  0.011350], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([4]) tensor([ 3.068704e-05,  1.720320e-04, -1.846318e-04], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([ 0.000125, -0.000561, -0.000137], device='cuda:0')\n",
      "-- torch.Size([2, 3, 2, 4]) tensor([-0.006074,  0.003219, -0.009708], device='cuda:0')\n",
      "-- torch.Size([4, 4]) tensor([-0.001385,  0.004992, -0.003819], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([ 1.371253e-04, -2.176035e-05, -4.429675e-04], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([-4.576159e-04,  1.020413e-05, -4.484524e-04], device='cuda:0')\n",
      "-- torch.Size([16, 4]) tensor([ 0.000522,  0.000821, -0.001104], device='cuda:0')\n",
      "-- torch.Size([16]) tensor([ 0.002158,  0.010123, -0.000862], device='cuda:0')\n",
      "-- torch.Size([4, 16]) tensor([-0.000435,  0.002875, -0.003700], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([-0.805315, -0.099838,  0.125308], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([4]) tensor([ 3.870354e-05, -4.718026e-06,  4.586788e-06], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([1.068276e-04, 6.082335e-05, 7.609130e-05], device='cuda:0')\n",
      "-- torch.Size([2, 3, 2, 4]) tensor([ 0.001500, -0.000545,  0.001477], device='cuda:0')\n",
      "-- torch.Size([4, 4]) tensor([-0.001401,  0.000285, -0.003588], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([-0.000235, -0.000427, -0.000706], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([ 0.000698,  0.000606, -0.000845], device='cuda:0')\n",
      "-- torch.Size([16, 4]) tensor([-0.000614, -0.001278,  0.001901], device='cuda:0')\n",
      "-- torch.Size([16]) tensor([ 0.005305, -0.009974,  0.001478], device='cuda:0')\n",
      "-- torch.Size([4, 16]) tensor([ 0.002198,  0.001977, -0.002967], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([-0.830891, -0.079503,  0.135784], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([4]) tensor([ 0.000110,  0.000572, -0.001352], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([-0.005916,  0.003276,  0.014037], device='cuda:0')\n",
      "---XXXX--\n",
      "layers_jacs_x[0].shape torch.Size([2, 2, 4, 2, 2, 4]) jac_dropout.shape torch.Size([2, 2, 4, 2, 2, 4])\n",
      "(tensor(1.794387, device='cuda:0'), tensor(0., device='cuda:0'), tensor(1., device='cuda:0'))\n",
      "5\n",
      "- 2\n",
      "-- torch.Size([6, 4]) tensor([-0.127169,  0.055102,  0.100259], device='cuda:0')\n",
      "-- torch.Size([6]) tensor([ 0.164353,  0.163971, -0.580547], device='cuda:0')\n",
      "- 1\n",
      "-- torch.Size([2, 4]) tensor([-0.628856, -0.075739,  0.011353], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([4]) tensor([ 3.065798e-05,  1.719916e-04, -1.845963e-04], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([ 0.000125, -0.000561, -0.000136], device='cuda:0')\n",
      "-- torch.Size([2, 3, 2, 4]) tensor([-0.006072,  0.003214, -0.009701], device='cuda:0')\n",
      "-- torch.Size([4, 4]) tensor([-0.001385,  0.004993, -0.003819], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([ 1.371248e-04, -2.176008e-05, -4.429660e-04], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([-4.576156e-04,  1.020363e-05, -4.484514e-04], device='cuda:0')\n",
      "-- torch.Size([16, 4]) tensor([ 0.000522,  0.000821, -0.001103], device='cuda:0')\n",
      "-- torch.Size([16]) tensor([ 0.002158,  0.010123, -0.000862], device='cuda:0')\n",
      "-- torch.Size([4, 16]) tensor([-0.000435,  0.002875, -0.003701], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([-0.805314, -0.099837,  0.125308], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([4]) tensor([ 3.870853e-05, -4.725602e-06,  4.549342e-06], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([1.068487e-04, 6.087232e-05, 7.605158e-05], device='cuda:0')\n",
      "-- torch.Size([2, 3, 2, 4]) tensor([ 0.001500, -0.000544,  0.001475], device='cuda:0')\n",
      "-- torch.Size([4, 4]) tensor([-0.001401,  0.000285, -0.003588], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([-0.000235, -0.000427, -0.000706], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([ 0.000698,  0.000606, -0.000845], device='cuda:0')\n",
      "-- torch.Size([16, 4]) tensor([-0.000614, -0.001278,  0.001901], device='cuda:0')\n",
      "-- torch.Size([16]) tensor([ 0.005305, -0.009974,  0.001478], device='cuda:0')\n",
      "-- torch.Size([4, 16]) tensor([ 0.002198,  0.001978, -0.002967], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([-0.830891, -0.079503,  0.135784], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([4]) tensor([ 0.000110,  0.000572, -0.001352], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([-0.005916,  0.003276,  0.014037], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# t_loss + train=False\n",
    "import torch\n",
    "torch.set_printoptions(precision=6)\n",
    "from torch.func import jacrev\n",
    "from model_torch_func import init_transformer_gpt2\n",
    "#from model_triton import *\n",
    "from loss_and_optimizer_triton import t_loss, t_loss_bkwd\n",
    "BS, H, N, D = 2, 2, 2, 4\n",
    "vocab_size = 6\n",
    "layers = 2\n",
    "p_gen_aux = [42] + [43,44,45] * layers\n",
    "layers_params = init_transformer_gpt2(vocab_size, D, layers, H, 4*D, N)\n",
    "y= torch.randint(vocab_size, (BS, N+1), device=\"cuda\")\n",
    "mask = torch.ones((BS, N, N), dtype=torch.bool, device=\"cuda\")\n",
    "res = t_loss(layers_params, y, mask, None, False)\n",
    "print(res)\n",
    "print(\"---\")\n",
    "\n",
    "def print_res_shapes(res):\n",
    "    print(len(res))\n",
    "    for it in res:\n",
    "        print(f'-', len(it))\n",
    "        for p in it:\n",
    "            print(f'--', p.shape, p.reshape(-1)[-3:]) # TODO: modify to check different parts\n",
    "\n",
    "from functools import partial\n",
    "fn = partial(t_loss, y_mask=mask, y_indices=None, train=False)\n",
    "res = jacrev(fn, has_aux=True)(layers_params, y)\n",
    "print(res[1])\n",
    "print_res_shapes(res[0])\n",
    "print(\"---XXXX--\")\n",
    "# for i, i_mask in enumerate(mask):\n",
    "#     mask[i] = torch.tril(i_mask)\n",
    "#     #mask[i] = torch.zeros_like(i_mask)\n",
    "# print(mask)\n",
    "# fn = partial(t_loss, y_mask=mask, y_indices=None, train=False)\n",
    "# res = jacrev(fn, has_aux=True)(layers_params, y)\n",
    "# #print_res_shapes(res[0])\n",
    "# print(\"---XXXX--\")\n",
    "\n",
    "res2 = t_loss_bkwd(layers_params, y, mask, None, train=False)\n",
    "print(res2[1])\n",
    "print_res_shapes(res2[0]) \n",
    "#print(res2[0])\n",
    "#print(res2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0926635a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(1.790465, device='cuda:0'), (tensor(1.790465, device='cuda:0'), tensor(0.222222, device='cuda:0'), tensor(0.900000, device='cuda:0')))\n",
      "---\n",
      "(tensor(1.790465, device='cuda:0'), tensor(0.222222, device='cuda:0'), tensor(0.900000, device='cuda:0'))\n",
      "5\n",
      "- 2\n",
      "-- torch.Size([6, 4]) tensor([-0.045141, -0.095859,  0.105749], device='cuda:0')\n",
      "-- torch.Size([6]) tensor([ 0.054522, -0.051900, -0.053196], device='cuda:0')\n",
      "- 1\n",
      "-- torch.Size([5, 4]) tensor([-0.287275, -0.061483,  0.133037], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([4]) tensor([ 2.621366e-05,  1.031182e-05, -8.969118e-05], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([-7.089571e-05,  1.040890e-05,  3.286575e-04], device='cuda:0')\n",
      "-- torch.Size([2, 3, 2, 4]) tensor([ 0.002025, -0.004901,  0.003491], device='cuda:0')\n",
      "-- torch.Size([4, 4]) tensor([ 0.002544, -0.001320, -0.002485], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([ 1.329654e-04, -2.255055e-04,  1.822136e-05], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([-6.698675e-04, -4.004006e-04,  6.491609e-05], device='cuda:0')\n",
      "-- torch.Size([16, 4]) tensor([-0.000952,  0.000901,  0.001892], device='cuda:0')\n",
      "-- torch.Size([16]) tensor([-0.000880, -0.000831,  0.004813], device='cuda:0')\n",
      "-- torch.Size([4, 16]) tensor([ 0.006085,  0.003742, -0.001966], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([-0.212419, -0.195482,  0.602741], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([4]) tensor([-3.697527e-05,  1.282218e-04, -9.789343e-05], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([8.535237e-05, 2.088104e-04, 3.603047e-04], device='cuda:0')\n",
      "-- torch.Size([2, 3, 2, 4]) tensor([ 0.001194, -0.002271,  0.001389], device='cuda:0')\n",
      "-- torch.Size([4, 4]) tensor([ 0.004022, -0.000468,  0.003913], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([-1.708629e-04, -1.164020e-04,  7.167473e-05], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([ 0.000388, -0.000280,  0.000169], device='cuda:0')\n",
      "-- torch.Size([16, 4]) tensor([ 0.000427, -0.001129, -0.000748], device='cuda:0')\n",
      "-- torch.Size([16]) tensor([-0.001295,  0.004399, -0.002245], device='cuda:0')\n",
      "-- torch.Size([4, 16]) tensor([-0.000445, -0.003594,  0.002810], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([-0.227935, -0.180489,  0.596650], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([4]) tensor([-0.001965, -0.001895,  0.000201], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([-0.005966, -0.001548,  0.003399], device='cuda:0')\n",
      "---XXXX--\n",
      "tensor([[[ True, False, False, False, False],\n",
      "         [ True,  True, False, False, False],\n",
      "         [ True,  True,  True, False, False],\n",
      "         [ True,  True,  True,  True, False],\n",
      "         [ True,  True,  True,  True,  True]],\n",
      "\n",
      "        [[ True, False, False, False, False],\n",
      "         [ True,  True, False, False, False],\n",
      "         [ True,  True,  True, False, False],\n",
      "         [ True,  True,  True,  True, False],\n",
      "         [ True,  True,  True,  True,  True]]], device='cuda:0')\n",
      "5\n",
      "- 2\n",
      "-- torch.Size([6, 4]) tensor([-0.043437, -0.091682,  0.098460], device='cuda:0')\n",
      "-- torch.Size([6]) tensor([ 0.054527, -0.051919, -0.053201], device='cuda:0')\n",
      "- 1\n",
      "-- torch.Size([5, 4]) tensor([-0.279689, -0.064336,  0.127854], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([4]) tensor([5.059837e-05, 3.095299e-05, 3.243785e-05], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([-7.941486e-05,  2.391755e-05,  3.962007e-04], device='cuda:0')\n",
      "-- torch.Size([2, 3, 2, 4]) tensor([ 0.009556, -0.009904,  0.002773], device='cuda:0')\n",
      "-- torch.Size([4, 4]) tensor([ 0.000318,  0.008268, -0.008789], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([ 1.356949e-04, -2.317391e-04,  2.948309e-05], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([-6.603127e-04, -4.029595e-04,  7.697562e-05], device='cuda:0')\n",
      "-- torch.Size([16, 4]) tensor([-0.001027,  0.000885,  0.001865], device='cuda:0')\n",
      "-- torch.Size([16]) tensor([-0.001043, -0.000788,  0.004742], device='cuda:0')\n",
      "-- torch.Size([4, 16]) tensor([ 0.006161,  0.003558, -0.001905], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([-0.223301, -0.218874,  0.596682], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([4]) tensor([-7.043941e-05,  2.282067e-04,  5.565344e-05], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([8.865294e-05, 2.654380e-04, 4.444804e-04], device='cuda:0')\n",
      "-- torch.Size([2, 3, 2, 4]) tensor([ 0.003345, -0.003571,  0.002118], device='cuda:0')\n",
      "-- torch.Size([4, 4]) tensor([0.010981, 0.007930, 0.015051], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([-1.557293e-04, -9.295341e-05,  6.294686e-05], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([ 0.000368, -0.000261,  0.000151], device='cuda:0')\n",
      "-- torch.Size([16, 4]) tensor([ 0.000367, -0.001056, -0.000709], device='cuda:0')\n",
      "-- torch.Size([16]) tensor([-0.001128,  0.004363, -0.002180], device='cuda:0')\n",
      "-- torch.Size([4, 16]) tensor([-0.000720, -0.003310,  0.003091], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([-0.229286, -0.206567,  0.584122], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([4]) tensor([-0.002043, -0.001806,  0.000644], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([-0.005963, -0.001548,  0.003399], device='cuda:0')\n",
      "---XXXX--\n",
      "layers_jacs_x[0].shape torch.Size([2, 5, 4, 2, 5, 4]) jac_dropout.shape torch.Size([2, 5, 4, 2, 5, 4])\n",
      "(tensor(1.790950, device='cuda:0'), tensor(0.222222, device='cuda:0'), tensor(0.900000, device='cuda:0'))\n",
      "5\n",
      "- 2\n",
      "-- torch.Size([6, 4]) tensor([-0.043424, -0.091677,  0.098473], device='cuda:0')\n",
      "-- torch.Size([6]) tensor([ 0.054527, -0.051919, -0.053201], device='cuda:0')\n",
      "- 1\n",
      "-- torch.Size([5, 4]) tensor([-0.279690, -0.064336,  0.127854], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([4]) tensor([5.058868e-05, 3.100754e-05, 3.245478e-05], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([-7.944202e-05,  2.394420e-05,  3.961900e-04], device='cuda:0')\n",
      "-- torch.Size([2, 3, 2, 4]) tensor([ 0.009555, -0.009908,  0.002774], device='cuda:0')\n",
      "-- torch.Size([4, 4]) tensor([ 0.000317,  0.008271, -0.008788], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([ 1.356957e-04, -2.317399e-04,  2.948336e-05], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([-6.603142e-04, -4.029602e-04,  7.697587e-05], device='cuda:0')\n",
      "-- torch.Size([16, 4]) tensor([-0.001028,  0.000885,  0.001865], device='cuda:0')\n",
      "-- torch.Size([16]) tensor([-0.001043, -0.000788,  0.004742], device='cuda:0')\n",
      "-- torch.Size([4, 16]) tensor([ 0.006162,  0.003556, -0.001905], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([-0.223302, -0.218874,  0.596683], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([4]) tensor([-7.045201e-05,  2.282072e-04,  5.564175e-05], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([8.865331e-05, 2.654082e-04, 4.444754e-04], device='cuda:0')\n",
      "-- torch.Size([2, 3, 2, 4]) tensor([ 0.003345, -0.003571,  0.002118], device='cuda:0')\n",
      "-- torch.Size([4, 4]) tensor([0.010984, 0.007930, 0.015051], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([-1.557294e-04, -9.295347e-05,  6.294683e-05], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([ 0.000368, -0.000261,  0.000151], device='cuda:0')\n",
      "-- torch.Size([16, 4]) tensor([ 0.000367, -0.001057, -0.000708], device='cuda:0')\n",
      "-- torch.Size([16]) tensor([-0.001128,  0.004363, -0.002180], device='cuda:0')\n",
      "-- torch.Size([4, 16]) tensor([-0.000720, -0.003309,  0.003090], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([-0.229286, -0.206567,  0.584122], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([4]) tensor([-0.002043, -0.001806,  0.000644], device='cuda:0')\n",
      "-- torch.Size([4]) tensor([-0.005963, -0.001548,  0.003399], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# t_loss + train=True\n",
    "import torch\n",
    "torch.set_printoptions(precision=6)\n",
    "from torch.func import jacrev\n",
    "from model_torch_func import init_transformer_gpt2\n",
    "#from model_triton import *\n",
    "from loss_and_optimizer_triton import t_loss, t_loss_bkwd\n",
    "BS, H, N, D = 2, 2, 5, 4\n",
    "vocab_size = 6\n",
    "layers = 2\n",
    "p_gen_aux = [42] + [43,44,45] * layers\n",
    "layers_params = init_transformer_gpt2(vocab_size, D, layers, H, 4*D, N)\n",
    "y= torch.randint(vocab_size, (BS, N+1), device=\"cuda\")\n",
    "mask = torch.ones((BS, N, N), dtype=torch.bool, device=\"cuda\")\n",
    "res = t_loss(layers_params, y, mask, None, True, p_gen_aux)\n",
    "print(res)\n",
    "print(\"---\")\n",
    "\n",
    "def print_res_shapes(res):\n",
    "    print(len(res))\n",
    "    for it in res:\n",
    "        print(f'-', len(it))\n",
    "        for p in it:\n",
    "            print(f'--', p.shape, p.reshape(-1)[-3:]) # TODO: modify to check different parts\n",
    "\n",
    "from functools import partial\n",
    "fn = partial(t_loss, y_mask=mask, y_indices=None, train=True, p_gen_aux=p_gen_aux)\n",
    "res = jacrev(fn, has_aux=True)(layers_params, y)\n",
    "print(res[1])\n",
    "print_res_shapes(res[0])\n",
    "print(\"---XXXX--\")\n",
    "for i, i_mask in enumerate(mask):\n",
    "    mask[i] = torch.tril(i_mask)\n",
    "    #mask[i] = torch.zeros_like(i_mask)\n",
    "print(mask)\n",
    "fn = partial(t_loss, y_mask=mask, y_indices=None, train=True, p_gen_aux=p_gen_aux)\n",
    "res = jacrev(fn, has_aux=True)(layers_params, y)\n",
    "print_res_shapes(res[0])\n",
    "print(\"---XXXX--\")\n",
    "\n",
    "res2 = t_loss_bkwd(layers_params, y, mask, None, True, p_gen_aux)\n",
    "print(res2[1])\n",
    "print_res_shapes(res2[0]) \n",
    "#print(res2[0])\n",
    "#print(res2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28793896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1.],\n",
       "        [0., 1., 1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Derisk jac_p idea.\n",
    "x = torch.zeros((2,3))\n",
    "generator = torch.Generator(device=x.device)\n",
    "generator.manual_seed(42)\n",
    "torch.bernoulli(torch.full_like(x, 0.9), generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a589a7cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qkv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Back to basics\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m q, k, v \u001b[38;5;241m=\u001b[39m \u001b[43mqkv\u001b[49m\u001b[38;5;241m.\u001b[39munbind(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      3\u001b[0m q \u001b[38;5;241m=\u001b[39m q\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,q\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m      4\u001b[0m k \u001b[38;5;241m=\u001b[39m k\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,k\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'qkv' is not defined"
     ]
    }
   ],
   "source": [
    "# Back to basics\n",
    "q, k, v = qkv.unbind(dim=2)\n",
    "q = q.reshape((-1,q.shape[-1]))\n",
    "k = k.reshape((-1,k.shape[-1]))\n",
    "v = v.reshape((-1, v.shape[-1]))\n",
    "print(q, k, v)\n",
    "\n",
    "def qk_fwd(q, k):\n",
    "    return torch.matmul(q, k.transpose(-2, -1))\n",
    "\n",
    "def qkv_fwd(q, k, v):\n",
    "    return torch.matmul(qk_fwd(q, k), v)\n",
    "\n",
    "print(qkv_fwd(q, k, v).shape)\n",
    "print(\"---\")\n",
    "#res = jacrev(qk_fwd)(q, k)\n",
    "res = jacrev(qkv_fwd)(q, k, v)\n",
    "print(res.shape)\n",
    "print(res)\n",
    "print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b325d26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 2, 3])\n",
      "tensor([[[[-0.033605, -2.002479, -1.487947],\n",
      "          [ 0.000000,  0.000000,  0.000000]],\n",
      "\n",
      "         [[-0.382970, -1.029678,  0.075037],\n",
      "          [ 0.000000,  0.000000,  0.000000]],\n",
      "\n",
      "         [[ 0.180972, -0.494185, -0.802026],\n",
      "          [ 0.000000,  0.000000,  0.000000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.000000,  0.000000,  0.000000],\n",
      "          [-0.033605, -2.002479, -1.487947]],\n",
      "\n",
      "         [[ 0.000000,  0.000000,  0.000000],\n",
      "          [-0.382970, -1.029678,  0.075037]],\n",
      "\n",
      "         [[ 0.000000,  0.000000,  0.000000],\n",
      "          [ 0.180972, -0.494185, -0.802026]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def qk_bkwd(q, k):\n",
    "    return k.transpose\n",
    "def qkv_bkwd(q, k, v):\n",
    "    d_qk_wd_dq = jacrev(qk_fwd)(q, k)\n",
    "\n",
    "    res = torch.matmul(v.transpose(1, 0), d_qk_wd_dq.transpose(1, 0).reshape(q.shape[0], -1))\n",
    "    res = res.reshape(res.shape[0], -1, q.numel())\n",
    "    res = res.transpose(1, 0)\n",
    "    res = res.reshape(q.shape + q.shape)\n",
    "    \n",
    "    return res\n",
    "\n",
    "#res2 = qk_bkwd(q, k)\n",
    "res2 = qkv_bkwd(q, k, v)\n",
    "print(res2.shape)\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "035518ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0.],\n",
       "        [0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.block_diag(torch.ones(2), torch.ones(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff969559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8190, -1.8277],\n",
      "        [-0.7926,  0.6985]])\n",
      "tensor([-2.6466, -0.0941])\n",
      "tensor([[[1., 1.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [1., 1.]]])\n",
      "torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "def test_fn(a):\n",
    "    return torch.sum(a, dim=1)\n",
    "\n",
    "aa = torch.randn((2,2))\n",
    "print(aa)\n",
    "print(test_fn(aa))\n",
    "res = jacrev(test_fn)(aa)\n",
    "print(res)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2666f3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.7855, 0.0000],\n",
      "          [0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.5382],\n",
      "          [0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000],\n",
      "          [0.7643, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000],\n",
      "          [0.0000, 0.7812]]]])\n",
      "tensor([[0.7855, 0.5382],\n",
      "        [0.7643, 0.7812]])\n"
     ]
    }
   ],
   "source": [
    "def t_test_fwd(x):\n",
    "    return 0.044715 * torch.pow(x,3)\n",
    "\n",
    "def t_test_bkwd(x):\n",
    "    return 0.044715 * 3 * torch.pow(x,2)\n",
    "\n",
    "def t_test_fwd(x):\n",
    "    k = math.sqrt(2/math.pi)\n",
    "    tanh_term = torch.tanh(k * (x + 0.044715 * torch.pow(x,3)))\n",
    "    return tanh_term\n",
    "\n",
    "def t_test_bkwd(x):\n",
    "    k = math.sqrt(2/math.pi)\n",
    "    tanh_term = torch.tanh(k * (x + 0.044715 * torch.pow(x,3)))\n",
    "    tanh_dx = (1 - torch.pow(tanh_term, 2)) * k * ( 1 + 3 * 0.044715 * torch.pow(x,2))\n",
    "    return tanh_dx\n",
    "\n",
    "\n",
    "# print(vjp(t_test_fwd, aa)[0])\n",
    "# print(t_test_bkwd(aa) * aa)\n",
    "\n",
    "# test_aa = torch.tensor(1.1)\n",
    "# print(grad(t_test_fwd)(test_aa))\n",
    "# print(t_test_bkwd(test_aa))\n",
    "\n",
    "print(jacrev(t_test_fwd)(aa))\n",
    "print(t_test_bkwd(aa))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fb4af9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
