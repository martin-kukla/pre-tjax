{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fece2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.9953, -1.1435,  0.5128],\n",
      "        [ 0.3337,  0.3123, -1.2417]])\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "from torch.func import grad, vjp, jacrev\n",
    "from model_triton import *\n",
    "\n",
    "aa = torch.randn((2,3)) #torch.randn((2, 2, 3))\n",
    "print(aa)\n",
    "print(\"----\")\n",
    "\n",
    "# RELU\n",
    "# print(t_relu_bkwd(aa) * aa)\n",
    "# print(vjp(t_relu_fwd, aa)[0])\n",
    "#print(jacrev(t_relu_fwd)(aa))\n",
    "\n",
    "# GELU\n",
    "# print(jacrev(t_gelu_fwd)(aa))\n",
    "# print(t_gelu_bkwd(aa))\n",
    "#print(t_gelu_bkwd(aa) * aa)\n",
    "\n",
    "# LOG_SOFTMAX\n",
    "# print(jacrev(t_log_softmax_fwd)(aa))\n",
    "# print(t_log_softmax_bkwd(aa))\n",
    "\n",
    "# Embed\n",
    "# from model_torch_func import init_proj_layer\n",
    "# params = (init_proj_layer(4, 2), )\n",
    "# aa =torch.tensor([1, 0, 1])\n",
    "# print(jacrev(t_embed_fwd)(params, aa))\n",
    "# print(t_embed_bkwd(params, aa))\n",
    "\n",
    "# Proj\n",
    "# aa = torch.randn((2,2))\n",
    "# #print(aa)\n",
    "# params = torch.randn((4,2))\n",
    "# #print(t_proj_fwd(params, aa))\n",
    "# res = jacrev(t_proj_fwd)(params, aa)\n",
    "# print(res.shape)\n",
    "# print(res)\n",
    "# res2 = t_proj_bkwd_p(params, aa)\n",
    "# print(res2.shape)\n",
    "# print(res2)\n",
    "# res = jacrev(t_proj_fwd, argnums=1)(params, aa)\n",
    "# print(res.shape, res)\n",
    "# res2 = t_proj_bkwd_x(params, aa)\n",
    "# print(res2.shape, res2)\n",
    "\n",
    "# Linear\n",
    "# aa = torch.randn((2,2))\n",
    "# print(aa)\n",
    "# params = (torch.randn((4,2)), torch.randn((4,)))\n",
    "# res = jacrev(t_linear_fwd)(params, aa)\n",
    "# print(res[0].shape, res[1].shape)\n",
    "# print(res)\n",
    "# res2 = t_linear_bkwd_p(params, aa)\n",
    "# print(res2[0].shape, res2[1].shape)\n",
    "# print(res2)\n",
    "\n",
    "# from model_triton import t_linear_bkwd_x\n",
    "# res = jacrev(t_linear_fwd, argnums=1)(params, aa)\n",
    "# print(res.shape, res)\n",
    "# res2 = t_linear_bkwd_x(params, aa)\n",
    "# print(res2.shape, res2)\n",
    "\n",
    "# LAYERNORM\n",
    "# x = torch.randn((2,3), device=\"cuda\")\n",
    "# print(x)\n",
    "# print(torch.mean(x, axis=-1, keepdims=True), torch.std(x, axis=-1, keepdims = True))\n",
    "# from model_torch_func import init_layernorm_layer\n",
    "# #params = init_layernorm_layer(3) # replace 1, 0s\n",
    "# params = torch.randn((3, ), device=\"cuda\"), torch.zeros((3,), device=\"cuda\")\n",
    "\n",
    "# from model_triton import t_layernorm_bkwd_p\n",
    "# res1 = jacrev(t_layernorm_fwd)(params, x)\n",
    "# res2 = t_layernorm_bkwd_p(params, x)\n",
    "# print(res1[0].shape, res1[0])\n",
    "# print(\"--\")\n",
    "# print(res2[0].shape, res2[0])\n",
    "\n",
    "# from model_triton import t_layernorm_bkwd_x\n",
    "# res1 = jacrev(t_layernorm_fwd, argnums=1)(params, x)\n",
    "# res2 = t_layernorm_bkwd_x(params, x)\n",
    "# print(res1.shape, res1)\n",
    "# print(\"--\")\n",
    "# print(res2.shape, res2)\n",
    "\n",
    "\n",
    "# TLAYER_FFN\n",
    "# aa = torch.randn((3,2), device=\"cuda\")\n",
    "# print(aa)\n",
    "# from model_torch_func import init_tlayer_ffn\n",
    "# from model_triton import t_tlayer_ffn_fwd, t_gelu_fwd, t_linear_bkwd_p, t_gelu_bkwd\n",
    "# from functools import partial\n",
    "# fn = partial(t_tlayer_ffn_fwd, activation_fn=t_gelu_fwd)\n",
    "# params = init_tlayer_ffn(2, 4)\n",
    "# print(fn(params, aa))\n",
    "# print(params[0].shape, params[1].shape)\n",
    "# print(\"--\")\n",
    "\n",
    "# res = jacrev(fn, argnums=0)(params, aa)\n",
    "# print(res[0].shape, res[1].shape, res[2].shape, res[3].shape)\n",
    "# print(res[0],res[1])\n",
    "# #print(res[2], res[3])\n",
    "\n",
    "# res2 = t_tlayer_ffn_bkwd_p(params, aa, t_gelu_fwd)\n",
    "# print(res2[0].shape, res2[1].shape, res2[2].shape, res2[3].shape)\n",
    "# print(res2[0], res2[1])\n",
    "# print(res2[2], res2[3])\n",
    "\n",
    "# res = jacrev(fn, argnums=1)(params, aa)\n",
    "# print(res.shape)\n",
    "# print(res)\n",
    "\n",
    "# res2 = t_tlayer_ffn_bkwd_x(params, aa, t_gelu_fwd)\n",
    "# print(res2.shape)\n",
    "# print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe8d05ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 torch.Size([2, 6, 4, 2, 4])\n",
      "tensor([[[[[0., 0., 0., 0.],\n",
      "           [2., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 2., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 2., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 2.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0., 0.],\n",
      "           [2., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 2., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 2., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 2.]]],\n",
      "\n",
      "\n",
      "         [[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0., 0.],\n",
      "           [2., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 2., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 2., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 2.]]],\n",
      "\n",
      "\n",
      "         [[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0., 0.],\n",
      "           [2., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 2., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 2., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 2.]]]]], device='cuda:0')\n",
      "1 torch.Size([2, 6, 4, 2, 4])\n",
      "tensor([[[[[0., 0., 0., 0.],\n",
      "           [2., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 2., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 2., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 2.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0., 0.],\n",
      "           [2., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 2., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 2., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 2.]]],\n",
      "\n",
      "\n",
      "         [[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0., 0.],\n",
      "           [2., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 2., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 2., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 2.]]],\n",
      "\n",
      "\n",
      "         [[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[2., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 2., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 2., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 2.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0., 0.],\n",
      "           [2., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 2., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 2., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 2.]]]]])\n"
     ]
    }
   ],
   "source": [
    "# Embed\n",
    "from model_torch_func import init_proj_layer\n",
    "params = (init_proj_layer(4, 2), )\n",
    "#aa =torch.tensor([1, 0, 1])\n",
    "aa = torch.randint(2, (2, 6))\n",
    "res=jacrev(t_embed_fwd)(params, aa)\n",
    "print(len(res), res[0].shape)\n",
    "print(res[0])\n",
    "\n",
    "res2=t_embed_bkwd(params, aa)\n",
    "print(len(res2), res2[0].shape)\n",
    "print(res2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f31f436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.9504,  0.5064],\n",
      "         [-1.1646, -0.3184],\n",
      "         [ 0.3456,  0.1814]]], device='cuda:0')\n",
      "tensor([[[    -0.0001,     -0.0001],\n",
      "         [     0.0002,      0.0002],\n",
      "         [    -0.0001,     -0.0001]]], device='cuda:0')\n",
      "torch.Size([4, 2]) torch.Size([4])\n",
      "--\n",
      "torch.Size([1, 3, 2, 1, 3, 2])\n",
      "tensor([[[[[[    -0.0001,     -0.0004],\n",
      "            [     0.0000,      0.0000],\n",
      "            [     0.0000,      0.0000]]],\n",
      "\n",
      "\n",
      "          [[[    -0.0001,     -0.0003],\n",
      "            [     0.0000,      0.0000],\n",
      "            [     0.0000,      0.0000]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[     0.0000,      0.0000],\n",
      "            [    -0.0001,     -0.0004],\n",
      "            [     0.0000,      0.0000]]],\n",
      "\n",
      "\n",
      "          [[[     0.0000,      0.0000],\n",
      "            [    -0.0001,     -0.0003],\n",
      "            [     0.0000,      0.0000]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[     0.0000,      0.0000],\n",
      "            [     0.0000,      0.0000],\n",
      "            [    -0.0001,     -0.0004]]],\n",
      "\n",
      "\n",
      "          [[[     0.0000,      0.0000],\n",
      "            [     0.0000,      0.0000],\n",
      "            [    -0.0001,     -0.0003]]]]]], device='cuda:0')\n",
      "--\n",
      "torch.Size([1, 3, 2, 1, 3, 2])\n",
      "tensor([[[[[[    -0.0001,     -0.0004],\n",
      "            [     0.0000,      0.0000],\n",
      "            [     0.0000,      0.0000]]],\n",
      "\n",
      "\n",
      "          [[[    -0.0001,     -0.0003],\n",
      "            [     0.0000,      0.0000],\n",
      "            [     0.0000,      0.0000]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[     0.0000,      0.0000],\n",
      "            [    -0.0001,     -0.0004],\n",
      "            [     0.0000,      0.0000]]],\n",
      "\n",
      "\n",
      "          [[[     0.0000,      0.0000],\n",
      "            [    -0.0001,     -0.0003],\n",
      "            [     0.0000,      0.0000]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[     0.0000,      0.0000],\n",
      "            [     0.0000,      0.0000],\n",
      "            [    -0.0001,     -0.0004]]],\n",
      "\n",
      "\n",
      "          [[[     0.0000,      0.0000],\n",
      "            [     0.0000,      0.0000],\n",
      "            [    -0.0001,     -0.0003]]]]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:767: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:135.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "# TLAYER_FFN\n",
    "aa = torch.randn((1, 3,2), device=\"cuda\")\n",
    "print(aa)\n",
    "from model_torch_func import init_tlayer_ffn\n",
    "from model_triton import t_tlayer_ffn_fwd, t_gelu_fwd, t_linear_bkwd_p, t_gelu_bkwd\n",
    "from functools import partial\n",
    "fn = partial(t_tlayer_ffn_fwd, activation_fn=t_gelu_fwd)\n",
    "params = init_tlayer_ffn(2, 4)\n",
    "print(fn(params, aa))\n",
    "print(params[0].shape, params[1].shape)\n",
    "print(\"--\")\n",
    "\n",
    "# res = jacrev(fn, argnums=0)(params, aa)\n",
    "# print(res[0].shape, res[1].shape, res[2].shape, res[3].shape)\n",
    "# print(res[0],res[1])\n",
    "# print(res[2], res[3])\n",
    "# print(\"--\")\n",
    "\n",
    "# res2 = t_tlayer_ffn_bkwd_p(params, aa, t_gelu_fwd)\n",
    "# print(res2[0].shape, res2[1].shape, res2[2].shape, res2[3].shape)\n",
    "# print(res2[0], res2[1])\n",
    "# print(res2[2], res2[3])\n",
    "\n",
    "res = jacrev(fn, argnums=1)(params, aa)\n",
    "print(res.shape)\n",
    "print(res)\n",
    "print(\"--\")\n",
    "\n",
    "# def t_tlayer_ffn_bkwd_x(layer_params, x, activation_fn):\n",
    "#     x_2d = x.reshape((-1, x.shape[-1]))\n",
    "    \n",
    "#     act_fn_bkwd = t_gelu_bkwd if activation_fn==t_gelu_fwd else t_relu_bkwd\n",
    "    \n",
    "#     dffn1_dx = t_linear_bkwd_x((layer_params[0], layer_params[1]), x_2d)\n",
    "#     x_2d = t_linear_fwd((layer_params[0], layer_params[1]), x_2d)\n",
    "#     dact_dx = act_fn_bkwd(x_2d)\n",
    "#     x_2d = activation_fn(x_2d)\n",
    "#     dffn2_dx = t_linear_bkwd_x((layer_params[2], layer_params[3]), x_2d)\n",
    "#     dffn2_act_dx = dact_dx * dffn2_dx #Note dact_dx is only 2D, but torch will add other dims\n",
    "#     jac = torch.einsum('abcd,cdef->abef', dffn2_act_dx, dffn1_dx)\n",
    "#     return jac.reshape(x.shape+x.shape)\n",
    "\n",
    "res2 = t_tlayer_ffn_bkwd_x(params, aa, t_gelu_fwd)\n",
    "print(res2.shape)\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7faa4c7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (454213176.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(torch.matmul(aa, params.reshape((-1, params.shape[-1])).transpose(-2, -1)).)\u001b[0m\n\u001b[0m                                                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from model_triton import *\n",
    "aa = torch.arange(8).reshape((2,2,2))\n",
    "params = torch.arange(12).reshape((2, 3, 2))\n",
    "\n",
    "print(torch.matmul(aa, params.reshape((-1, params.shape[-1])).transpose(-2, -1)).)\n",
    "print(torch.matmul(aa, params.transpose(-2, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ebac331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1],\n",
       "         [ 2,  3],\n",
       "         [ 4,  5]],\n",
       "\n",
       "        [[ 6,  7],\n",
       "         [ 8,  9],\n",
       "         [10, 11]],\n",
       "\n",
       "        [[12, 13],\n",
       "         [14, 15],\n",
       "         [16, 17]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.transpose(-2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bb924be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n",
      "torch.Size([2, 3, 2, 3, 2, 3, 3, 2])\n",
      "--\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 3, 2, 3, 2, 3, 3, 2]' is invalid for input of size 108",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#print(res)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m res2 \u001b[38;5;241m=\u001b[39m \u001b[43mt_proj_bkwd_p\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(res2\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#print(res2)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# res = jacrev(t_proj_fwd, argnums=1)(params, aa)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# print(res.shape, res)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# res2 = t_proj_bkwd_x(params, aa)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# print(res2.shape, res2)\u001b[39;00m\n",
      "File \u001b[0;32m/efs/notebooks/mkukla/pre-tjax/model_triton.py:103\u001b[0m, in \u001b[0;36mt_proj_bkwd_p\u001b[0;34m(layer_params, x)\u001b[0m\n\u001b[1;32m    100\u001b[0m aux \u001b[38;5;241m=\u001b[39m aux\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand(BS, outdim, outdim, N)\n\u001b[1;32m    102\u001b[0m outdims \u001b[38;5;241m=\u001b[39m indims[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m (outdim, )\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43maux\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutdims\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlayer_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 3, 2, 3, 2, 3, 3, 2]' is invalid for input of size 108"
     ]
    }
   ],
   "source": [
    "# Proj\n",
    "import torch\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "from torch.func import grad, vjp, jacrev\n",
    "from model_triton import *\n",
    "aa = torch.randn((1, 3, 2, 2))\n",
    "#print(aa)\n",
    "params = torch.randn((2, 3, 3, 2))\n",
    "output = t_proj_fwd(params, aa)\n",
    "#print(output.shape, output)\n",
    "print(\"--\")\n",
    "res = jacrev(t_proj_fwd)(params, aa)\n",
    "print(res.shape)\n",
    "#print(res)\n",
    "print(\"--\")\n",
    "res2 = t_proj_bkwd_p(params, aa)\n",
    "print(res2.shape)\n",
    "#print(res2)\n",
    "# res = jacrev(t_proj_fwd, argnums=1)(params, aa)\n",
    "# print(res.shape, res)\n",
    "# res2 = t_proj_bkwd_x(params, aa)\n",
    "# print(res2.shape, res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33489285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 2, 3, 1, 1, 2, 3])\n",
      "tensor([[[[[[[[0.179492, 0.046042, 0.011952],\n",
      "              [0.000000, 0.000000, 0.000000]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[0.632378, 0.162211, 0.042108],\n",
      "              [0.000000, 0.000000, 0.000000]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[0.905338, 0.232228, 0.060283],\n",
      "              [0.000000, 0.000000, 0.000000]]]]],\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          [[[[[0.000000, 0.000000, 0.000000],\n",
      "              [0.094128, 0.024145, 0.006268]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[0.000000, 0.000000, 0.000000],\n",
      "              [0.331628, 0.085066, 0.022082]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[0.000000, 0.000000, 0.000000],\n",
      "              [0.474773, 0.121784, 0.031613]]]]]]]], device='cuda:0')\n",
      "--\n",
      "torch.Size([1, 1, 2, 3, 1, 1, 2, 3])\n",
      "tensor([[[[[[[[0.179492, 0.046042, 0.011952],\n",
      "              [0.000000, 0.000000, 0.000000]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[0.000000, 0.000000, 0.000000],\n",
      "              [0.094128, 0.024145, 0.006268]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[0.632378, 0.162211, 0.042108],\n",
      "              [0.000000, 0.000000, 0.000000]]]]],\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          [[[[[0.000000, 0.000000, 0.000000],\n",
      "              [0.331628, 0.085066, 0.022082]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[0.905338, 0.232228, 0.060283],\n",
      "              [0.000000, 0.000000, 0.000000]]]],\n",
      "\n",
      "\n",
      "\n",
      "           [[[[0.000000, 0.000000, 0.000000],\n",
      "              [0.474773, 0.121784, 0.031613]]]]]]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:767: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:135.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "# t_scaled_dot_prod_attn\n",
    "import torch\n",
    "torch.set_printoptions(precision=6)\n",
    "from torch.func import jacrev\n",
    "from model_triton import *\n",
    "BS, H, N, D = 1, 1, 2, 3\n",
    "qkv= torch.randn((BS, H, 3, N, D), device=\"cuda\")\n",
    "mask = torch.ones((BS, N, N), dtype=torch.bool, device=\"cuda\")\n",
    "from functools import partial\n",
    "\n",
    "def attn_fwd(q, k, mask):\n",
    "    attn = torch.matmul(q, torch.transpose(k, -2, -1))\n",
    "    attn = attn / math.sqrt(D)\n",
    "    attn = torch.where(torch.unsqueeze(mask,dim=1), attn, torch.full_like(attn, -1e9)) # Note, instead of usign -jnp.inf, which results in NaNs (NIT: probably better to use jax.numpy.finfo)\n",
    "    return torch.exp(t_log_softmax_fwd(attn)) #TODO XXX: numerical stability\n",
    "\n",
    "# q, k, _ = torch.unbind(qkv, dim=2)\n",
    "# #fn = partial(attn_fwd, mask=mask) #this works\n",
    "# #fn = partial(softmax_attn, mask=mask, train=False)\n",
    "# res1 = jacrev(fn)(q, k)\n",
    "# res2 = jacrev(fn, argnums=1)(q, k)\n",
    "# print(res1.shape, res2.shape)\n",
    "# print(res1)\n",
    "# print(res2)\n",
    "# print(\"--\")\n",
    "\n",
    "fn = partial(t_scaled_dot_prod_attn_fwd, mask=mask, train=False)\n",
    "res = jacrev(fn)(qkv)\n",
    "# print(res.shape)\n",
    "dq,dk,dv = res.unbind(-3)\n",
    "print(dq.shape)\n",
    "print(dq)\n",
    "#print(dk)\n",
    "#print(dv)\n",
    "print(\"--\")\n",
    "\n",
    "### Repro for numerical isntability!\n",
    "def attn_bkwd(q, k, mask): # Do all ops in 3d instead of 4d\n",
    "    attn = torch.matmul(q, torch.transpose(k, -2, -1))\n",
    "    attn = attn / math.sqrt(D)\n",
    "    attn = torch.where(torch.unsqueeze(mask,dim=1), attn, torch.full_like(attn, -1e9)) # Note, instead of usign -jnp.inf, which results in NaNs (NIT: probably better to use jax.numpy.finfo)\n",
    "    dattn_dx = torch.exp(t_log_softmax_fwd(attn))[..., None, None, None, None] * t_log_softmax_bkwd(attn) \n",
    "    #dattn_dx = t_log_softmax_bkwd(attn) # TODO XXX: numerical stability\n",
    "    jac1 = torch.matmul(dattn_dx, k/math.sqrt(D))\n",
    "    jac2 = torch.matmul(q.transpose(-2,-1)/math.sqrt(D), dattn_dx).transpose(-2,-1)\n",
    "    return jac1, jac2\n",
    "\n",
    "# This works modulo numerical instability\n",
    "# res2 = attn_bkwd(q, k, mask)\n",
    "# print(res2[0].shape, res2[1].shape)\n",
    "# print(res2[0])\n",
    "# print(res2[1])\n",
    "\n",
    "# This works modulo numerical instability\n",
    "# res2 = t_softmax_attn_bkwd(q, k, mask, False)\n",
    "# print(res2[0].shape, res2[1].shape)\n",
    "# print(res2[0])\n",
    "# print(res2[1])\n",
    "\n",
    "res2 = t_scaled_dot_prod_attn_bkwd(qkv, mask, False)\n",
    "print(res2[0].shape) #, res2[1].shape, res2[2].shape)\n",
    "print(res2[0])\n",
    "#print(res2[1])\n",
    "#print(res2[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ab875d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 2, 2, 1, 2, 4])\n",
      "--\n",
      "torch.Size([1, 2, 2, 2, 1, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "# t_tlayer_attn_heads_fwd\n",
    "import torch\n",
    "torch.set_printoptions(precision=6)\n",
    "from torch.func import jacrev\n",
    "from model_torch_func import init_tlayer_attn_heads\n",
    "from model_triton import *\n",
    "BS, H, N, D = 1, 2, 2, 4\n",
    "layer_params = init_tlayer_attn_heads(D, H)\n",
    "qkv= torch.randn((BS, 3, N, D), device=\"cuda\").unbind(-3)\n",
    "mask = torch.ones((BS, N, N), dtype=torch.bool, device=\"cuda\")\n",
    "from functools import partial\n",
    "\n",
    "# fn = partial(t_tlayer_attn_heads_fwd, mask=mask, train=False)\n",
    "# res = jacrev(fn)(layer_params, qkv)\n",
    "# print(res.shape)\n",
    "# #print(res)\n",
    "# print(\"--\")\n",
    "# res2 = t_tlayer_attn_heads_bkwd_p(layer_params, qkv, mask, False)\n",
    "# print(res2.shape)\n",
    "\n",
    "fn = partial(t_tlayer_attn_heads_fwd, mask=mask, train=False)\n",
    "res = jacrev(fn, argnums=1)(layer_params, qkv)\n",
    "print(res[0].shape)\n",
    "#print(res)\n",
    "print(\"--\")\n",
    "res2 = t_tlayer_attn_heads_bkwd_x(layer_params, qkv, mask, False)\n",
    "print(res2[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8b2f743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_tlayer_attn_fwd\n",
    "import torch\n",
    "torch.set_printoptions(precision=6)\n",
    "from torch.func import jacrev\n",
    "from model_torch_func import init_tlayer_attn\n",
    "from model_triton import *\n",
    "BS, H, N, D = 1, 1, 2, 4\n",
    "layer_params = init_tlayer_attn(D, H)\n",
    "qkv= torch.randn((BS, 3, N, D), device=\"cuda\").unbind(-3)\n",
    "mask = torch.ones((BS, N, N), dtype=torch.bool, device=\"cuda\")\n",
    "from functools import partial\n",
    "# fn = partial(t_tlayer_attn_fwd, mask=mask, train=False)\n",
    "# # res = jacrev(fn)(layer_params, qkv)\n",
    "# # print(len(res), res[0].shape, res[1].shape)\n",
    "# # print(res[0][0][0][0])\n",
    "# # #print(res)\n",
    "# # print(\"--\")\n",
    "# # res2 = t_tlayer_attn_bkwd_p(layer_params, qkv, mask, False)\n",
    "# # print(len(res2), res2[0].shape, res2[1].shape)\n",
    "# # print(res2[0][0][0][0])\n",
    "\n",
    "# ####\n",
    "\n",
    "# res = jacrev(fn, argnums=1)(layer_params, qkv)\n",
    "# print(len(res), res[0].shape, res[1].shape)\n",
    "# print(res[0][0][0][0])\n",
    "\n",
    "# res2 = t_tlayer_attn_bkwd_x(layer_params, qkv, mask, False)\n",
    "# print(len(res2), res2[0].shape, res2[1].shape)\n",
    "# print(res2[0][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "405b65ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 4])\n",
      "---\n",
      "torch.Size([1, 2, 4, 1, 2, 4]) tensor([[[[[[ 9.998097e-01, -2.875166e-05,  1.540709e-04,  6.500125e-05],\n",
      "            [-4.817256e-04, -1.268953e-04,  5.714922e-04,  3.712886e-05]]],\n",
      "\n",
      "\n",
      "          [[[ 2.011918e-04,  1.000168e+00, -1.218463e-04, -2.473996e-04],\n",
      "            [ 6.724527e-04,  2.545502e-04, -3.880580e-04, -5.389448e-04]]],\n",
      "\n",
      "\n",
      "          [[[ 7.207511e-05,  1.075177e-05,  9.999416e-01, -2.443895e-05],\n",
      "            [ 1.804511e-04,  8.391979e-05, -2.151169e-05, -2.428592e-04]]],\n",
      "\n",
      "\n",
      "          [[[-9.842351e-05, -3.943307e-05,  7.235640e-05,  1.000065e+00],\n",
      "            [-2.822778e-04, -7.325434e-06,  6.896323e-04, -4.000292e-04]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[-1.903173e-04, -2.874095e-05,  1.540713e-04,  6.498698e-05],\n",
      "            [ 9.995183e-01, -1.269059e-04,  5.714889e-04,  3.716303e-05]]],\n",
      "\n",
      "\n",
      "          [[[ 2.011959e-04,  1.680674e-04, -1.218459e-04, -2.474174e-04],\n",
      "            [ 6.724274e-04,  1.000255e+00, -3.880622e-04, -5.389022e-04]]],\n",
      "\n",
      "\n",
      "          [[[ 7.207593e-05,  1.075439e-05, -5.838787e-05, -2.444239e-05],\n",
      "            [ 1.804460e-04,  8.391717e-05,  9.999785e-01, -2.428509e-04]]],\n",
      "\n",
      "\n",
      "          [[[-9.841856e-05, -3.941718e-05,  7.235692e-05,  6.547867e-05],\n",
      "            [-2.823081e-04, -7.341150e-06,  6.896273e-04,  9.996001e-01]]]]]],\n",
      "       device='cuda:0')\n",
      "---\n",
      "torch.Size([1, 1, 2, 4, 1, 2, 4]) tensor([[[[[[[ 9.998097e-01, -2.872384e-05,  1.540249e-04,  6.495602e-05],\n",
      "             [-4.815429e-04, -1.268483e-04,  5.712699e-04,  3.712127e-05]]],\n",
      "\n",
      "\n",
      "           [[[ 2.011755e-04,  1.000168e+00, -1.218282e-04, -2.474155e-04],\n",
      "             [ 6.724309e-04,  2.545559e-04, -3.879720e-04, -5.390147e-04]]],\n",
      "\n",
      "\n",
      "           [[[ 7.209573e-05,  1.078044e-05,  9.999416e-01, -2.447914e-05],\n",
      "             [ 1.805346e-04,  8.393657e-05, -2.163817e-05, -2.428329e-04]]],\n",
      "\n",
      "\n",
      "           [[[-9.843126e-05, -3.941824e-05,  7.236740e-05,  1.000065e+00],\n",
      "             [-2.822788e-04, -7.309660e-06,  6.897195e-04, -4.001310e-04]]]],\n",
      "\n",
      "\n",
      "\n",
      "          [[[[-1.902538e-04, -2.871318e-05,  1.540253e-04,  6.494171e-05],\n",
      "             [ 9.995185e-01, -1.268588e-04,  5.712665e-04,  3.715549e-05]]],\n",
      "\n",
      "\n",
      "           [[[ 2.011796e-04,  1.680815e-04, -1.218277e-04, -2.474333e-04],\n",
      "             [ 6.724056e-04,  1.000255e+00, -3.879762e-04, -5.389721e-04]]],\n",
      "\n",
      "\n",
      "           [[[ 7.209655e-05,  1.078304e-05, -5.839700e-05, -2.448264e-05],\n",
      "             [ 1.805295e-04,  8.393398e-05,  9.999784e-01, -2.428246e-04]]],\n",
      "\n",
      "\n",
      "           [[[-9.842638e-05, -3.940234e-05,  7.236794e-05,  6.546061e-05],\n",
      "             [-2.823091e-04, -7.325376e-06,  6.897144e-04,  9.995999e-01]]]]]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# t_gpt2_tlayer_fwd_sublock1_fwd\n",
    "import torch\n",
    "torch.set_printoptions(precision=6)\n",
    "from torch.func import jacrev\n",
    "from model_torch_func import init_tlayer_gpt2\n",
    "from model_triton import *\n",
    "BS, H, N, D = 1, 1, 2, 4\n",
    "layer_params = init_tlayer_gpt2(D, H, 4*D, 1)\n",
    "y= torch.randn((BS, N, D), device=\"cuda\")\n",
    "mask = torch.ones((BS, N, N), dtype=torch.bool, device=\"cuda\")\n",
    "res = t_gpt2_tlayer_sublock1_fwd(layer_params[:-6], y, mask, False)\n",
    "print(res.shape)\n",
    "print(\"---\")\n",
    "\n",
    "from functools import partial\n",
    "fn = partial(t_gpt2_tlayer_sublock1_fwd, mask=mask, train=False)\n",
    "# res = jacrev(fn)(layer_params[:-6], y)\n",
    "# print(len(res), res[0].shape, res[1].shape, res[2].shape, res[3].shape)\n",
    "# print(res[1])\n",
    "# #print(res[1])\n",
    "# print(\"---\")\n",
    "\n",
    "# res2 = t_gpt2_tlayer_sublock1_bkwd_p(layer_params[:-6], y, mask, train=False)\n",
    "# print(len(res2), res2[0].shape, res2[1].shape, res2[2].shape, res2[3].shape)\n",
    "# print(res2[1])\n",
    "\n",
    "res = jacrev(fn, argnums=1)(layer_params[:-6], y)\n",
    "print(res.shape, res)\n",
    "print(\"---\")\n",
    "\n",
    "# def t_gpt2_tlayer_sublock1_bkwd_x(layer_params, y, mask, train=True): # input: seq_len x emb_dim\n",
    "#     y_diff = t_layernorm_fwd(layer_params[:2], y)\n",
    "#     jac_layernorm_x = t_layernorm_bkwd_x(layer_params[:2], y)\n",
    "#     y = y + t_dropout(t_tlayer_attn_fwd(layer_params[2:], (y_diff, y_diff, y_diff), mask, train), train)\n",
    "#     # TODO XXX: add dropout!\n",
    "#     jac_tlayer_attn_x = t_tlayer_attn_bkwd_x(layer_params[2:], (y_diff, y_diff, y_diff), mask, train)\n",
    "    \n",
    "#     jac_y = torch.eye(y.numel(), device=y.device)    \n",
    "#     jac_tlayer_attn_x = torch.stack(jac_tlayer_attn_x)\n",
    "#     jac_y_diff = torch.einsum(\"xabcdef, defghi->abcghi\", jac_tlayer_attn_x, jac_layernorm_x)\n",
    "#     return jac_y.reshape(jac_y_diff.shape)[None, ] + jac_y_diff\n",
    "\n",
    "res2 = t_gpt2_tlayer_sublock1_bkwd_x(layer_params[:-6], y, mask, train=False)\n",
    "print(res2.shape, res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10800577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 4])\n",
      "---\n",
      "torch.Size([2, 2, 4, 2, 2, 4]) tensor([[[[[[ 1.000018e+00,  1.035568e-04, -6.908900e-06, -1.145899e-04],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "          [[[ 4.272713e-05,  1.000212e+00, -1.643325e-05, -2.384886e-04],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "          [[[-8.216233e-05,  5.904608e-04,  1.000031e+00, -5.393328e-04],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "          [[[ 6.103794e-04, -2.515970e-04, -2.328960e-04,  9.998741e-01],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 1.000118e+00,  1.146279e-04, -6.040256e-05, -1.720720e-04]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "          [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 2.566159e-04,  1.000223e+00, -1.368028e-04, -3.425726e-04]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "          [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [-3.802580e-04,  9.568295e-04,  1.000455e+00, -1.032078e-03]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "          [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 9.791560e-04, -2.639877e-04, -7.408063e-04,  1.000026e+00]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]]]],\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        [[[[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[ 9.999838e-01,  1.237949e-04, -1.256265e-04,  1.808158e-05],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "          [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[-5.510164e-05,  1.000280e+00, -2.312211e-04,  6.415677e-06],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "          [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[-2.359532e-04,  1.568700e-04,  1.000461e+00, -3.814029e-04],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "          [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[ 1.366578e-04, -5.819646e-05, -3.121780e-04,  1.000234e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 1.000078e+00,  5.280593e-05, -1.542320e-05, -1.151516e-04]]],\n",
      "\n",
      "\n",
      "          [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 1.384179e-04,  1.000226e+00,  2.110156e-05, -3.853066e-04]]],\n",
      "\n",
      "\n",
      "          [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [-1.888537e-04,  9.301221e-04,  1.000427e+00, -1.168601e-03]]],\n",
      "\n",
      "\n",
      "          [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 1.001746e-03, -3.052143e-04, -5.616745e-04,  9.998652e-01]]]]]],\n",
      "       device='cuda:0')\n",
      "---\n",
      "torch.Size([2, 2, 4, 2, 2, 4]) tensor([[[[[[ 1.000018e+00,  1.035568e-04, -6.908870e-06, -1.145900e-04],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "          [[[ 4.272713e-05,  1.000212e+00, -1.643326e-05, -2.384886e-04],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "          [[[-8.216233e-05,  5.904610e-04,  1.000031e+00, -5.393329e-04],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "          [[[ 6.103795e-04, -2.515970e-04, -2.328960e-04,  9.998741e-01],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 1.000118e+00,  1.146280e-04, -6.040267e-05, -1.720720e-04]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "          [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 2.566158e-04,  1.000223e+00, -1.368029e-04, -3.425725e-04]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "          [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [-3.802578e-04,  9.568294e-04,  1.000455e+00, -1.032078e-03]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "          [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 9.791561e-04, -2.639877e-04, -7.408065e-04,  1.000026e+00]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]]]],\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        [[[[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[ 9.999837e-01,  1.237949e-04, -1.256265e-04,  1.808159e-05],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "          [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[-5.510165e-05,  1.000280e+00, -2.312211e-04,  6.415669e-06],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "          [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[-2.359532e-04,  1.568700e-04,  1.000461e+00, -3.814028e-04],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "          [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[ 1.366578e-04, -5.819648e-05, -3.121780e-04,  1.000234e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 1.000078e+00,  5.280594e-05, -1.542314e-05, -1.151516e-04]]],\n",
      "\n",
      "\n",
      "          [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 1.384179e-04,  1.000226e+00,  2.110161e-05, -3.853067e-04]]],\n",
      "\n",
      "\n",
      "          [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [-1.888538e-04,  9.301222e-04,  1.000427e+00, -1.168601e-03]]],\n",
      "\n",
      "\n",
      "          [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 1.001746e-03, -3.052144e-04, -5.616745e-04,  9.998651e-01]]]]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# t_gpt2_tlayer_fwd_sublock2_fwd\n",
    "import torch\n",
    "torch.set_printoptions(precision=6)\n",
    "from torch.func import jacrev\n",
    "from model_torch_func import init_tlayer_gpt2\n",
    "from model_triton import *\n",
    "BS, H, N, D = 2, 1, 2, 4\n",
    "layer_params = init_tlayer_gpt2(D, H, 4*D, 1)\n",
    "y= torch.randn((BS, N, D), device=\"cuda\")\n",
    "mask = torch.ones((BS, N, N), dtype=torch.bool, device=\"cuda\")\n",
    "y = t_gpt2_tlayer_sublock1_fwd(layer_params[:-6], y, mask, False)\n",
    "res = t_gpt2_tlayer_sublock2_fwd(layer_params[-6:], y, False)\n",
    "print(res.shape)\n",
    "print(\"---\")\n",
    "\n",
    "from functools import partial\n",
    "fn = partial(t_gpt2_tlayer_sublock2_fwd, train=False)\n",
    "# res = jacrev(fn)(layer_params[-6:], y)\n",
    "# print(len(res), res[0].shape, res[1].shape, res[2].shape, res[3].shape)\n",
    "# print(res[1])\n",
    "# print(\"---\")\n",
    "\n",
    "res = jacrev(fn, argnums=1)(layer_params[-6:], y)\n",
    "print(res.shape, res)\n",
    "print(\"---\")\n",
    "\n",
    "res2 = t_gpt2_tlayer_sublock2_bkwd_x(layer_params[-6:], y, train=False)\n",
    "print(res2.shape, res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3fac65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 4])\n",
      "---\n",
      "torch.Size([2, 2, 4, 2, 2, 4])\n",
      "tensor([[[[[[ 9.999627e-01,  1.201024e-04,  3.038353e-06, -8.580500e-05],\n",
      "            [ 1.852606e-04,  1.017048e-04, -2.604173e-05, -2.609237e-04]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "          [[[ 1.891640e-04,  1.000441e+00, -2.049131e-05, -6.100892e-04],\n",
      "            [-2.495393e-05, -1.998381e-05,  1.972595e-04, -1.523217e-04]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "          [[[ 6.383702e-05,  1.907873e-04,  9.999929e-01, -2.475114e-04],\n",
      "            [-1.333327e-04, -8.866435e-05,  4.955884e-04, -2.735914e-04]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "          [[[ 4.036669e-05, -4.697078e-04, -1.650362e-06,  1.000431e+00],\n",
      "            [-4.578828e-04, -2.573401e-04,  2.484325e-04,  4.667904e-04]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[ 8.198236e-05,  8.281086e-05, -8.392461e-06, -1.564008e-04],\n",
      "            [ 9.994563e-01, -3.496928e-04,  1.676638e-03, -7.833139e-04]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "          [[[-2.173336e-05,  7.277331e-05,  1.766959e-06, -5.280690e-05],\n",
      "            [ 6.439973e-04,  1.000348e+00,  8.018104e-05, -1.071765e-03]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "          [[[-4.623392e-05,  1.008653e-04,  4.019617e-06, -5.865099e-05],\n",
      "            [ 7.431118e-04,  4.447007e-04,  9.987394e-01,  7.270960e-05]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "          [[[-2.010547e-04, -1.382915e-04,  2.026858e-05,  3.190776e-04],\n",
      "            [-9.143048e-04, -5.413218e-04,  1.355541e-03,  1.000100e+00]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]]]],\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        [[[[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[ 1.000064e+00,  1.066492e-04,  2.533870e-04, -4.241885e-04],\n",
      "            [ 1.280003e-04, -7.407740e-06, -4.895235e-05, -7.164020e-05]]],\n",
      "\n",
      "\n",
      "          [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[ 1.206660e-05,  1.000126e+00,  2.150644e-04, -3.535118e-04],\n",
      "            [-2.131216e-05, -5.222684e-05,  9.229597e-05, -1.875698e-05]]],\n",
      "\n",
      "\n",
      "          [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[-6.395065e-05,  7.154318e-06,  9.999261e-01,  1.306989e-04],\n",
      "            [-7.367061e-05, -1.440660e-04,  2.616423e-04, -4.390566e-05]]],\n",
      "\n",
      "\n",
      "          [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[ 1.950790e-04, -1.391836e-04,  4.076387e-05,  9.999033e-01],\n",
      "            [-3.111959e-04, -3.785147e-05,  2.069381e-04,  1.421093e-04]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[ 2.053034e-05,  1.226091e-05,  4.666840e-05, -7.945964e-05],\n",
      "            [ 9.998249e-01, -5.736472e-04,  9.854587e-04, -2.367102e-04]]],\n",
      "\n",
      "\n",
      "          [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[-1.568452e-05,  4.066346e-05,  4.314193e-05, -6.812087e-05],\n",
      "            [ 3.218902e-04,  9.999841e-01, -1.272952e-04, -1.787114e-04]]],\n",
      "\n",
      "\n",
      "          [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[-1.851295e-05,  6.913945e-05,  8.422090e-05, -1.348474e-04],\n",
      "            [ 2.767096e-04,  4.364293e-04,  9.991824e-01,  1.044341e-04]]],\n",
      "\n",
      "\n",
      "          [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[-5.455651e-05,  2.175977e-06, -6.927346e-05,  1.216540e-04],\n",
      "            [-2.647674e-04, -5.614561e-04,  1.008864e-03,  9.998173e-01]]]]]],\n",
      "       device='cuda:0')\n",
      "---\n",
      "torch.Size([2, 2, 4, 2, 2, 4])\n",
      "tensor([[[[[[ 9.999627e-01,  1.201024e-04,  3.038303e-06, -8.580498e-05],\n",
      "            [ 1.852606e-04,  1.017048e-04, -2.604169e-05, -2.609237e-04]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "          [[[ 1.891641e-04,  1.000441e+00, -2.049125e-05, -6.100892e-04],\n",
      "            [-2.495391e-05, -1.998380e-05,  1.972595e-04, -1.523218e-04]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "          [[[ 6.383697e-05,  1.907872e-04,  9.999928e-01, -2.475115e-04],\n",
      "            [-1.333327e-04, -8.866435e-05,  4.955884e-04, -2.735913e-04]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "          [[[ 4.036669e-05, -4.697077e-04, -1.650352e-06,  1.000431e+00],\n",
      "            [-4.578828e-04, -2.573401e-04,  2.484324e-04,  4.667905e-04]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[ 8.198235e-05,  8.281085e-05, -8.392465e-06, -1.564007e-04],\n",
      "            [ 9.994563e-01, -3.496928e-04,  1.676638e-03, -7.833139e-04]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "          [[[-2.173337e-05,  7.277331e-05,  1.766976e-06, -5.280691e-05],\n",
      "            [ 6.439972e-04,  1.000348e+00,  8.018102e-05, -1.071765e-03]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "          [[[-4.623395e-05,  1.008653e-04,  4.019677e-06, -5.865100e-05],\n",
      "            [ 7.431118e-04,  4.447007e-04,  9.987394e-01,  7.270949e-05]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]],\n",
      "\n",
      "\n",
      "          [[[-2.010547e-04, -1.382915e-04,  2.026862e-05,  3.190777e-04],\n",
      "            [-9.143048e-04, -5.413219e-04,  1.355541e-03,  1.000100e+00]],\n",
      "\n",
      "           [[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]]]]],\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        [[[[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[ 1.000064e+00,  1.066493e-04,  2.533870e-04, -4.241885e-04],\n",
      "            [ 1.280003e-04, -7.407732e-06, -4.895236e-05, -7.164017e-05]]],\n",
      "\n",
      "\n",
      "          [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[ 1.206655e-05,  1.000126e+00,  2.150644e-04, -3.535118e-04],\n",
      "            [-2.131216e-05, -5.222683e-05,  9.229596e-05, -1.875697e-05]]],\n",
      "\n",
      "\n",
      "          [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[-6.395071e-05,  7.154297e-06,  9.999261e-01,  1.306990e-04],\n",
      "            [-7.367063e-05, -1.440660e-04,  2.616423e-04, -4.390566e-05]]],\n",
      "\n",
      "\n",
      "          [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[ 1.950790e-04, -1.391836e-04,  4.076381e-05,  9.999033e-01],\n",
      "            [-3.111959e-04, -3.785147e-05,  2.069381e-04,  1.421093e-04]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[ 2.053034e-05,  1.226091e-05,  4.666840e-05, -7.945966e-05],\n",
      "            [ 9.998249e-01, -5.736471e-04,  9.854587e-04, -2.367101e-04]]],\n",
      "\n",
      "\n",
      "          [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[-1.568453e-05,  4.066347e-05,  4.314194e-05, -6.812087e-05],\n",
      "            [ 3.218901e-04,  9.999841e-01, -1.272953e-04, -1.787113e-04]]],\n",
      "\n",
      "\n",
      "          [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[-1.851294e-05,  6.913945e-05,  8.422093e-05, -1.348474e-04],\n",
      "            [ 2.767096e-04,  4.364293e-04,  9.991825e-01,  1.044341e-04]]],\n",
      "\n",
      "\n",
      "          [[[ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00],\n",
      "            [ 0.000000e+00,  0.000000e+00,  0.000000e+00,  0.000000e+00]],\n",
      "\n",
      "           [[-5.455654e-05,  2.175976e-06, -6.927345e-05,  1.216540e-04],\n",
      "            [-2.647674e-04, -5.614561e-04,  1.008864e-03,  9.998174e-01]]]]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# t_tlayer_fwd_gpt2\n",
    "import torch\n",
    "torch.set_printoptions(precision=6)\n",
    "from torch.func import jacrev\n",
    "from model_torch_func import init_tlayer_gpt2\n",
    "from model_triton import *\n",
    "BS, H, N, D = 2, 1, 2, 4\n",
    "layer_params = init_tlayer_gpt2(D, H, 4*D, 1)\n",
    "y= torch.randn((BS, N, D), device=\"cuda\")\n",
    "mask = torch.ones((BS, N, N), dtype=torch.bool, device=\"cuda\")\n",
    "res = t_gpt2_tlayer_fwd(layer_params, y, mask, False)\n",
    "print(res.shape)\n",
    "print(\"---\")\n",
    "\n",
    "from functools import partial\n",
    "fn = partial(t_gpt2_tlayer_fwd, mask=mask, train=False)\n",
    "# res = jacrev(fn)(layer_params, y)\n",
    "# print(len(res), res[0].shape, res[1].shape, res[2].shape, res[3].shape, res[4].shape, res[5].shape)\n",
    "# print(res[0])\n",
    "# print(res[1])\n",
    "# print(\"---\")\n",
    "\n",
    "# res2 = t_gpt2_tlayer_bkwd_p(layer_params, y, mask, train=False)\n",
    "# print(len(res2), res2[0].shape, res2[1].shape, res2[2].shape, res2[3].shape, res2[4].shape, res2[5].shape)\n",
    "# print(res2[0])\n",
    "# print(res2[1])\n",
    "\n",
    "res = jacrev(fn, argnums=1)(layer_params, y)\n",
    "print(res.shape)\n",
    "print(res)\n",
    "print(\"---\")\n",
    "\n",
    "res2 = t_gpt2_tlayer_bkwd_x(layer_params, y, mask, train=False)\n",
    "print(res2.shape)\n",
    "print(res2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cbde90bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 4])\n",
      "---\n",
      "1 torch.Size([2, 2, 4, 2, 4])\n",
      "tensor([[[[[1., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 1., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 1., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 1.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0., 0.],\n",
      "           [1., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 1., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 1., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 1.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[1., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 1., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 1., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 1.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0., 0.],\n",
      "           [1., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 1., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 1., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 1.]]]]], device='cuda:0')\n",
      "1 torch.Size([2, 2, 4, 2, 4])\n",
      "tensor([[[[[1., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 1., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 1., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 1.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0., 0.],\n",
      "           [1., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 1., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 1., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 1.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[1., 0., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 1., 0., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 1., 0.],\n",
      "           [0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 1.],\n",
      "           [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0., 0.],\n",
      "           [1., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 1., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 1., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0.],\n",
      "           [0., 0., 0., 1.]]]]])\n"
     ]
    }
   ],
   "source": [
    "# pos enc test\n",
    "import torch\n",
    "torch.set_printoptions(precision=6)\n",
    "from torch.func import jacrev\n",
    "from model_torch_func import init_tlayer_gpt2\n",
    "from model_triton import *\n",
    "BS, H, N, D = 2, 1, 2, 4\n",
    "vocab_size = 6\n",
    "layers = 2\n",
    "layers_params = init_transformer_gpt2(vocab_size, D, layers, H, 4*D, N)\n",
    "y= torch.randint(vocab_size, (BS, N), device=\"cuda\")\n",
    "mask = torch.ones((BS, N, N), dtype=torch.bool, device=\"cuda\")\n",
    "def test_fwd(params, y):\n",
    "    y = t_embed_fwd(params[0], y)\n",
    "    return y + params[1][0]\n",
    "    \n",
    "res = test_fwd(layers_params[:2], y)\n",
    "print(res.shape)\n",
    "\n",
    "print(\"---\")\n",
    "\n",
    "res = jacrev(test_fwd)(layers_params[:2], y)\n",
    "print(len(res[1]), res[1][0].shape)\n",
    "print(res[1][0])\n",
    "#print_res_shapes(res)\n",
    "\n",
    "def test_bkwd_p(params, y):\n",
    "    indices = torch.arange(y.shape[1]).unsqueeze(0).expand(*y.shape)\n",
    "    y = t_embed_fwd(params[0], y)\n",
    "    \n",
    "    \n",
    "    #print(f'params[1][0].shape', params[1][0].shape)\n",
    "    #print(f'indices.shape', indices.shape)\n",
    "    jac = t_embed_bkwd(params[1], indices) \n",
    "    jac = (jac[0] / params[1][0].shape[1] * 2, )\n",
    "    \n",
    "    return [None, jac]\n",
    "res2 = test_bkwd_p(layers_params[:2], y)\n",
    "print(len(res2[1]), res2[1][0].shape)\n",
    "print(res2[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf56ae54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [0, 1]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.randn((2, N))\n",
    "torch.arange(y.shape[1]).unsqueeze(0).expand(*y.shape)\n",
    "#.expand(y.shape[0], 1)\n",
    "#res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d148f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 4])\n",
      "---\n",
      "5\n",
      "- 2\n",
      "-- torch.Size([1, 2, 4, 6, 4]) tensor([0., 0., 0.], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 6]) tensor([0., 0., 0.], device='cuda:0')\n",
      "- 1\n",
      "-- torch.Size([1, 2, 4, 2, 4]) tensor([ 1.819440, -6.423049,  7.003040], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([-0.000181,  0.002994,  0.001876], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([0.000616, 0.010489, 0.002303], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 1, 3, 4, 4]) tensor([-0.028404,  0.028136,  0.080293], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4, 4]) tensor([ 0.001987, -0.044547,  0.098599], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([ 0.000751, -0.001716, -0.002677], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([-0.000567, -0.002559, -0.003033], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 16, 4]) tensor([ 0.147827, -0.076241, -0.100222], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 16]) tensor([ 0.000806,  0.038270, -0.113544], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4, 16]) tensor([-0.178024,  0.204412,  0.087067], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([ 1.849642, -6.458894,  7.049758], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([-0.000202,  0.000180,  0.000585], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([0.000725, 0.000612, 0.000727], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 1, 3, 4, 4]) tensor([-0.007992,  0.008410,  0.023074], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4, 4]) tensor([ 0.066596, -0.170094,  0.043868], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([ 0.003127,  0.000366, -0.000582], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([-0.002401,  0.000533, -0.000665], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 16, 4]) tensor([ 0.169998, -0.089587, -0.114118], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 16]) tensor([-0.014966,  0.020991, -0.130503], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4, 16]) tensor([-0.160189,  0.025947, -0.145940], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([ 1.883415, -6.436313,  7.072845], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([0.000000, 0.000000, 0.877050], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([0., 0., 1.], device='cuda:0')\n",
      "---XXXX--\n",
      "5\n",
      "- 2\n",
      "-- torch.Size([1, 2, 4, 6, 4]) tensor([0., 0., 0.], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 6]) tensor([0., 0., 0.], device='cuda:0')\n",
      "- 1\n",
      "-- torch.Size([1, 2, 4, 2, 4]) tensor([ 1.819439, -6.423046,  7.003036], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([-0.000180,  0.002994,  0.001876], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([0.000616, 0.010490, 0.002303], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 1, 3, 4, 4]) tensor([-0.028397,  0.028130,  0.080275], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4, 4]) tensor([ 0.001987, -0.044543,  0.098581], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([ 0.000751, -0.001716, -0.002677], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([-0.000567, -0.002559, -0.003033], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 16, 4]) tensor([ 0.147850, -0.076230, -0.100200], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 16]) tensor([ 0.000806,  0.038270, -0.113544], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4, 16]) tensor([-0.177992,  0.204399,  0.087035], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([ 1.849643, -6.458895,  7.049762], device='cuda:0')\n",
      "- 10\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([-0.000202,  0.000180,  0.000585], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([0.000725, 0.000611, 0.000727], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 1, 3, 4, 4]) tensor([-0.007992,  0.008410,  0.023073], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4, 4]) tensor([ 0.066601, -0.170113,  0.043880], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([ 0.003127,  0.000366, -0.000582], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([-0.002401,  0.000533, -0.000665], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 16, 4]) tensor([ 0.169965, -0.089614, -0.114155], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 16]) tensor([-0.014966,  0.020991, -0.130503], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4, 16]) tensor([-0.160196,  0.025940, -0.145926], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([ 1.883415, -6.436314,  7.072845], device='cuda:0')\n",
      "- 2\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([0.000000, 0.000000, 0.877050], device='cuda:0')\n",
      "-- torch.Size([1, 2, 4, 4]) tensor([0., 0., 1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# t_gpt2_tlayers_fwd\n",
    "import torch\n",
    "torch.set_printoptions(precision=6)\n",
    "from torch.func import jacrev\n",
    "from model_torch_func import init_tlayer_gpt2\n",
    "from model_triton import *\n",
    "BS, H, N, D = 1, 1, 2, 4\n",
    "vocab_size = 6\n",
    "layers = 2\n",
    "layers_params = init_transformer_gpt2(vocab_size, D, layers, H, 4*D, N)\n",
    "y= torch.randint(vocab_size, (BS, N), device=\"cuda\")\n",
    "mask = torch.ones((BS, N, N), dtype=torch.bool, device=\"cuda\")\n",
    "res = t_gpt2_tlayers_fwd(layers_params, y, mask, None, False)\n",
    "print(res.shape)\n",
    "\n",
    "print(\"---\")\n",
    "\n",
    "def print_res_shapes(res):\n",
    "    print(len(res))\n",
    "    for it in res:\n",
    "        print(f'-', len(it))\n",
    "        for p in it:\n",
    "            print(f'--', p.shape, p.reshape(-1)[-3:]) # TODO: modify to check different parts\n",
    "\n",
    "from functools import partial\n",
    "fn = partial(t_gpt2_tlayers_fwd, mask=mask, indices=None, train=False)\n",
    "res = jacrev(fn)(layers_params, y)\n",
    "print_res_shapes(res)\n",
    "print(\"---XXXX--\")\n",
    "\n",
    "# def t_gpt2_tlayers_bkwd_p(params, y, mask, indices, train=True): # input: seq_len x\n",
    "#     indices = torch.arange(y.shape[1], device=y.device).unsqueeze(0).expand(*y.shape) # we ignore indices arg\n",
    "#     jac_embed = t_embed_bkwd(params[0], y)\n",
    "#     # Due to tying of embedding and final projection layers,\n",
    "#     # we need to fill zeroed gradient with respect to biases:\n",
    "#     jac_embed = [jac_embed[0], torch.zeros(jac_embed[0].shape[:-1], device=y.device)]\n",
    "#     y = t_embed_fwd(params[0], y)\n",
    "#     # Reuse t_embed_bkwd to compute jacobian of pos_encoding\n",
    "#     # Need to account for lack of  1/ sqrt(emb_dim)\n",
    "#     jac_pos_enc = t_embed_bkwd(params[1], indices) \n",
    "#     jac_pos_enc = [jac_pos_enc[0] / params[1][0].shape[1] * 2, ]\n",
    "#     # TODO XXX: add dropout\n",
    "#     y = t_dropout(y + params[1][0], train)\n",
    "    \n",
    "#     layers_jacs_p = []\n",
    "#     layers_jacs_x = []\n",
    "    \n",
    "#     for layer_params in params[2:-1]:\n",
    "#         layers_jacs_p.append(t_gpt2_tlayer_bkwd_p(layer_params, y, mask, train))\n",
    "#         layers_jacs_x.append(t_gpt2_tlayer_bkwd_x(layer_params, y, mask, train))\n",
    "#         y = t_gpt2_tlayer_fwd(layer_params, y, mask, train)\n",
    "#     jac_layernorm_p = t_layernorm_bkwd_p(params[-1], y)\n",
    "#     jac_layernorm_x = t_layernorm_bkwd_x(params[-1], y)    \n",
    "#     y = t_layernorm_fwd(params[-1], y)\n",
    "    \n",
    "#     # Propoagate back\n",
    "#     def mult_j_in_2d(j_left_2d, j): # we need to do it u\n",
    "#         j = j.flatten(end_dim=len(y.shape)-1) #TODO XXX: is there a nice way of coding it?\n",
    "#         j_indim = j.shape[1:]\n",
    "#         j = j.reshape((y.numel(), -1))\n",
    "#         res = torch.matmul(j_left_2d, j)\n",
    "#         return res.reshape(y.shape + j_indim)\n",
    "#     layers_jacs_x[-1]=torch.einsum('abcdef, defghi -> abcghi', jac_layernorm_x, layers_jacs_x[-1])\n",
    "#     jac_layernorm_x_2d = jac_layernorm_x.reshape((y.numel(), y.numel()))\n",
    "#     layers_jacs_p[-1] = [mult_j_in_2d(jac_layernorm_x_2d, j) for j in layers_jacs_p[-1]] \n",
    "#     for i in reversed(range(1, len(layers_jacs_p))):\n",
    "#         layers_jacs_x[i-1]=torch.einsum('abcdef, defghi -> abcghi',layers_jacs_x[i], layers_jacs_x[i-1])\n",
    "#         jac_layer_2d = layers_jacs_x[i].reshape((y.numel(), y.numel()))\n",
    "#         layers_jacs_p[i-1] = [mult_j_in_2d(jac_layer_2d, j) for j in layers_jacs_p[i-1]] \n",
    "#     jac_pos_enc[0] =torch.einsum('abcdef, defgh -> abcgh', layers_jacs_x[0], jac_pos_enc[0])\n",
    "#     jac_embed[0] = torch.einsum('abcdef, defgh -> abcgh', layers_jacs_x[0], jac_embed[0])\n",
    "\n",
    "#     return tuple([jac_embed, jac_pos_enc] + layers_jacs_p + [jac_layernorm_p])\n",
    "\n",
    "res2 = t_gpt2_tlayers_bkwd_p(layers_params, y, mask, None, train=False)\n",
    "print_res_shapes(res2) \n",
    "#print(res2[0])\n",
    "#print(res2[1])\n",
    "\n",
    "# res = jacrev(fn, argnums=1)(layers_params, y)\n",
    "# print(res.shape)\n",
    "# print(res)\n",
    "# print(\"---\")\n",
    "\n",
    "# res2 = t_tlayer_fwd_gpt2_bkwd_x(layers_params, y, mask, train=False)\n",
    "# print(res2.shape)\n",
    "# print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c41d0097",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected size for first two dimensions of batch2 tensor to be: [2, 2] but got: [2, 5].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected size for first two dimensions of batch2 tensor to be: [2, 2] but got: [2, 5]."
     ]
    }
   ],
   "source": [
    "torch.matmul(torch.randn((4,2)), torch.randn(2,5, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ebc350",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_tlayer_attn_fwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fe688011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.144207, -0.994919,  0.033497],\n",
      "        [-0.169633, -0.113686, -0.300468]], device='cuda:0') tensor([[ 0.432276,  1.592006,  0.251207],\n",
      "        [ 0.249900, -1.219356, -1.527182]], device='cuda:0') tensor([[-0.585331, -0.783070,  0.105058],\n",
      "        [ 0.878028, -0.177942,  0.542449]], device='cuda:0')\n",
      "torch.Size([2, 3])\n",
      "---\n",
      "torch.Size([2, 3, 2, 3])\n",
      "tensor([[[[-0.033605, -2.002479, -1.487947],\n",
      "          [ 0.000000,  0.000000,  0.000000]],\n",
      "\n",
      "         [[-0.382970, -1.029678,  0.075037],\n",
      "          [ 0.000000,  0.000000,  0.000000]],\n",
      "\n",
      "         [[ 0.180972, -0.494185, -0.802026],\n",
      "          [ 0.000000,  0.000000,  0.000000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.000000,  0.000000,  0.000000],\n",
      "          [-0.033605, -2.002479, -1.487947]],\n",
      "\n",
      "         [[ 0.000000,  0.000000,  0.000000],\n",
      "          [-0.382970, -1.029678,  0.075037]],\n",
      "\n",
      "         [[ 0.000000,  0.000000,  0.000000],\n",
      "          [ 0.180972, -0.494185, -0.802026]]]], device='cuda:0')\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Back to basics\n",
    "q, k, v = qkv.unbind(dim=2)\n",
    "q = q.reshape((-1,q.shape[-1]))\n",
    "k = k.reshape((-1,k.shape[-1]))\n",
    "v = v.reshape((-1, v.shape[-1]))\n",
    "print(q, k, v)\n",
    "\n",
    "def qk_fwd(q, k):\n",
    "    return torch.matmul(q, k.transpose(-2, -1))\n",
    "\n",
    "def qkv_fwd(q, k, v):\n",
    "    return torch.matmul(qk_fwd(q, k), v)\n",
    "\n",
    "print(qkv_fwd(q, k, v).shape)\n",
    "print(\"---\")\n",
    "#res = jacrev(qk_fwd)(q, k)\n",
    "res = jacrev(qkv_fwd)(q, k, v)\n",
    "print(res.shape)\n",
    "print(res)\n",
    "print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "12ec02f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 2, 3])\n",
      "tensor([[[[-0.033605, -2.002479, -1.487947],\n",
      "          [ 0.000000,  0.000000,  0.000000]],\n",
      "\n",
      "         [[-0.382970, -1.029678,  0.075037],\n",
      "          [ 0.000000,  0.000000,  0.000000]],\n",
      "\n",
      "         [[ 0.180972, -0.494185, -0.802026],\n",
      "          [ 0.000000,  0.000000,  0.000000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.000000,  0.000000,  0.000000],\n",
      "          [-0.033605, -2.002479, -1.487947]],\n",
      "\n",
      "         [[ 0.000000,  0.000000,  0.000000],\n",
      "          [-0.382970, -1.029678,  0.075037]],\n",
      "\n",
      "         [[ 0.000000,  0.000000,  0.000000],\n",
      "          [ 0.180972, -0.494185, -0.802026]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def qk_bkwd(q, k):\n",
    "    return k.transpose\n",
    "def qkv_bkwd(q, k, v):\n",
    "    d_qk_wd_dq = jacrev(qk_fwd)(q, k)\n",
    "\n",
    "    res = torch.matmul(v.transpose(1, 0), d_qk_wd_dq.transpose(1, 0).reshape(q.shape[0], -1))\n",
    "    res = res.reshape(res.shape[0], -1, q.numel())\n",
    "    res = res.transpose(1, 0)\n",
    "    res = res.reshape(q.shape + q.shape)\n",
    "    \n",
    "    return res\n",
    "\n",
    "#res2 = qk_bkwd(q, k)\n",
    "res2 = qkv_bkwd(q, k, v)\n",
    "print(res2.shape)\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a5231c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0.],\n",
       "        [0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.block_diag(torch.ones(2), torch.ones(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53501ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8190, -1.8277],\n",
      "        [-0.7926,  0.6985]])\n",
      "tensor([-2.6466, -0.0941])\n",
      "tensor([[[1., 1.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [1., 1.]]])\n",
      "torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "def test_fn(a):\n",
    "    return torch.sum(a, dim=1)\n",
    "\n",
    "aa = torch.randn((2,2))\n",
    "print(aa)\n",
    "print(test_fn(aa))\n",
    "res = jacrev(test_fn)(aa)\n",
    "print(res)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a0d5d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.7855, 0.0000],\n",
      "          [0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.5382],\n",
      "          [0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000],\n",
      "          [0.7643, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000],\n",
      "          [0.0000, 0.7812]]]])\n",
      "tensor([[0.7855, 0.5382],\n",
      "        [0.7643, 0.7812]])\n"
     ]
    }
   ],
   "source": [
    "def t_test_fwd(x):\n",
    "    return 0.044715 * torch.pow(x,3)\n",
    "\n",
    "def t_test_bkwd(x):\n",
    "    return 0.044715 * 3 * torch.pow(x,2)\n",
    "\n",
    "def t_test_fwd(x):\n",
    "    k = math.sqrt(2/math.pi)\n",
    "    tanh_term = torch.tanh(k * (x + 0.044715 * torch.pow(x,3)))\n",
    "    return tanh_term\n",
    "\n",
    "def t_test_bkwd(x):\n",
    "    k = math.sqrt(2/math.pi)\n",
    "    tanh_term = torch.tanh(k * (x + 0.044715 * torch.pow(x,3)))\n",
    "    tanh_dx = (1 - torch.pow(tanh_term, 2)) * k * ( 1 + 3 * 0.044715 * torch.pow(x,2))\n",
    "    return tanh_dx\n",
    "\n",
    "\n",
    "# print(vjp(t_test_fwd, aa)[0])\n",
    "# print(t_test_bkwd(aa) * aa)\n",
    "\n",
    "# test_aa = torch.tensor(1.1)\n",
    "# print(grad(t_test_fwd)(test_aa))\n",
    "# print(t_test_bkwd(test_aa))\n",
    "\n",
    "print(jacrev(t_test_fwd)(aa))\n",
    "print(t_test_bkwd(aa))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3832d90b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
