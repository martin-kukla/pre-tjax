{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4a64b9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x504 and 512x512)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m y_indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39munsqueeze(y_indices, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     17\u001b[0m train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m logits_torch_logits \u001b[38;5;241m=\u001b[39m \u001b[43mbatched_forward_gpt2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m logits_triton \u001b[38;5;241m=\u001b[39m t_batched_forward_gpt2(params, y_in, y_mask, y_indices, train) \n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_functorch/apis.py:188\u001b[0m, in \u001b[0;36mvmap.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_functorch/vmap.py:281\u001b[0m, in \u001b[0;36mvmap_impl\u001b[0;34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(func, flat_in_dims, chunks_flat_args,\n\u001b[1;32m    278\u001b[0m                          args_spec, out_dims, randomness, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    280\u001b[0m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_functorch/vmap.py:47\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_functorch/vmap.py:403\u001b[0m, in \u001b[0;36m_flat_vmap\u001b[0;34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m vmap_increment_nesting(batch_size, randomness) \u001b[38;5;28;01mas\u001b[39;00m vmap_level:\n\u001b[1;32m    402\u001b[0m     batched_inputs \u001b[38;5;241m=\u001b[39m _create_batched_inputs(flat_in_dims, flat_args, vmap_level, args_spec)\n\u001b[0;32m--> 403\u001b[0m     batched_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n",
      "File \u001b[0;32m/efs/notebooks/mkukla/pre-tjax/model_triton.py:128\u001b[0m, in \u001b[0;36mforward_gpt2\u001b[0;34m(params, y, y_mask, y_indices, train)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_gpt2\u001b[39m(params, y, y_mask, y_indices, train): \u001b[38;5;66;03m# input: seq_len x\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mtlayers_fwd_gpt2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m     y \u001b[38;5;241m=\u001b[39m linear_fwd(params[\u001b[38;5;241m0\u001b[39m], y) \n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m/efs/notebooks/mkukla/pre-tjax/model_triton.py:122\u001b[0m, in \u001b[0;36mtlayers_fwd_gpt2\u001b[0;34m(params, y, mask, indices, train)\u001b[0m\n\u001b[1;32m    119\u001b[0m y \u001b[38;5;241m=\u001b[39m dropout(y \u001b[38;5;241m+\u001b[39m params[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m], train)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_params \u001b[38;5;129;01min\u001b[39;00m params[\u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m--> 122\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mtlayer_fwd_gpt2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m y \u001b[38;5;241m=\u001b[39m layernorm_fwd(params[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], y)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m/efs/notebooks/mkukla/pre-tjax/model_triton.py:111\u001b[0m, in \u001b[0;36mtlayer_fwd_gpt2\u001b[0;34m(layer_params, y, mask, train)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtlayer_fwd_gpt2\u001b[39m(layer_params, y, mask, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m): \u001b[38;5;66;03m# input: seq_len x emb_dim\u001b[39;00m\n\u001b[1;32m    110\u001b[0m     y_diff \u001b[38;5;241m=\u001b[39m layernorm_fwd(layer_params[:\u001b[38;5;241m2\u001b[39m], y)\n\u001b[0;32m--> 111\u001b[0m     y \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m+\u001b[39m dropout(\u001b[43mtlayer_attn_fwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43my_diff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_diff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_diff\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m, train)\n\u001b[1;32m    113\u001b[0m     y_diff \u001b[38;5;241m=\u001b[39m layernorm_fwd(layer_params[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m6\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m], y)\n\u001b[1;32m    114\u001b[0m     y \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m+\u001b[39m dropout(tlayer_ffn_fwd(layer_params[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m:], y_diff, gelu), train)\n",
      "File \u001b[0;32m/efs/notebooks/mkukla/pre-tjax/model_triton.py:88\u001b[0m, in \u001b[0;36mtlayer_attn_fwd\u001b[0;34m(layer_params, qkv, mask, train)\u001b[0m\n\u001b[1;32m     86\u001b[0m heads_attns \u001b[38;5;241m=\u001b[39m tlayer_attn_heads_fwd(layer_params[\u001b[38;5;241m0\u001b[39m], qkv, mask, train)\n\u001b[1;32m     87\u001b[0m attn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcatenate(torch\u001b[38;5;241m.\u001b[39munbind(heads_attns, \u001b[38;5;241m0\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# TODO XXX: there is probably better way to go from [K, M, N] -> [M, K*N]. Or modify VMAP to return diff shape\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mproj_fwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/efs/notebooks/mkukla/pre-tjax/model_triton.py:66\u001b[0m, in \u001b[0;36mproj_fwd\u001b[0;34m(layer_params, x)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mproj_fwd\u001b[39m(layer_params, x): \u001b[38;5;66;03m# input: seq_len x emb_dim\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x504 and 512x512)"
     ]
    }
   ],
   "source": [
    "from model_triton import *\n",
    "\n",
    "seq_len = 32\n",
    "vocab_size = 12000\n",
    "layers = 12\n",
    "emb_dim= 512\n",
    "nheads = 12\n",
    "ffn_dim = 256\n",
    "params = init_transformer_gpt2(vocab_size, emb_dim, layers, nheads, ffn_dim, seq_len)\n",
    "\n",
    "y_in = torch.arange(seq_len, dtype=torch.int32, device=\"cuda\")\n",
    "y_in = torch.unsqueeze(y_in, 0)\n",
    "y_mask = torch.tril(torch.ones((seq_len, seq_len), dtype=torch.bool, device=\"cuda\"))\n",
    "y_mask = torch.unsqueeze(y_mask,0)\n",
    "y_indices = torch.arange(seq_len, dtype=torch.int16, device=\"cuda\")\n",
    "y_indices = torch.unsqueeze(y_indices, 0)\n",
    "train=False\n",
    "logits_torch_logits = batched_forward_gpt2(params, y_in, y_mask, y_indices, train) \n",
    "print('------')\n",
    "logits_triton = t_batched_forward_gpt2(params, y_in, y_mask, y_indices, train) \n",
    "torch.allclose(logits_torch_logits, logits_triton, 1e-04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16e4903",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
