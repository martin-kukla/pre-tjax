{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66a1a758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset\n",
      "Loading tokenizer bpe_tokenizer_ds_train_all_merges_35k.pickle\n",
      "Tokenizing dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 134.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totals: x 335720 y 328840\n",
      "avgs per batch: x 3357.2 y 3288.4\n",
      "avgs per datapoint: x 26.228125 y 25.690625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tokenized_dataset import get_batched_examples, load_tokenized_dataset\n",
    "\n",
    "# Take sample of data\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "ds, (tokenizer, detokenize, tokenizer_vocab_size) = load_tokenized_dataset()\n",
    "\n",
    "sample_batch_size=128\n",
    "sample_num_iters=100\n",
    "sample_n = sample_batch_size * sample_num_iters\n",
    "seq_len=50\n",
    "x_lens = []\n",
    "y_lens = []\n",
    "\n",
    "def count_toks(x):\n",
    "    return np.sum(np.array(x) != 0)\n",
    "for i, (x, y) in tqdm(enumerate(itertools.islice(get_batched_examples(ds, sample_batch_size, seq_len), sample_num_iters))):\n",
    "    for x_row, y_row in zip(x, y):\n",
    "        x_lens.append(count_toks(x_row))\n",
    "        y_lens.append(count_toks(y_row))\n",
    "print(f'totals: x {sum(x_lens)} y {sum(y_lens)}')\n",
    "print(f'avgs per batch: x {sum(x_lens)/sample_num_iters} y {sum(y_lens)/sample_num_iters}')\n",
    "print(f'avgs per datapoint: x {sum(x_lens)/len(x_lens)} y {sum(y_lens)/len(y_lens)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6431487",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Smaller than 50 (out of {len(x_lens)}): x {sum([x_len<50 for x_len in x_lens])} y {sum([y_len<50 for y_len in y_lens])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692d82dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(x_lens)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8cadff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (x, y) in tqdm(enumerate(itertools.islice(get_batched_examples(32, 50), 10))):\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf847cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (x, y) in tqdm(enumerate(itertools.islice(get_batched_examples(320, 50), 1))):\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249cb750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find max len helper\n",
    "from tokenized_dataset import load_tokenized_dataset, get_batched_examples, get_batched_examples_per_length, get_batched_examples_packed\n",
    "ds, (tokenizer, detokenize, tokenizer_vocab_size) = load_tokenized_dataset()\n",
    "ds = ds.shuffle(seed=42) # TODO XXX: put it in better place? does it mess up with resume_from_checkpoint logic?\n",
    "\n",
    "#train_lens_x = [len(item['x']) for item in ds[\"train\"]]\n",
    "#train_lens_y = [len(item['y']) for item in ds[\"train\"]]\n",
    "val_lens_x = [len(item['x']) for item in ds[\"validation\"]]\n",
    "val_lens_y = [len(item['y']) for item in ds[\"validation\"]]\n",
    "len([len_x for len_x in lens_x if len_x>94])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
